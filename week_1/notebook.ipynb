{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8df86b3-5640-4b79-8819-8573b06a4930",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "æœ¬ç« ç¯€å°‡å¸¶ä½ å¿«é€Ÿèµ°éä¸€å€‹ **LlamaIndex å‘é‡æª¢ç´¢ï¼ˆVector-based RAGï¼‰** çš„æœ€å°å¯è¡Œæµç¨‹ï¼ˆMinimal Working Exampleï¼‰ï¼ŒåŒ…å«ï¼š\n",
    "\n",
    "1. è¼‰å…¥ Embedding Model  \n",
    "2. å»ºç«‹ Vector Store  \n",
    "3. å°‡æ–‡ä»¶åˆ‡åˆ†ç‚º Nodes ä¸¦å»ºç«‹ Embeddings\n",
    "    - Node æ˜¯ LlamaIndex ç”šè‡³æ•´å€‹ RAG æ¶æ§‹ä¸­ï¼Œæª¢ç´¢ï¼ˆRetrievalï¼‰çš„ã€Œæœ€å°åŸå­å–®ä½ã€ã€‚\n",
    "4. å»ºç«‹ Index\n",
    "    - Index æ˜¯é€£æ¥ Node å’Œæ•¸æ“šå­˜å„²çš„é‚è¼¯æ©‹æ¨‘ã€‚\n",
    "    - çµ„ç¹”è€…ï¼šå®ƒæ±ºå®šäº†æ•¸æ“šå¦‚ä½•è¢«çµ„ç¹”ã€‚æœ€å¸¸è¦‹çš„æ˜¯ VectorStoreIndexï¼Œå®ƒæœƒæŠŠ Node çš„å‘é‡å­˜å…¥ Vector Storeã€‚\n",
    "    - ä¸­ä»‹ï¼šç•¶ä½ é€²è¡ŒæŸ¥è©¢æ™‚ï¼Œä½ æ˜¯å‘ Index æå•ï¼ŒIndex æœƒå»èª¿åº¦ Vector Store å°‹æ‰¾æœ€åŒ¹é…çš„ Nodeï¼Œä¸¦å°‡å…¶å›å‚³ã€‚\n",
    "6. ä½¿ç”¨ Retriever é€²è¡ŒæŸ¥è©¢  \n",
    "\n",
    "æ­¤æµç¨‹æ˜¯å»ºæ§‹ **Retrieval-Augmented Generationï¼ˆRAGï¼‰ç³»çµ±** çš„åŸºç¤ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca214960-3eb2-4513-8205-febe66ec4125",
   "metadata": {},
   "source": [
    "## Ollama Cloud Service with LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6fc09-f62d-4148-b932-5c2bcd6be8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from initialization import credential_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40009e5-2d0b-4ecd-8a29-d0195ed7f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "model = \"gpt-oss:120b-cloud\"\n",
    "base_url = \"https://ollama.com\"\n",
    "\n",
    "credential_init()\n",
    "\n",
    "ollama_llm = Ollama(model=model, request_timeout=60.0, \n",
    "                         base_url=base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725db8d9-e452-45f2-a0c1-f3a07da11b3f",
   "metadata": {},
   "source": [
    "ä¹Ÿå¯ä»¥å¾ src.ollama_connection è£¡ç›´æ¥èª¿ç”¨:\n",
    "\n",
    "```\n",
    "from src.ollama_connection import llama_index_ollama\n",
    "\n",
    "ollama_llm = llama_index_ollama(model=model, temperature=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e53c7c-8c18-4746-bdef-47f96929068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await ollama_llm.acomplete(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb46db1-cfd5-4777-b96f-3bdd84e4d329",
   "metadata": {},
   "source": [
    "## Loading embedding model\n",
    "\n",
    "åœ¨ RAG ç³»çµ±ä¸­ï¼Œ**Embedding Model** è² è²¬å°‡æ–‡å­—è½‰æ›æˆé«˜ç¶­åº¦å‘é‡ï¼ˆvectorï¼‰ï¼Œä»¥ä¾¿å¾ŒçºŒé€²è¡Œèªæ„ç›¸ä¼¼åº¦æœå°‹ã€‚\n",
    "\n",
    "é€™è£¡æˆ‘å€‘ä½¿ç”¨ HuggingFace ä¸Šçš„ **BAAI/bge-small-en-v1.5**ï¼š\n",
    "- è¼•é‡ã€é€Ÿåº¦å¿«\n",
    "- é©åˆæœ¬åœ°ç«¯æˆ–æ•™å­¸ç¤ºç¯„\n",
    "- å‘é‡ç¶­åº¦ç‚º **384**\n",
    "\n",
    "```python\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "```\n",
    "\n",
    "ğŸ“Œ æ³¨æ„\n",
    "Embedding model çš„è¼¸å‡ºç¶­åº¦ï¼Œå¿…é ˆèˆ‡å¾Œé¢ Vector Store ä½¿ç”¨çš„å‘é‡ç¶­åº¦ä¸€è‡´ï¼Œå¦å‰‡æœƒç”¢ç”ŸéŒ¯èª¤ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31eee42-0f2c-44ab-a311-4c3f18c249b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# loads https://huggingface.co/BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aac67a7-9be1-4907-98c0-198db363e93e",
   "metadata": {},
   "source": [
    "## Loading a vector store\n",
    "\n",
    "Vector Store ç”¨ä¾†å„²å­˜ï¼š\n",
    "\n",
    ">- Node çš„å‘é‡è¡¨ç¤ºï¼ˆembeddingsï¼‰\n",
    "\n",
    ">- å°æ‡‰çš„ Node ID\n",
    "\n",
    "é€™è£¡ä½¿ç”¨ FAISSï¼ˆFacebook AI Similarity Searchï¼‰ï¼š\n",
    "\n",
    ">- é«˜æ•ˆèƒ½\n",
    "\n",
    ">- å¸¸è¦‹æ–¼æœ¬åœ°å‘é‡æª¢ç´¢å ´æ™¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f723a7b-0f4c-4325-b71b-3db5e04712a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "d = 384 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfced4f5-7263-4bfe-b106-b365109ec12e",
   "metadata": {},
   "source": [
    "ğŸ“Œ IndexFlatL2\n",
    "è¡¨ç¤ºä½¿ç”¨ L2 è·é›¢ï¼ˆæ­å¼è·é›¢ï¼‰ä¾†è¨ˆç®—å‘é‡ç›¸ä¼¼åº¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9476f6e6-025f-4507-8573-a8ad8379c364",
   "metadata": {},
   "source": [
    "## Creating Nodes and Their Embeddings\n",
    "\n",
    "ç‚ºä»€éº¼éœ€è¦ Nodesï¼Ÿ\n",
    "\n",
    "åœ¨ LlamaIndex ä¸­ï¼š\n",
    "\n",
    ">- Document æ˜¯åŸå§‹æ–‡ä»¶\n",
    ">- Node æ˜¯å¯è¢«æª¢ç´¢çš„æœ€å°å–®ä½\n",
    "\n",
    "Node Parser æ±ºå®šäº†ï¼š\n",
    "\n",
    ">- æ–‡ä»¶å¦‚ä½•è¢«åˆ‡åˆ†\n",
    ">- æ¯å€‹ Node çš„ä¸Šä¸‹æ–‡ç¯„åœèˆ‡ metadata\n",
    "\n",
    "---\n",
    "SentenceWindowNodeParserï¼ˆå¥å­è¦–çª—è§£æå™¨ï¼‰\n",
    "\n",
    "æ­¤ Parser æœƒï¼š\n",
    "\n",
    ">- å°‡æ–‡ä»¶åˆ‡æˆã€Œå–®ä¸€å¥å­ã€\n",
    ">- ä½†åœ¨ metadata ä¸­ä¿ç•™å‰å¾Œçš„ã€Œå¥å­è¦–çª—ï¼ˆwindowï¼‰ã€\n",
    "\n",
    "é€™å° embedding éå¸¸æœ‰ç”¨ï¼š\n",
    "\n",
    ">- embedding å¾ˆç²¾æº–ï¼ˆå–®å¥ï¼‰\n",
    ">- å›ç­”æ™‚ä»ä¿æœ‰ä¸Šä¸‹æ–‡ï¼ˆwindowï¼‰\n",
    "\n",
    "---\n",
    "IngestionPipelineï¼ˆè³‡æ–™è™•ç†ç®¡ç·šï¼‰\n",
    "\n",
    "IngestionPipeline å°‡å¤šå€‹æ­¥é©Ÿä¸²åœ¨ä¸€èµ·ï¼š\n",
    "\n",
    ">1. Node Parserï¼ˆæ–‡ä»¶ â†’ Nodesï¼‰\n",
    ">2. Embedding Modelï¼ˆNodes â†’ Vectorsï¼‰\n",
    ">3. å¯«å…¥ Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e3f9c-e450-4c48-b5a6-5b209c5daa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter, SentenceWindowNodeParser\n",
    "from llama_index.core.extractors import TitleExtractor\n",
    "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
    "\n",
    "node_parser = SentenceWindowNodeParser(\n",
    "    # How many sentences on both sides to capture. \n",
    "    # Setting this to 3 results in 7 sentences.\n",
    "    window_size=3, # # å‰å¾Œå„ 3 å¥ï¼Œå…± 7 å¥\n",
    "    # the metadata key for to be used in MetadataReplacementPostProcessor\n",
    "    window_metadata_key=\"window\",\n",
    "    # the metadata key that holds the original sentence\n",
    "    original_text_metadata_key=\"original_sentence\"\n",
    ")\n",
    "\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        node_parser,\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "# run the pipeline\n",
    "nodes = pipeline.run(documents=[Document.example()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee60945-13ec-42c8-be3e-d89701b3fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c23c1b-76f2-4775-8206-2ad92f8f3550",
   "metadata": {},
   "source": [
    "ğŸ“Œ å¥½è™•\n",
    "\n",
    ">- æµç¨‹æ¨¡çµ„åŒ–\n",
    ">- æ˜“æ–¼æ›¿æ› parser / embedding / extractor\n",
    ">- é©åˆæ­£å¼å°ˆæ¡ˆä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b1e37-f00d-46b0-a083-5952d4c196bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688243d-9b33-4632-81ba-24e9a8afd341",
   "metadata": {},
   "source": [
    "## Building the Indexï¼ˆå»ºç«‹ç´¢å¼•ï¼‰\n",
    "\n",
    "Index æ˜¯ï¼š\n",
    "\n",
    ">- Vector Store çš„æŠ½è±¡å°è£\n",
    ">- æä¾› Retriever èˆ‡ Query Engine çš„å…¥å£\n",
    "\n",
    "Storage Context çš„æ ¸å¿ƒåŠŸç”¨\n",
    "\n",
    "åœ¨ LlamaIndex ä¸­ï¼Œè³‡æ–™ä¸åªæ˜¯ã€Œå‘é‡ã€è€Œå·²ã€‚ä¸€å€‹å®Œæ•´çš„ RAG ç³»çµ±éœ€è¦å„²å­˜å¤šç¨®è³‡è¨Šï¼ŒStorage Context è² è²¬çµ±ä¸€ç®¡ç†ä»¥ä¸‹å¹¾å€‹çµ„ä»¶ï¼š\n",
    "\n",
    "- Vector Store (å‘é‡å„²å­˜)ï¼š\n",
    "    - å„²å­˜ Node çš„ Embeddingï¼ˆå‘é‡ï¼‰ã€‚\n",
    "    - ç”¨æ–¼ã€Œèªç¾©æœå°‹ã€ã€‚\n",
    "\n",
    "- Docstore (æ–‡ä»¶å„²å­˜)ï¼š\n",
    "    - å„²å­˜ Node çš„ åŸå§‹æ–‡æœ¬å…§å®¹ å’Œ å…ƒæ•¸æ“š (Metadata)ã€‚\n",
    "    - ç‚ºä»€éº¼éœ€è¦ï¼Ÿ å› ç‚ºå‘é‡æ•¸æ“šåº«æœ‰æ™‚åªå­˜å‘é‡ï¼Œç•¶æœå°‹åˆ°åŒ¹é…çš„å‘é‡å¾Œï¼Œç³»çµ±éœ€è¦å›é ­å¾ Docstore æŠ“å–çœŸæ­£çš„æ–‡å­—çµ¦ LLM çœ‹ã€‚\n",
    "\n",
    "- Index Store (ç´¢å¼•å„²å­˜)ï¼š\n",
    "\n",
    "    - å„²å­˜ Index æœ¬èº«çš„çµæ§‹è³‡è¨Šï¼ˆä¾‹å¦‚ï¼šé€™æ£µæ¨¹æ˜¯æ€éº¼é€£çš„ï¼Œæˆ–è€…é€™å€‹æ‘˜è¦ç´¢å¼•çš„å±¤ç´šé—œä¿‚ï¼‰ã€‚\n",
    "\n",
    "- Property Graph Store (å±¬æ€§åœ–å„²å­˜)ï¼š\n",
    "\n",
    "    - ï¼ˆé¸é…ï¼‰ç”¨æ–¼å„²å­˜çŸ¥è­˜åœ–è­œï¼ˆKnowledge Graphï¼‰çš„å¯¦é«”èˆ‡é—œä¿‚ã€‚\n",
    " \n",
    "![caption](Gemini_Generated_Image_gfpi58gfpi58gfpi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801dc0f8-d669-4f9f-aabe-b0d02984943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    llm=ollama_llm\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex(nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3fbda-e353-41a9-876b-dabdc21d1570",
   "metadata": {},
   "source": [
    "## Retrieving Nodesï¼ˆèªæ„æª¢ç´¢ï¼‰\n",
    "\n",
    "Retriever è² è²¬ï¼š\n",
    "\n",
    ">- å°‡ query è½‰æˆ embedding\n",
    ">- èˆ‡å‘é‡è³‡æ–™åº«æ¯”å°\n",
    ">- å›å‚³æœ€ç›¸ä¼¼çš„ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde936c3-817e-46ba-9314-4bd7953489d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11214f5-a1a0-4185-838a-4369bc99c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.retrieve(\"what is LLM?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af9c939-d17b-4b7a-a0ec-91ee2027deae",
   "metadata": {},
   "source": [
    "å›å‚³çµæœæ˜¯ Node listï¼Œä¸æ˜¯æœ€çµ‚æ–‡å­—ç­”æ¡ˆ\n",
    "\n",
    "é€™äº› Nodes æœƒåœ¨å¾ŒçºŒäº¤çµ¦ LLM ç”¢ç”Ÿå›æ‡‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4397a2-be98-4e98-94ea-5388285e08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index from base nodes\n",
    "# base_index = VectorStoreIndex(base_nodes)\n",
    "\n",
    "# Instantiate query engine from vector index\n",
    "base_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=1,\n",
    ")\n",
    "\n",
    "# Send query to the engine to get related node(s)\n",
    "base_response = base_query_engine.query(\"what is LLM?\")\n",
    "\n",
    "print(base_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d3d49-743e-46d9-8c48-7206da32912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response.source_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb38a72-fe29-449a-839a-a9439d1f1ba5",
   "metadata": {},
   "source": [
    "# Basic Node Parsers\n",
    "\n",
    "å®˜æ–¹æ–‡æª”: https://developers.llamaindex.ai/python/framework/module_guides/loading/node_parsers/modules/\n",
    "\n",
    "åœ¨ **LlamaIndex** ä¸­ï¼Œ**Node Parser**ï¼ˆç¯€é»è§£æå™¨ï¼‰è² è²¬å°‡åŸå§‹æ–‡ä»¶ï¼ˆå¦‚ PDFã€Markdownã€ç´”æ–‡å­—ï¼‰åˆ‡åˆ†æˆè¼ƒå°ã€çµæ§‹åŒ–çš„å–®ä½ï¼Œç¨±ç‚º **Nodes**ã€‚é€™äº› Nodes æ˜¯å¾ŒçºŒå»ºç«‹ç´¢å¼•ã€æª¢ç´¢èˆ‡èªæ„æœå°‹çš„åŸºç¤ã€‚\n",
    "\n",
    "## ç‚ºä»€éº¼éœ€è¦ Node Parserï¼Ÿ\n",
    "- ğŸ§© **æå‡æª¢ç´¢å“è³ª**ï¼šé©ç•¶çš„åˆ‡åˆ†å¯è®“æ¨¡å‹æ›´ç²¾æº–ç†è§£ä¸Šä¸‹æ–‡  \n",
    "- âš–ï¸ **æ§åˆ¶ä¸Šä¸‹æ–‡é•·åº¦**ï¼šé¿å…å–®æ¬¡è¼¸å…¥éé•·ï¼Œè¶…å‡º LLM é™åˆ¶  \n",
    "- ğŸ—ï¸ **ä¿ç•™çµæ§‹è³‡è¨Š**ï¼šå¯åŒ…å« metadataï¼ˆå¦‚æ®µè½ã€é ç¢¼ã€æ¨™é¡Œï¼‰\n",
    "\n",
    "## å¸¸è¦‹çš„ Node Parser é¡å‹\n",
    "- **SentenceSplitter**ï¼šä¾å¥å­åˆ‡åˆ†ï¼ˆæœ€å¸¸ç”¨ï¼‰\n",
    "- **TokenTextSplitter**ï¼šä¾ token æ•¸é‡åˆ‡åˆ†ï¼Œé©åˆç²¾ç´°æ§åˆ¶\n",
    "- **MarkdownNodeParser**ï¼šä¿ç•™ Markdown çµæ§‹ï¼ˆå¦‚æ¨™é¡Œã€æ¸…å–®ï¼‰\n",
    "- **HierarchicalNodeParser**ï¼šå»ºç«‹çˆ¶å­éšå±¤çš„ç¯€é»çµæ§‹\n",
    "\n",
    "## åŸºæœ¬ä½¿ç”¨ç¯„ä¾‹\n",
    "```python\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "\n",
    "parser = SentenceSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "```\n",
    "\n",
    "## ç¸½çµ\n",
    "\n",
    "Node Parser æ˜¯ LlamaIndex æ–‡ä»¶è™•ç†æµç¨‹ä¸­çš„é—œéµå…ƒä»¶ï¼Œæ±ºå®šäº†è³‡æ–™å¦‚ä½•è¢«åˆ‡åˆ†èˆ‡ç†è§£ã€‚é¸æ“‡åˆé©çš„ Parser èˆ‡åƒæ•¸ï¼Œèƒ½é¡¯è‘—å½±éŸ¿ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»çµ±çš„æ•ˆèƒ½èˆ‡æº–ç¢ºåº¦ã€‚\n",
    "\n",
    "## åŸºæ–¼æª”æ¡ˆçš„Node Parser\n",
    "\n",
    "æœ‰å¤šç¨®**ä»¥æª”æ¡ˆç‚ºåŸºç¤çš„ Node Parser**ï¼Œæœƒæ ¹æ“šè¢«è§£æçš„å…§å®¹é¡å‹ï¼ˆä¾‹å¦‚ JSONã€Markdown ç­‰ï¼‰ä¾†å»ºç«‹å°æ‡‰çš„ç¯€é»ï¼ˆNodesï¼‰ã€‚\n",
    "\n",
    "æœ€ç°¡å–®çš„æµç¨‹æ˜¯å°‡ **FlatFileReader** èˆ‡ **SimpleFileNodeParser** çµåˆä½¿ç”¨ï¼Œç³»çµ±æœƒè‡ªå‹•ç‚ºæ¯ä¸€ç¨®å…§å®¹é¡å‹é¸æ“‡æœ€åˆé©çš„ Node Parserã€‚æ¥è‘—ï¼Œä½ å¯ä»¥å†å°‡é€™é¡æª”æ¡ˆå‹ Node Parser èˆ‡**æ–‡å­—å‹ Node Parser** ä¸²æ¥ä½¿ç”¨ï¼Œä»¥é€²ä¸€æ­¥è€ƒé‡å¯¦éš›æ–‡å­—é•·åº¦ï¼Œç¢ºä¿åˆ‡åˆ†çµæœæ›´ç¬¦åˆå¾ŒçºŒè™•ç†éœ€æ±‚ã€‚\n",
    "\n",
    "\n",
    "### SimpleFileNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522ed63-b461-4a01-aba2-8697ce164ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.core.node_parser import SimpleFileNodeParser\n",
    "from llama_index.readers.file import FlatReader\n",
    "\n",
    "\n",
    "md_docs = FlatReader().load_data(Path(\"week_1/week-1.md\"))\n",
    "\n",
    "parser = SimpleFileNodeParser()\n",
    "md_nodes = parser.get_nodes_from_documents(md_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131fcb16-598f-4878-827c-6cb0f6109448",
   "metadata": {},
   "source": [
    "### HTMLNodeParser\n",
    "æ­¤ Node Parser æœƒä½¿ç”¨ **BeautifulSoup** ä¾†è§£æåŸå§‹çš„ HTML å…§å®¹ã€‚\n",
    "\n",
    "é è¨­æƒ…æ³ä¸‹ï¼Œå®ƒåªæœƒè§£æä¸€éƒ¨åˆ†æŒ‡å®šçš„ HTML æ¨™ç±¤ï¼Œä½†ä½ ä¹Ÿå¯ä»¥è‡ªè¡Œè¦†å¯«é€™å€‹è¨­å®šã€‚\n",
    "\n",
    "é è¨­è§£æçš„æ¨™ç±¤åŒ…å«ï¼š\n",
    "`[\"p\", \"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"li\", \"b\", \"i\", \"u\", \"section\"]`\n",
    "\n",
    "å¯åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ä¾†å–å¾—ç¯„ä¾‹ HTML æª”æ¡ˆï¼š\n",
    "\n",
    "```bash\n",
    "python -m html_file_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3137e4f-b87d-424f-b2f5-eea9dc59bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HTMLNodeParser\n",
    "\n",
    "html_docs = FlatReader().load_data(Path(\"week_1/Titan.html\"))\n",
    "\n",
    "parser = HTMLNodeParser(tags=[\"p\", \"h1\", 'u', 'section'])  # optional list of tags\n",
    "nodes = parser.get_nodes_from_documents(html_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0894ea29-3727-4b46-a69a-48896f6e993c",
   "metadata": {},
   "source": [
    "### JSONNodeParser\n",
    "\n",
    "ç”¨æ–¼è§£æåŸå§‹çš„ JSON è³‡æ–™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec5a05-52d7-4e76-91af-4208235ed85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import JSONNodeParser\n",
    "\n",
    "json_docs = FlatReader().load_data(Path(\"week_1/mock_data.json\"))\n",
    "\n",
    "parser = JSONNodeParser()\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(json_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d841a42-3c6c-4796-b807-91f06910a8c6",
   "metadata": {},
   "source": [
    "### MarkdownNodeParser\n",
    "ç”¨æ–¼è§£æåŸå§‹çš„ Markdown æ–‡å­—å…§å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8d4fd-7460-4fe1-9341-760557cbd274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import FlatReader\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "\n",
    "parser = MarkdownNodeParser()\n",
    "\n",
    "md_docs = FlatReader().load_data(Path(\"week_1/week-1.md\"))\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(md_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6ca0a-e681-46ee-af4f-335072ac04da",
   "metadata": {},
   "source": [
    "## Text-Splitters\n",
    "\n",
    "ä¸æ˜¯è¶Šå¤§è¶Šå¥½\n",
    "\n",
    ">- Chunk å¤ªå¤§ â†’ embedding æ··åˆå¤šå€‹ä¸»é¡Œï¼Œç›¸ä¼¼åº¦å¤±æº–\n",
    ">- Chunk å¤ªå° â†’ èªæ„ç ´ç¢ï¼ŒLLM å›ç­”å“è³ªä¸‹é™\n",
    "\n",
    "### CodeSplitter\n",
    "\n",
    "æœƒæ ¹æ“šç¨‹å¼ç¢¼æ‰€ä½¿ç”¨çš„ç¨‹å¼èªè¨€ï¼Œå°‡åŸå§‹çš„ç¨‹å¼ç¢¼æ–‡å­—é€²è¡Œåˆ‡åˆ†ã€‚\n",
    "\n",
    "å¯åœ¨ä»¥ä¸‹é€£çµæŸ¥çœ‹å®Œæ•´æ”¯æ´çš„ç¨‹å¼èªè¨€æ¸…å–®ï¼š\n",
    "\n",
    "https://github.com/grantjenks/py-tree-sitter-languages#license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0ebe9-44d4-43b9-bb01-ae5dea2dda2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import FlatReader\n",
    "from llama_index.core.node_parser import CodeSplitter\n",
    "\n",
    "documents = FlatReader().load_data(Path(\"week_1/mock_python.py\"))\n",
    "\n",
    "splitter = CodeSplitter(\n",
    "    language=\"python\",\n",
    "    chunk_lines=40,  # lines per chunk\n",
    "    chunk_lines_overlap=15,  # lines overlap between chunks\n",
    "    max_chars=1500,  # max chars per chunk\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56bfbd-21e7-4936-992c-56271cd8d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ede387-3f91-4803-a027-b77f54e37b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782d40d-82b4-4bb8-900f-dad6ad30f580",
   "metadata": {},
   "source": [
    "### LangchainNodeParser\n",
    "ä½ ä¹Ÿå¯ä»¥å°‡ **LangChain** ä¸­ç¾æœ‰çš„ä»»ä½•æ–‡å­—åˆ‡åˆ†å™¨ï¼ˆtext splitterï¼‰åŒ…è£æˆä¸€å€‹ Node Parser ä¾†ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ff909-7a1a-439b-b422-c9efa58eadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from llama_index.core.node_parser import LangchainNodeParser\n",
    "\n",
    "documents = FlatReader().load_data(Path(\"week_1/mock_langchain_text.md\"))\n",
    "\n",
    "parser = LangchainNodeParser(RecursiveCharacterTextSplitter(chunk_size=250))\n",
    "nodes = parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57866bb-cc6b-4810-addb-2f9a91f07ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb32ac-86fa-420c-bed9-55e28c7c886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nodes[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496745f1-a7dd-4fb7-8a7c-d626f6967188",
   "metadata": {},
   "source": [
    "### SentenceSplitter\n",
    "**SentenceSplitter** æœƒåœ¨ç›¡é‡ä¿ç•™å¥å­é‚Šç•Œçš„å‰æä¸‹ï¼Œå°æ–‡å­—å…§å®¹é€²è¡Œåˆ‡åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b838fe-a163-408f-9b74-fcc1f3d03c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "documents = FlatReader().load_data(Path(\"week_1/mock_langchain_text.md\"))\n",
    "\n",
    "sentence_splitter_node_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = sentence_splitter_node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7aa15e-8066-49d2-8d03-6b49a0632cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter.split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484ee3e-82dd-4da2-8e83-b4a4af9947cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo ç§»å» Advance Node Parser\n",
    "# ### SentenceWindowNodeParser\n",
    "\n",
    "# `SentenceWindowNodeParser` èˆ‡å…¶ä»–ç¯€é»è§£æå™¨ç›¸ä¼¼ï¼Œä¸éå®ƒæœƒå°‡æ‰€æœ‰æ–‡ä»¶æ‹†åˆ†æˆå–®ç¨çš„å¥å­ã€‚  \n",
    "# ç”Ÿæˆçš„ç¯€é»åœ¨å…¶ metadata ä¸­é‚„åŒ…å«äº†æ¯å€‹ç¯€é»å‘¨åœçš„ã€Œå¥å­çª—å£ã€ã€‚  \n",
    "# > âš ï¸ è«‹æ³¨æ„ï¼Œé€™äº› metadata ä¸æœƒè¢« LLM æˆ–åµŒå…¥æ¨¡å‹çœ‹åˆ°ã€‚  \n",
    "\n",
    "# é€™åœ¨ç”Ÿæˆå…·æœ‰éå¸¸ç‰¹å®šç¯„åœçš„åµŒå…¥æ™‚æœ€ç‚ºæœ‰ç”¨ã€‚  \n",
    "# ç„¶å¾Œï¼Œçµåˆ `MetadataReplacementNodePostProcessor`ï¼Œæ‚¨å¯ä»¥åœ¨å°‡ç¯€é»å‚³é€çµ¦ LLM ä¹‹å‰ï¼Œç”¨å…¶å‘¨åœçš„ä¸Šä¸‹æ–‡æ›¿æ›è©²å¥å­ã€‚  \n",
    "\n",
    "# ä¸‹é¢æ˜¯ä¸€å€‹ä½¿ç”¨é è¨­è¨­å®šä¾†è¨­ç½®è§£æå™¨çš„ç¯„ä¾‹ï¼š  \n",
    "# > åœ¨å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œæ‚¨é€šå¸¸åªéœ€è¦èª¿æ•´å¥å­çš„çª—å£å¤§å°å³å¯ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206bda57-c7d7-4ce3-a69a-b37cae544a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "#     # how many sentences on either side to capture\n",
    "#     window_size=3,\n",
    "#     # the metadata key that holds the window of surrounding sentences\n",
    "#     window_metadata_key=\"window\",\n",
    "#     # the metadata key that holds the original sentence\n",
    "#     original_text_metadata_key=\"original_sentence\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b183ed3-cf9b-405c-8851-57a3c7c259af",
   "metadata": {},
   "source": [
    "### SemanticSplitterNodeParser\n",
    "\n",
    "SemanticSplitter ä¸æ˜¯è² è²¬æ–·å¥çš„ï¼Œ\n",
    "å®ƒåªæ˜¯åœ¨ã€Œå·²æ–·å¥½çš„å¥å­ã€ä¹‹é–“æ‰¾èªæ„è·³èºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543c4ce-4883-41c7-9f17-88a92cb7a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "documents = FlatReader().load_data(Path(\"week_1/semantic_test_zh.txt\"))\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=32,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼Œ\", \" \"]\n",
    ").split_text\n",
    "\n",
    "# text_splitter = SentenceSplitter(chunk_size=64,\n",
    "#                                  chunk_overlap=0).split_text\n",
    "\n",
    "semantic_splitter_node_parser = SemanticSplitterNodeParser.from_defaults(\n",
    "    embed_model = embed_model,\n",
    "    sentence_splitter=text_splitter,\n",
    "    include_metadata=True,\n",
    "    include_prev_next_rel=True,\n",
    "    breakpoint_percentile_threshold=75,\n",
    ")\n",
    "\n",
    "nodes = semantic_splitter_node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a66863-f776-46de-97fb-fc80d87b80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0216d-74ea-468a-a04a-033b96ae7ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1740a41-628f-489c-b3dc-4a979c6361ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a815d52-a00f-435e-a5e7-281a6896431d",
   "metadata": {},
   "source": [
    "### TokenTextSplitter\n",
    "`TokenTextSplitter` å˜—è©¦æ ¹æ“šåŸå§‹çš„ **token æ•¸é‡** å°‡æ–‡æœ¬åˆ‡åˆ†æˆå¤§å°ä¸€è‡´çš„å¡Šï¼ˆchunkï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85fe69-9553-47ad-9f8b-14866e1480f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "node_parser = TokenTextSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    "    separator=\" \",\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e691b-a638-4531-a8cc-edd32b257c96",
   "metadata": {},
   "source": [
    "# VectorStore\n",
    "\n",
    "é€™è£¡æˆ‘å€‘å±•ç¤ºå¦‚ä½•å®£å‘Švectorstoreï¼Œç„¶å¾Œåœ¨Indexçš„éƒ¨åˆ†ç¤ºç¯„å¦‚ä½•retrieveã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b7111-93ed-487c-98a6-20d0bd55b5bd",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6e37f-adad-46d9-9402-c0b862831706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "d = 1024 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´ï¼Œé€™é‚Šé…åˆ BAAI/bge-m3\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "faiss_vector_store = FaissVectorStore(faiss_index=faiss_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4f7af-0353-4b2a-a604-1c02027297b7",
   "metadata": {},
   "source": [
    "## Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ab6eb-1a1d-4435-b6a5-f681a435d529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from qdrant_client import AsyncQdrantClient\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "\n",
    "client = AsyncQdrantClient(path=\"week_1/langchain_qdrant\")\n",
    "\n",
    "qdrant_vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"my_document\" # This collection will hold your vectors and associated documents.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e72740-763f-4bc1-b904-17b9a69c12f6",
   "metadata": {},
   "source": [
    "# Index - Basic\n",
    "\n",
    "## VectorIndexStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f77054e-dab7-45bf-97ca-c194ecb0b307",
   "metadata": {},
   "source": [
    "å»ºç«‹documentsã€‚å…ˆè²æ˜æˆ‘æ²’è²·ä»–å€‘è‚¡ç¥¨ï¼Œä¹Ÿä¸æä¾›æŠ•è³‡å»ºè­°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb8f97-d621-43b3-a3ed-5889a893d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_splitter = SentenceSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=120,\n",
    ")\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "\n",
    "files = [\n",
    "    \"week_1/TSMC_2024_å¹´åº¦è²¡å ±.pdf\",\n",
    "    \"week_1/å¯Œé‚¦é‡‘_2024_å¹´åº¦è²¡å ±.pdf\",\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for f in files:\n",
    "    doc_text = \"\\n\\n\".join([d.get_content() for d in loader.load(f)])\n",
    "    docs.append(Document(text=doc_text, metadata={\"file_path\":f}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92900ce-6d1b-44f9-bfc5-ba570dfd089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e118c-a0ff-4f07-a949-d42228d72712",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].id_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de3645-6396-4b70-b4b7-ebbcea0e3dd6",
   "metadata": {},
   "source": [
    "### æ­é… FAISS\n",
    "\n",
    "é€™è£¡çš„åšæ³•ç®—æ˜¯ä¸€ç¨®å¿«é€Ÿæš´åŠ›çš„æ‰‹æ®µã€‚å‹™å¯¦ä¸Šæœƒç”¨\n",
    "\n",
    "parser â†’ nodes â†’ index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47739de7-0c70-4a81-ab67-3fb01cedc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=faiss_vector_store)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "faiss_index = VectorStoreIndex.from_documents(\n",
    "    docs,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    llm=ollama_llm,\n",
    "    transformations=[text_splitter],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac94e4-7775-45c6-9703-27564b35039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_retriever = faiss_index.as_retriever(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e9ae55-754c-43e6-b146-97f152b2f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await faiss_retriever.aretrieve(\"å¹´åº¦ç‡Ÿæ¥­é¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baec3b8-63c9-49c5-a372-9ade72ef0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c494c-7bd6-49a3-a3d6-04aeb204144c",
   "metadata": {},
   "source": [
    "**FAISS ä¸æ”¯æ´åœ¨metadataå±¤é¢éæ¿¾ç¯€é»**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd38620-d904-4674-b8a5-2dc8c945dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters, ExactMatchFilter\n",
    "\n",
    "output = await faiss_retriever.aretrieve(\"å¯Œé‚¦å¹´åº¦ç‡Ÿæ¥­é¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b718d-2309-4bf5-8dbf-94c2aa0b45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74fdf8-8295-4d4a-bf78-06373c88f5e5",
   "metadata": {},
   "source": [
    "### æ­é… Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fa5e2-9c83-4891-8955-ba7baa42f331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=qdrant_vector_store)\n",
    "\n",
    "qdrant_index = VectorStoreIndex.from_documents(\n",
    "    docs,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    llm=ollama_llm,\n",
    "    transformations=[text_splitter],\n",
    "    use_async=True # å› ç‚ºæˆ‘å€‘ä½¿ç”¨async client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6f664-0fe5-4dc4-a131-217b1287f5b7",
   "metadata": {},
   "source": [
    "```\n",
    "ValueError: Async client is not initialized!\n",
    "Please pass in `aclient` to the constructor: `QdrantVectorStore(..., aclient=AsyncQdrantClient(...))`\n",
    "Selection deleted\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4f525-607e-409e-9668-9e46c4447cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_retriever = qdrant_index.as_retriever(similarity_top_k=3)\n",
    "\n",
    "output = await qdrant_retriever.aretrieve(\"å¹´åº¦ç‡Ÿæ¥­é¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b605b-91da-40ed-9c8b-cdefc54fa6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43212be-0713-461f-b764-0fa95c36d80e",
   "metadata": {},
   "source": [
    "é€émetadataé€²è¡Œéæ¿¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9f37e-1ce6-4053-9d64-bc19e91cf65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilters,\n",
    "    ExactMatchFilter,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        ExactMatchFilter(key=\"file_path\", value=\"week_1/å¯Œé‚¦é‡‘_2024_å¹´åº¦è²¡å ±.pdf\"),\n",
    "        # ExactMatchFilter(key=\"source\", value=\"manual.pdf\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "qdrant_retriever = qdrant_index.as_retriever(\n",
    "    similarity_top_k=3,\n",
    "    filters=filters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be38d7d-1110-4688-8e69-16a5e9f1fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = qdrant_retriever.retrieve(\"å¹´åº¦ç‡Ÿæ¥­é¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e7bf3-c6a9-448b-8462-4909e6720acc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696fe86-0c92-4b14-b3b5-c36f59e22bfc",
   "metadata": {},
   "source": [
    "# è©•ä¼° (Evaluation)\n",
    "\n",
    "æˆ‘å€‘é€™è£¡ç”¨LlamaIndexæä¾›çš„Metricsä¾†ç¤ºç¯„å¦‚ä½•é€²è¡Œè©•ä¼°\n",
    "å¾Œé¢æˆ‘å€‘æœƒä½¿ç”¨RAGASé€™å€‹æ¡†æ¶é€²è¡Œè©•ä¼°\n",
    "\n",
    "> âš ï¸ æ³¨æ„ï¼šé€™å€‹éç¨‹å¯èƒ½èŠ±è²»è¼ƒé«˜æˆæœ¬ã€‚è«‹å°å¿ƒä½¿ç”¨ï¼Œä¸¦æ ¹æ“šé ç®—èª¿æ•´æ¨£æœ¬æ•¸é‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71983c26-47c1-41a5-b496-e8f04cd0ab22",
   "metadata": {},
   "source": [
    "ç”¢ç”Ÿnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42194c6-fbae-4368-bd8f-b587a6802f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = text_splitter.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f22473-4015-483b-b308-d04935d9cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d56fa70-69ff-4d6c-a050-248cf9391f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset\n",
    "import nest_asyncio\n",
    "\n",
    "\"\"\"\n",
    "nest_asyncio æœƒ æ‰“è£œä¸ï¼ˆpatchï¼‰ ç¾æœ‰çš„äº‹ä»¶å¾ªç’°ï¼Œä½¿å¾— åœ¨å·²ç¶“é‹è¡Œçš„äº‹ä»¶å¾ªç’°ä¸­å¯ä»¥å†æ¬¡åµŒå¥—é‹è¡Œ asyncioã€‚\n",
    "\n",
    "æ›å¥è©±èªªï¼Œå®ƒè®“ä½ åœ¨ Jupyter Notebook è£¡å¯ä»¥é †åˆ©åŸ·è¡Œï¼š\n",
    "\n",
    "asyncio.run()\n",
    "\n",
    "è‡ªå·±å¯«çš„ async å‡½æ•¸\n",
    "\n",
    "å„ç¨®éœ€è¦äº‹ä»¶å¾ªç’°çš„åº«ï¼ˆä¾‹å¦‚ LLM SDKã€WebSocketã€FastAPI çš„æ¸¬è©¦ç­‰ï¼‰\n",
    "\n",
    "è€Œä¸æœƒç¢°åˆ°ã€Œäº‹ä»¶å¾ªç’°å·²ç¶“é‹è¡Œã€çš„éŒ¯èª¤ã€‚\n",
    "\"\"\"\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b65e40-c11f-4502-8d28-3c406c7ac14f",
   "metadata": {},
   "source": [
    "## äººå·¥æ•¸æ“šåˆæˆ\n",
    "\n",
    "`num_questions_per_chunk` èˆ‡ `num` çš„å·®ç•°èªªæ˜\n",
    "\n",
    "åœ¨ä½¿ç”¨ DatasetGeneratorï¼ˆä¾‹å¦‚ `generate_dataset_from_nodes`ï¼‰æ™‚ï¼Œ  \n",
    "`num_questions_per_chunk` èˆ‡ `num` åˆ†åˆ¥æ§åˆ¶ **æ·±åº¦** èˆ‡ **å»£åº¦**ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 1. `num_questions_per_chunk`ï¼ˆæ¯å€‹ Node ç”¢ç”Ÿçš„å•é¡Œæ•¸é‡ï¼‰\n",
    "\n",
    "### å®šç¾©\n",
    "æ­¤åƒæ•¸å®šç¾© LLM åœ¨è™•ç†**å–®ä¸€ Nodeï¼ˆchunkï¼‰**æ™‚ï¼Œ  \n",
    "è¦å¾è©² Node çš„å…§å®¹ä¸­æŒ–æ˜å‡ºå¤šå°‘å€‹å•é¡Œã€‚\n",
    "\n",
    "- **ä½œç”¨å°è±¡**ï¼šå–®ä¸€ Node\n",
    "- **æ§åˆ¶é¢å‘**ï¼šæ·±åº¦ï¼ˆdepthï¼‰\n",
    "\n",
    "### è¡Œç‚ºé‚è¼¯\n",
    "- è¨­ç‚º `1`  \n",
    "  â†’ LLM è®€å– Node Aï¼Œç”¢ç”Ÿ **1 å€‹å•é¡Œ**\n",
    "- è¨­ç‚º `3`  \n",
    "  â†’ LLM é‡å° Node A çš„å…§å®¹ï¼Œç”¢ç”Ÿ **3 å€‹ä¸åŒçš„å•é¡Œ**\n",
    "\n",
    "### å½±éŸ¿\n",
    "- æ•¸å€¼è¶Šé«˜ï¼š\n",
    "  - å°å–®ä¸€å…§å®¹çš„æ¸¬è©¦è¶Šæ·±å…¥ã€è¶Šåš´å¯†\n",
    "- ä½†å¦‚æœï¼š\n",
    "  - Node æœ¬èº«å…§å®¹è¼ƒå°‘\n",
    "  - æˆ–è³‡è¨Šå¯†åº¦ä¸é«˜  \n",
    "  å‰‡å¯èƒ½å°è‡´ï¼š\n",
    "  - å•é¡Œé‡è¤‡\n",
    "  - æˆ–å•é¡Œå“è³ªä¸‹é™\n",
    "\n",
    "---\n",
    "\n",
    "## 2. `num`ï¼ˆç¸½å…±è™•ç†çš„ Node æ•¸é‡ï¼‰\n",
    "\n",
    "### å®šç¾©\n",
    "æ­¤åƒæ•¸å®šç¾© DatasetGenerator  \n",
    "**ç¸½å…±è¦å¾ `selected_nodes` ä¸­æŒ‘é¸å¤šå°‘å€‹ Node ä¾†ç”Ÿæˆå•é¡Œ**ã€‚\n",
    "\n",
    "- **ä½œç”¨å°è±¡**ï¼šæ•´å€‹ Node åˆ—è¡¨\n",
    "- **æ§åˆ¶é¢å‘**ï¼šå»£åº¦ï¼ˆbreadthï¼‰\n",
    "\n",
    "### è¡Œç‚ºé‚è¼¯\n",
    "- å‡è¨­ä½ æœ‰ `100` å€‹ Nodes\n",
    "- è‹¥è¨­å®š `num = 5`\n",
    "  - åªæœƒé¸å–å‰ `5` å€‹ Nodes ä¾†ç”Ÿæˆå•é¡Œ\n",
    "\n",
    "### å½±éŸ¿\n",
    "- æ±ºå®šæ¸¬è©¦è³‡æ–™é›†æ¶µè“‹ï¼š\n",
    "  - å¤šå°‘åŸå§‹æ–‡ä»¶å…§å®¹\n",
    "  - å¤šå°‘ä¸»é¡Œç¯„åœ\n",
    "\n",
    "---\n",
    "\n",
    "## 3. é¡Œç›®ç¸½æ•¸çš„è¨ˆç®—æ–¹å¼\n",
    "\n",
    "ä½ å¯ä»¥ç”¨ä»¥ä¸‹å…¬å¼ä¾†ä¼°ç®—æœ€çµ‚ç”Ÿæˆçš„é¡Œç›®æ•¸é‡ï¼š\n",
    "\n",
    "$$\n",
    "\\text{Total Questions} = \\text{num} \\times \\text{num\\_questions\\_per\\_chunk}\n",
    "$$\n",
    "\n",
    "### ç¯„ä¾‹\n",
    "```python\n",
    "num = 5\n",
    "num_questions_per_chunk = 1\n",
    "```\n",
    "\n",
    "- è™•ç† 5 å€‹ Nodes\n",
    "- æ¯å€‹ Node ç”¢ç”Ÿ 1 é¡Œ\n",
    "\n",
    "ğŸ‘‰ æœ€çµ‚ç”¢å‡ºï¼š5 å€‹å•é¡Œ\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ç›´è¦ºåœ–è§£ï¼ˆç™½è©±æ¯”å–»ï¼‰\n",
    "\n",
    "å¯ä»¥æŠŠé€™å…©å€‹åƒæ•¸æƒ³åƒæˆã€Œå‡ºè€ƒé¡Œã€çš„æ–¹å¼ï¼š\n",
    "\n",
    "- numï¼šé¸å¹¾å€‹äºº\n",
    "    å¾å…¨ç­ä¸­é¸å‡º 5 å€‹å­¸ç”Ÿ\n",
    "- num_questions_per_chunkï¼šæ¯äººå¯«å¹¾é¡Œ\n",
    "    è¦æ±‚é€™ 5 å€‹å­¸ç”Ÿ\n",
    "\n",
    "æ¯äººå„å¯« 1 é¡Œè€ƒå·\n",
    "\n",
    "ğŸ‘‰ æœ€å¾Œä½ å°±æœƒæ‹¿åˆ° 5 é¡Œè€ƒé¡Œ\n",
    "\n",
    "## 5. ç¸½çµ\n",
    "\n",
    "| åƒæ•¸                        | æ§åˆ¶é¢å‘ | å•çš„æ˜¯ä»€éº¼         |\n",
    "| ------------------------- | ---- | ------------- |\n",
    "| `num`                     | å»£åº¦   | è¦æ¶µè“‹å¤šå°‘ Nodesï¼Ÿ  |\n",
    "| `num_questions_per_chunk` | æ·±åº¦   | æ¯å€‹ Node è¦æŒ–å¤šæ·±ï¼Ÿ |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a09012-c5b2-4d14-b45b-5acc01becfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "selected_nodes = np.random.choice(nodes, size=50, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628d4be-add7-4e27-befc-e0fa2e7f1581",
   "metadata": {},
   "source": [
    "å¯ä»¥é€é`text_question_template`é€™å€‹åƒæ•¸ä¾†è‡ªå®šç¾©æ•¸æ“šç”Ÿæˆä½¿ç”¨çš„promptã€‚ç›¡é‡ä¿æŒæ ¼å¼ä¸€è‡´ï¼Œå¦å¤–åˆ¥å¿˜äº†{context_str}å’Œ{query_str}æ˜¯å¿…å‚™çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca390f0-59c0-49e0-8f32-7b8f2158285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# 1. å°‡å­—ä¸²å°è£æˆ PromptTemplate ç‰©ä»¶\n",
    "text_question_template = PromptTemplate(\n",
    "    'Context information is below.\\n'\n",
    "    '---------------------\\n'\n",
    "    '{context_str}\\n'\n",
    "    '---------------------\\n'\n",
    "    'Given the context information and not prior knowledge.\\n'\n",
    "    'generate only questions based on the below query.\\n'\n",
    "    '{query_str}\\n'\n",
    "    'ã€‚æ‰€æœ‰çš„è¼¸å‡ºå¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡(traditional Chinese)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfbafc-297c-44e6-8080-da4d28d5ab0b",
   "metadata": {},
   "source": [
    "ä¸€æ¬¡æ‰”50å€‹é€²å» Ollama CloudæœƒæŠ±æ€¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37e1ca-2e14-426d-a56b-b94926da3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# åˆ†æ‰¹ç”Ÿæˆï¼Œä¾‹å¦‚ä¸€æ¬¡åªè™•ç† 5 å€‹ nodeï¼Œæ¯æ‰¹ä¹‹é–“ä¼‘æ¯ä¸€ä¸‹\n",
    "async def batch_generate_questions(all_nodes, batch_size=5):\n",
    "    all_questions = []\n",
    "    # å°‡ 50 å€‹ nodes åˆ†æˆæ¯ 5 å€‹ä¸€çµ„\n",
    "    for i in range(0, len(all_nodes), batch_size):\n",
    "        batch_nodes = all_nodes[i:i + batch_size]\n",
    "        print(f\"æ­£åœ¨è™•ç†ç¬¬ {i} åˆ° {i+batch_size} å€‹ç¯€é»...\")\n",
    "\n",
    "        dataset_generator = DatasetGenerator(\n",
    "            batch_nodes,\n",
    "            llm=ollama_llm,\n",
    "            text_question_template=text_question_template,\n",
    "            num_questions_per_chunk=1,\n",
    "        )\n",
    "        \n",
    "        # é‡å°é€™ä¸€å°æ‰¹ç”Ÿæˆå•é¡Œ\n",
    "        # æ³¨æ„é€™è£¡ num å°±ç­‰æ–¼ batch_size\n",
    "        batch_questions = await dataset_generator.agenerate_dataset_from_nodes(num=len(batch_nodes))\n",
    "        all_questions.append(batch_questions)\n",
    "        \n",
    "        # è®“ Ollama å–˜å£æ°£ï¼Œä¼‘æ¯ 2 ç§’\n",
    "        await asyncio.sleep(2) \n",
    "    \n",
    "    return all_questions\n",
    "\n",
    "eval_dataset = await batch_generate_questions(all_nodes=selected_nodes[:10], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b645a-7378-4d2d-ab11-e2cb9bbe1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad26e4-500f-4358-860a-5b49efa32045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.dataset_generation import  QueryResponseDataset\n",
    "\n",
    "combined_queries = {}\n",
    "combined_responses = {}\n",
    "\n",
    "for ds in eval_dataset:\n",
    "    # å°‡æ¯å€‹ dataset çš„å­—å…¸åˆä½µåˆ°ç¸½å­—å…¸ä¸­\n",
    "    combined_queries.update(ds.queries)\n",
    "    combined_responses.update(ds.responses)\n",
    "    \n",
    "# å›å‚³ä¸€å€‹å…¨æ–°çš„ Dataset ç‰©ä»¶\n",
    "final_dataset = QueryResponseDataset(\n",
    "    queries=combined_queries,\n",
    "    responses=combined_responses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aba5cc-fbcd-4c1f-a2f3-3a8377cb2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.qr_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c636d-b85c-4320-a217-79c55a8c5a65",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "| Evaluator          | è©•ä¼°é‡é»    | æ˜¯å¦éœ€è¦åƒè€ƒç­”æ¡ˆ | æ˜¯å¦ä½¿ç”¨ Context |\n",
    "| ------------------ | ------- | -------- | ------------ |\n",
    "| Correctness        | æ˜¯å¦æ­£ç¢º    | éœ€è¦       | ä¸ä¸€å®š          |\n",
    "| SemanticSimilarity | èªæ„æ˜¯å¦ç›¸ä¼¼  | éœ€è¦       | ä¸ä¸€å®š          |\n",
    "| Relevancy          | æ˜¯å¦å›ç­”å•é¡Œ  | ä¸éœ€è¦      | ä¸éœ€è¦          |\n",
    "| Faithfulness       | æ˜¯å¦å¿ å¯¦æ–¼è³‡æ–™ | ä¸éœ€è¦      | éœ€è¦           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed18314-cbac-46bd-be02-7a1c10530c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.core.evaluation import CorrectnessEvaluator, SemanticSimilarityEvaluator, RelevancyEvaluator, FaithfulnessEvaluator\n",
    "\n",
    "evaluator_c = CorrectnessEvaluator(llm=ollama_llm)\n",
    "evaluator_s = SemanticSimilarityEvaluator(embed_model=embed_model)\n",
    "evaluator_r = RelevancyEvaluator(llm=ollama_llm)\n",
    "evaluator_f = FaithfulnessEvaluator(llm=ollama_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf54a1-69b1-4b2c-bebf-c12c4a09f9a5",
   "metadata": {},
   "source": [
    "å»ºç«‹query_engine\n",
    "\n",
    "ç•¶ä½ å‘¼å« as_query_engine æ™‚å‚³å…¥ llm å’Œ embed_modelï¼Œé€™æœƒè¦†è“‹æ‰ï¼ˆOverrideï¼‰ç•¶åˆåœ¨å»ºç«‹ qdrant_index æ™‚è¨­å®šçš„å…¨åŸŸæˆ–ç´¢å¼•å±¤ç´šçš„ç‰©ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff765d0a-7254-47b0-8deb-c5c77b26be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_query_engine = qdrant_index.as_query_engine(similarity_top_k=5,\n",
    "                                                   response_mode=\"compact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864440b-a28b-4997-8a24-55a785d76e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.eval_utils import get_responses, get_results_df\n",
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "eval_qs = final_dataset.questions\n",
    "qr_pairs = final_dataset.qr_pairs\n",
    "ref_response_strs = [r for (_, r) in qr_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee1cf3-b67e-407b-ad47-4c85ed8b87c4",
   "metadata": {},
   "source": [
    "å¯¦é©—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebeaf5-d5e1-4158-bc8a-7873c17af77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_responses = get_responses(eval_qs[:2], qdrant_query_engine, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad098feb-08de-4035-bf50-6f5c571ec8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_responses[0].source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7055d3-e769-42ae-8c53-655dbc6e1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_dict = {\n",
    "    \"correctness\": evaluator_c,\n",
    "    \"faithfulness\": evaluator_f,\n",
    "    \"relevancy\": evaluator_r,\n",
    "    \"similarity\": evaluator_s\n",
    "}\n",
    "\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa2dc4-7a7c-4552-99c7-f91b300ec11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = await batch_runner.aevaluate_responses(\n",
    "    eval_qs[:2], # å•é¡Œ \n",
    "    responses=pred_responses, # å›æ‡‰ \n",
    "    reference=ref_response_strs[:2] # `æ¨™æº–ç­”æ¡ˆ`\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd86fe-4197-4957-ba50-b4d6a2cc2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(\n",
    "    [eval_results],\n",
    "    names=[\"Qdrant\"],\n",
    "    metric_keys=['correctness', 'faithfulness', 'relevancy', 'similarity']\n",
    ")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38791186-a0c0-441b-a732-cc8096f9a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[\"correctness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139fd082-c173-41f0-94cb-6260572bd4b9",
   "metadata": {},
   "source": [
    "## åŸºæ–¼é—œè¯çš„ç¯€é»è§£æå™¨ (Relation-Based Node Parsers)\n",
    "\n",
    "### HierarchicalNodeParser\n",
    "\n",
    "æ­¤ç¯€é»è§£æå™¨æœƒå°‡ç¯€é»åˆ‡åˆ†æˆ **éšå±¤å¼ç¯€é»ï¼ˆhierarchical nodesï¼‰**ã€‚  \n",
    "ä¹Ÿå°±æ˜¯èªªï¼Œå–®ä¸€è¼¸å…¥æœƒè¢«åˆ‡åˆ†æˆå¤šå€‹ä¸åŒå¤§å°çš„éšå±¤ï¼Œæ¯å€‹ç¯€é»éƒ½æœƒåŒ…å«å°å…¶ **çˆ¶ç¯€é»** çš„åƒè€ƒã€‚\n",
    "\n",
    "ç•¶èˆ‡ `AutoMergingRetriever` çµåˆä½¿ç”¨æ™‚ï¼Œé€™å¯ä»¥è®“æˆ‘å€‘åœ¨å¤§å¤šæ•¸å­ç¯€é»è¢«æª¢ç´¢åˆ°æ™‚ï¼Œè‡ªå‹•å°‡æª¢ç´¢åˆ°çš„ç¯€é»æ›¿æ›ç‚ºå…¶çˆ¶ç¯€é»ã€‚  \n",
    "é€™å€‹éç¨‹å¯ä»¥ç‚º LLM æä¾›æ›´å®Œæ•´çš„ä¸Šä¸‹æ–‡ï¼Œæœ‰åŠ©æ–¼ç”Ÿæˆæ›´ç²¾ç¢ºçš„å›ç­”ã€‚\n",
    "\n",
    "#### åƒè€ƒè³‡æ–™\n",
    "- [çŸ¥ä¹å°ˆæ¬„æ–‡ç« ](https://zhuanlan.zhihu.com/p/678698001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0a235-3b01-4fb9-9032-3b1a8b0f2678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ebbc8-765f-40e6-954a-fd51196732ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae252c0-b87b-437a-9cc0-eb6ecafca0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[2048, 512, 128]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348ab93-5873-497e-8702-64cc2109163d",
   "metadata": {},
   "source": [
    "## HierarchicalNodeParser + AutoMergingRetriever ç¯„ä¾‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bcc75-a673-4d69-831a-3e3a8b1ad1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "\n",
    "docs = loader.load(\"08ç‰©ç†.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3d2b0-9c6b-4d86-8108-ee2a7d35a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fdfb7-5860-4284-bdb6-0c4a0f7ff040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8649d9-c74f-40a6-947d-41d68e7c8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20846a6a-2ce0-43c9-a843-20e11ab81f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a3900-1459-4cad-b8dc-cf2f14782741",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ec7f9-10c8-4c88-b830-8b67a19158f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22260c51-9217-4cd6-a238-9fc8f5ee00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "root_nodes = get_root_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08674d96-2f5e-46df-a395-d56b485b89cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce3556-8acc-4f55-8bb7-14979b305084",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(root_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421225d7-a836-430b-9642-c100f2e261e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283a8a4b-0ab4-4ce9-89ed-aeb38a1e5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07545d03-c80f-49cf-8dba-b01be352d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb2fdd-282d-47b8-a586-64625c6a1d36",
   "metadata": {},
   "source": [
    "### Load into Storage\n",
    "æˆ‘å€‘é¦–å…ˆå®šç¾©ä¸€å€‹ **docstore**ï¼Œå°‡æ‰€æœ‰ç¯€é»ï¼ˆnodesï¼‰åŠ è¼‰é€²å»ã€‚\n",
    "\n",
    "æ¥è‘—ï¼Œæˆ‘å€‘å®šç¾©ä¸€å€‹ **VectorStoreIndex**ï¼ŒåªåŒ…å« **è‘‰ç¯€é»ï¼ˆleaf-level nodesï¼‰**ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf62e-d965-4ea3-b4a6-45289a2991a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d03d3-9b59-46cd-9aa7-1649da0db769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# loads https://huggingface.co/BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a746e-660a-419b-b0b3-a35642bff45c",
   "metadata": {},
   "source": [
    "### Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d442f5-b2e8-4c57-9107-6542b1b56ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a62d5-6bbb-4a0b-8563-191b0f53213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe8978-fac3-465a-a8e0-bd90c616c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"åŸå­èˆ‡åŸå­æ ¸çš„çµ„æˆ\"\n",
    "nodes = retriever.retrieve(query_str)\n",
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a457ff7-a782-441c-ac0d-c4cfaf3c3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1015a-7322-4da5-b1d1-e3d96600797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc485dd-b2d9-40b9-b98d-a37000fbdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c942cd9-2151-447d-9b4e-f7235ea6309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\n",
    "base_query_engine = RetrieverQueryEngine.from_args(base_retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb0c2a-964d-4e55-ae0d-5aeab9e5e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e345ef-6110-41fb-83f8-ddc2b86b0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_response = base_query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4ca28-5687-409a-b83a-8f28c925dd12",
   "metadata": {},
   "source": [
    "### è©•ä¼° (Evaluation)\n",
    "\n",
    "æˆ‘å€‘å°‡ä»¥æ›´ **é‡åŒ–çš„æ–¹å¼** è©•ä¼°éšå±¤å¼æª¢ç´¢å™¨ï¼ˆhierarchical retrieverï¼‰ç›¸è¼ƒæ–¼åŸºæº–æª¢ç´¢å™¨ï¼ˆbaseline retrieverï¼‰çš„æ•ˆæœã€‚\n",
    "\n",
    "> âš ï¸ æ³¨æ„ï¼šé€™å€‹éç¨‹å¯èƒ½èŠ±è²»è¼ƒé«˜æˆæœ¬ã€‚è«‹å°å¿ƒä½¿ç”¨ï¼Œä¸¦æ ¹æ“šé ç®—èª¿æ•´æ¨£æœ¬æ•¸é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7500df2-19af-4ca3-b6d6-a38e1787e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import nest_asyncio\n",
    "\n",
    "\"\"\"\n",
    "nest_asyncio æœƒ æ‰“è£œä¸ï¼ˆpatchï¼‰ ç¾æœ‰çš„äº‹ä»¶å¾ªç’°ï¼Œä½¿å¾— åœ¨å·²ç¶“é‹è¡Œçš„äº‹ä»¶å¾ªç’°ä¸­å¯ä»¥å†æ¬¡åµŒå¥—é‹è¡Œ asyncioã€‚\n",
    "\n",
    "æ›å¥è©±èªªï¼Œå®ƒè®“ä½ åœ¨ Jupyter Notebook è£¡å¯ä»¥é †åˆ©åŸ·è¡Œï¼š\n",
    "\n",
    "asyncio.run()\n",
    "\n",
    "è‡ªå·±å¯«çš„ async å‡½æ•¸\n",
    "\n",
    "å„ç¨®éœ€è¦äº‹ä»¶å¾ªç’°çš„åº«ï¼ˆä¾‹å¦‚ LLM SDKã€WebSocketã€FastAPI çš„æ¸¬è©¦ç­‰ï¼‰\n",
    "\n",
    "è€Œä¸æœƒç¢°åˆ°ã€Œäº‹ä»¶å¾ªç’°å·²ç¶“é‹è¡Œã€çš„éŒ¯èª¤ã€‚\n",
    "\"\"\"\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74a2d2-6de8-4ade-a950-e90c3b67e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator(\n",
    "    root_nodes[:5],\n",
    "    llm=llm,\n",
    "    show_progress=True,\n",
    "    num_questions_per_chunk=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae0d3e-c955-44e7-917b-a8bccd964aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73383-ba1d-4c18-8a61-a6665dcdffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d973ffa-12e4-4807-bd03-e3906aab7acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96b1b0-74de-49f6-b150-42362d5f9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e5ed1-26ec-4641-b4aa-510c285ab725",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_nodes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fecef-f1bf-42d3-94ca-a204140efc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"ç‰©ç†_eval_qr_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa32b0-4798-4e0e-8800-15947937d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "# eval_dataset = QueryResponseDataset.from_json(\n",
    "#     \"ç‰©ç†_eval_qr_dataset.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d07fe1-13a6-4d03-83a0-ff95f6da5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.core.evaluation import (\n",
    "    CorrectnessEvaluator,\n",
    "    SemanticSimilarityEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    FaithfulnessEvaluator,\n",
    "    PairwiseComparisonEvaluator,\n",
    ")\n",
    "\n",
    "\n",
    "# NOTE: can uncomment other evaluators\n",
    "evaluator_c = CorrectnessEvaluator(llm=llm)\n",
    "# evaluator_s = SemanticSimilarityEvaluator(llm=eval_llm)\n",
    "evaluator_r = RelevancyEvaluator(llm=llm)\n",
    "evaluator_f = FaithfulnessEvaluator(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23275517-0bce-4974-be2f-e190e6b8e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import RelevancyEvaluator\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\"\"\"\n",
    "Despite the name, RelevancyEvaluator in current LlamaIndex versions is primarily answering:\n",
    "\n",
    "â€œIs the response relevant to the query given the provided context?â€\n",
    "\"\"\"\n",
    "\n",
    "evaluator = RelevancyEvaluator(llm=llm)\n",
    "\n",
    "result = evaluator.evaluate(\n",
    "    query=\"What is photosynthesis?\",\n",
    "    response=\"Photosynthesis is the process by which plants convert sunlight into energy.\",\n",
    "    contexts = [\n",
    "    \"Photosynthesis is a biological process where plants use sunlight to synthesize food from carbon dioxide and water.\"\n",
    "]\n",
    ")\n",
    "\n",
    "print(result.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec49ed4-7f60-4ea6-a446-a29354e65b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.eval_utils import (\n",
    "    get_responses,\n",
    "    get_results_df,\n",
    ")\n",
    "from llama_index.core.evaluation import BatchEvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d3a3c-aca6-49c4-a30a-e2e483ff4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qs = eval_dataset.questions\n",
    "qr_pairs = eval_dataset.qr_pairs\n",
    "ref_response_strs = [r for (_, r) in qr_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2d63e-1855-4338-8d14-204409442550",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222461d-9b1c-47d8-a5b5-c49640084761",
   "metadata": {},
   "outputs": [],
   "source": [
    "qr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a289568-ad66-450b-a038-6e054d5897cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_responses = get_responses(eval_qs, query_engine, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c5b2a0-a08d-4a57-974d-03e0ffd1a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred_responses = get_responses(\n",
    "    eval_qs, base_query_engine, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0809b484-9cf7-453a-9240-988ddf6c009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_response_strs = [str(p) for p in pred_responses]\n",
    "base_pred_response_strs = [str(p) for p in base_pred_responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ac590-191f-4cf3-8a59-6ea76d9c9783",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(pred_responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d08018-3ae9-4167-a775-2875d66534dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_dict = {\n",
    "    \"correctness\": evaluator_c,\n",
    "    \"faithfulness\": evaluator_f,\n",
    "    \"relevancy\": evaluator_r,\n",
    "}\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c588f-815c-493b-94c8-be6ab49def5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = await batch_runner.aevaluate_responses(\n",
    "    eval_qs, responses=pred_responses, reference=ref_response_strs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a746d1e-2d1f-4886-a7c4-2b65e60e5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_eval_results = await batch_runner.aevaluate_responses(\n",
    "    eval_qs, responses=base_pred_responses, reference=ref_response_strs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928745c-4d3e-44f0-b6dc-27b6d870ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_results_df(\n",
    "    [eval_results, base_eval_results],\n",
    "    [\"Auto Merging Retriever\", \"Base Retriever\"],\n",
    "    [\"correctness\", \"relevancy\"],\n",
    ")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de018d-1716-4f5d-99ed-b0dafbc9c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_response_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df927c0c-ea08-421b-9dbe-2e768dd7a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for base_eval_result, eval_result, reference_result in zip(base_eval_results['correctness'], eval_results['correctness'], ref_response_strs):\n",
    "    if base_eval_result.score > eval_result.score:\n",
    "        print(\"\\n******\")\n",
    "        print(f\"query: {base_eval_result.query}\")\n",
    "        print(f\"reference: {reference_result}\")\n",
    "        print(\"\\n\")\n",
    "        print(f\"base_eval_result: {base_eval_result.response}, {base_eval_result.score}\")\n",
    "        print(\"\\n\")\n",
    "        print(f\"eval_result: {eval_result.response}, {eval_result.score}\")\n",
    "        print(\"\\n******\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
