{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d66705-1b85-462f-90de-d4176e520fd5",
   "metadata": {},
   "source": [
    "# é€²éšæª¢ç´¢ç­–ç•¥ - Part 4\n",
    "## ReRank\n",
    "\n",
    "### FlagEmbeddingReranker\n",
    "é€™æ˜¯ç”¨æ–¼åœ¨æœ¬åœ°åŸ·è¡Œé–‹æºé‡æ–°æ’åºï¼ˆrerankerï¼‰æ¨¡å‹çš„ **LlamaIndex æ•´åˆé¡åˆ¥**ã€‚\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼š**  \n",
    "å®ƒæ˜¯å° BAAIï¼ˆåŒ—äº¬æ™ºæºäººå·¥æ™ºæ…§ç ”ç©¶é™¢ï¼‰æ¨¡å‹å¥—ä»¶çš„å°è£ã€‚è©²é¡åˆ¥æ¡ç”¨ **Cross-Encoderï¼ˆäº¤å‰ç·¨ç¢¼å™¨ï¼‰æ¶æ§‹**ï¼Œä¹Ÿå°±æ˜¯åŒæ™‚è™•ç†æŸ¥è©¢ï¼ˆqueryï¼‰èˆ‡æ–‡ä»¶ï¼ˆdocumentï¼‰ï¼Œä»¥è¨ˆç®—ã€ŒçœŸæ­£çš„ã€ç›¸é—œæ€§åˆ†æ•¸ï¼Œè€Œä¸æ˜¯æ¯”è¼ƒé å…ˆè¨ˆç®—å¥½çš„å‘é‡ã€‚  \n",
    "\n",
    "**æœ€é©åˆå°è±¡ï¼š**  \n",
    "å¸Œæœ›åœ¨è‡ªæœ‰ç¡¬é«”ï¼ˆGPUï¼‰ä¸ŠåŸ·è¡Œé«˜å“è³ªé‡æ–°æ’åºã€ä¸”ä¸æƒ³æ”¯ä»˜ API å‘¼å«è²»ç”¨çš„é–‹ç™¼è€…ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**BAAI/bge-reranker-large**\n",
    "\n",
    "é€™æ˜¯ç›®å‰å…¨çƒæœ€å—æ­¡è¿çš„é–‹æºé‡æ–°æ’åºæ¨¡å‹ä¹‹ä¸€ã€‚\n",
    "\n",
    "**ä¸»è¦å„ªå‹¢ï¼š**  \n",
    "å®ƒåœ¨ MTEBï¼ˆMassive Text Embedding Benchmarkï¼Œå¤§è¦æ¨¡æ–‡å­—åµŒå…¥åŸºæº–æ¸¬è©¦ï¼‰ä¸­é•·æœŸååˆ—å‰èŒ…ã€‚ã€ŒLargeã€ç‰ˆæœ¬ï¼ˆç´„ 5.6 å„„åƒæ•¸ï¼‰åœ¨è‹±æ–‡èˆ‡ä¸­æ–‡ä»»å‹™ä¸Šéƒ½å…·æœ‰æ¥µé«˜çš„æº–ç¢ºåº¦ã€‚  \n",
    "\n",
    "**å–æ¨ï¼š**  \n",
    "ç”±æ–¼å®ƒæ˜¯ Cross-Encoder æ¶æ§‹ï¼Œå…¶é€Ÿåº¦æ˜é¡¯æ…¢æ–¼åˆå§‹çš„å‘é‡æœå°‹ã€‚å› æ­¤ï¼Œé€šå¸¸åªæœƒå°‡å‰ 10â€“50 ç­†æ–‡ä»¶å‚³å…¥è©²æ¨¡å‹é€²è¡Œé‡æ–°æ’åºã€‚\n",
    "\n",
    "**ç›®å‰ç‹€æ…‹ï¼š**  \n",
    "è¼ƒæ–°çš„ **BGE-Reranker-v2-m3**ï¼ˆè¿‘æœŸç™¼å¸ƒï¼‰åŠŸèƒ½æ›´åŠ å…¨é¢ï¼Œæ”¯æ´å¤šèªè¨€ä¸¦å¯è™•ç†æ¥µé•·çš„ä¸Šä¸‹æ–‡å…§å®¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d6bf2-1a08-40fb-b4cb-579514e72621",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/FlagOpen/FlagEmbedding.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eca919-4216-46da-88b3-785a99803dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "from initialization import credential_init\n",
    "from src.ollama_connection import llama_index_ollama\n",
    "\n",
    "ollama_llm = llama_index_ollama(model=\"gpt-oss:120b-cloud\", temperature=0)\n",
    "\n",
    "credential_init()\n",
    "\n",
    "flag_embedding_reranker = FlagEmbeddingReranker(\n",
    "    top_n=20,\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    "    # å¦‚æœä½ æœ‰ NVIDIA GPUï¼Œå¼·çƒˆå»ºè­°å°‡æ­¤é …è¨­ç‚º Trueã€‚ä½¿ç”¨ FP16ï¼ˆåŠç²¾åº¦ï¼‰å¯ä»¥é¡¯è‘—æ¸›å°‘é¡¯å­˜ä½”ç”¨ä¸¦æå‡æ¨è«–é€Ÿåº¦ï¼Œä¸”å°é‡æ’ç²¾åº¦å½±éŸ¿æ¥µå°ã€‚\n",
    "    use_fp16=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39842c3-1fa2-4f3c-a89f-a71b56bd0c93",
   "metadata": {},
   "source": [
    "<!-- å‘é‡æª¢ç´¢ $top\\_k=50 \\rightarrow$ ç²—é¸ 50 ä»½ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e917114-8f43-4963-a429-aebc76f01610",
   "metadata": {},
   "source": [
    "**RAG æ¶æ§‹ä¸­çš„å…©éšæ®µæª¢ç´¢èˆ‡ `top_n` åƒæ•¸èªªæ˜**\n",
    "\n",
    "åœ¨ **Retrieval-Augmented Generationï¼ˆRAGï¼‰** æ¶æ§‹ä¸­ï¼Œæª¢ç´¢ï¼ˆRetrievalï¼‰é€šå¸¸è¨­è¨ˆç‚ºã€Œå…©å€‹éšæ®µã€ï¼Œè€Œ `top_n` æ˜¯æ§åˆ¶æœ€çµ‚è¼¸å‡ºå“è³ªèˆ‡æˆæœ¬çš„æ ¸å¿ƒåƒæ•¸ã€‚\n",
    "\n",
    "æª¢ç´¢æ¼æ–—ï¼š\n",
    "    \n",
    "å‘é‡æª¢ç´¢ $top\\_k=50 \\rightarrow$ ç²—é¸ 50 ä»½\n",
    "\n",
    "ReRanker $top\\_k=5 \\rightarrow$ ç²¾é¸ 5 ä»½\n",
    "\n",
    "LLM Context $\\rightarrow$ æœ€çµ‚è™•ç† 5 ä»½\n",
    "\n",
    "---\n",
    "\n",
    "**ä¸€ã€å…©éšæ®µæª¢ç´¢æµç¨‹**\n",
    "\n",
    "**ç¬¬ä¸€éšæ®µï¼šåˆç¯©ï¼ˆCandidate Retrievalï¼‰**\n",
    "\n",
    "- å¾å‘é‡è³‡æ–™åº«ä¸­å¿«é€Ÿæ‰¾å›å¤§é‡å€™é¸æ–‡æª”ï¼ˆä¾‹å¦‚ 30ï½100 ä»½ï¼‰\n",
    "- å¸¸ç”¨æ–¹æ³•åŒ…å«ï¼š\n",
    "  - å‘é‡ç›¸ä¼¼åº¦ï¼ˆCosine / Dot Productï¼‰\n",
    "  - ANNï¼ˆApproximate Nearest Neighborï¼‰\n",
    "- ç‰¹æ€§èªªæ˜ï¼š\n",
    "  - å„ªé»ï¼šé€Ÿåº¦å¿«ã€å¯æ“´å±•æ€§é«˜\n",
    "  - ç¼ºé»ï¼šç²¾åº¦è¼ƒä½ï¼Œå¯èƒ½åŒ…å«èªæ„ç›¸ä¼¼ä½†å¯¦éš›ä¸ç›¸é—œçš„æ–‡æª”\n",
    "\n",
    "---\n",
    "\n",
    "**ç¬¬äºŒéšæ®µï¼šé‡æ’ï¼ˆRe-rankingï¼‰**\n",
    "\n",
    "- ä½¿ç”¨ Reranker æ¨¡å‹å°ç¬¬ä¸€éšæ®µçš„å€™é¸æ–‡æª”é€²è¡Œæ·±åº¦èªæ„åˆ†æ\n",
    "- é‡æ–°è¨ˆç®—ã€Œå•é¡Œï¼ˆQueryï¼‰ã€èˆ‡ã€Œæ¯ä¸€ä»½æ–‡æª”ã€ä¹‹é–“çš„ç›¸é—œæ€§åˆ†æ•¸\n",
    "- ç‰¹æ€§èªªæ˜ï¼š\n",
    "  - å„ªé»ï¼šèªæ„ç†è§£èƒ½åŠ›å¼·ã€æ’åºç²¾æº–\n",
    "  - ç¼ºé»ï¼šè¨ˆç®—æˆæœ¬è¼ƒé«˜ï¼Œå› æ­¤åƒ…ç”¨æ–¼å°‘é‡å€™é¸æ–‡æª”\n",
    "\n",
    "---\n",
    "\n",
    "**äºŒã€`top_n` çš„å®šç¾©**\n",
    "\n",
    "`top_n` ç”¨ä¾†æ±ºå®šï¼š\n",
    "\n",
    "> æœ€çµ‚è¦äº¤çµ¦ LLM ä½œç‚ºä¸Šä¸‹æ–‡ï¼ˆContextï¼‰çš„æ–‡æª”æ•¸é‡\n",
    "\n",
    "**ç¯„ä¾‹èªªæ˜**\n",
    "\n",
    "- ç¬¬ä¸€éšæ®µå–å›ï¼š50 ä»½æ–‡æª”  \n",
    "- ç¶“ Reranker é‡æ–°æ’åºå¾Œ  \n",
    "- è¨­å®š `top_n = 10`  \n",
    "\n",
    "çµæœç‚ºï¼š  \n",
    "åªä¿ç•™ã€Œç›¸é—œæ€§æœ€é«˜çš„å‰ 10 ä»½æ–‡æª”ã€å‚³é€çµ¦ LLM ä½œç‚ºåƒè€ƒä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**ä¸‰ã€ç‚ºä»€éº¼éœ€è¦è¨­å®š `top_n`ï¼Ÿ**\n",
    "\n",
    "**1. ç²¾æº–éæ¿¾**\n",
    "- ç§»é™¤ç¬¬ä¸€éšæ®µä¸­ï¼š\n",
    "  - è¡¨é¢ä¸Šç›¸ä¼¼\n",
    "  - ä½†å¯¦éš›èªæ„ä¸ç›¸é—œçš„é›œè¨Šæ–‡æª”\n",
    "\n",
    "**2. å„ªåŒ–æˆæœ¬**\n",
    "- æ¸›å°‘å‚³é€çµ¦ LLM çš„æ–‡å­—é‡\n",
    "- æœ‰æ•ˆé™ä½ï¼š\n",
    "  - Token ä½¿ç”¨é‡\n",
    "  - æ¨è«–æˆæœ¬\n",
    "  - ç³»çµ±å»¶é²ï¼ˆLatencyï¼‰\n",
    "\n",
    "**3. æå‡ç”Ÿæˆå“è³ª**\n",
    "- é¿å…ä¸Šä¸‹æ–‡éé•·é€ æˆï¼š\n",
    "  - é—œéµè³‡è¨Šè¢«ç¨€é‡‹\n",
    "  - LLM å‡ºç¾ã€Œè³‡è¨Šéºå¿˜ï¼ˆLost in the Middleï¼‰ã€å•é¡Œ\n",
    "\n",
    "---\n",
    "\n",
    "**å››ã€`top_n` è¨­å®šå»ºè­°**\n",
    "\n",
    "| ä½¿ç”¨æƒ…å¢ƒ | å»ºè­° `top_n` |\n",
    "|---------|-------------|\n",
    "| ä¸€èˆ¬å•ç­”ï¼ˆFAQã€å®¢æœï¼‰ | 3 ï½ 5 |\n",
    "| æŠ€è¡“å•é¡Œã€éœ€å¼•ç”¨æ–‡ä»¶ | 5 ï½ 8 |\n",
    "| è¤‡é›œæ¨ç†ã€å¤šä¾†æºæ•´åˆ | 10 ä»¥ä¸Š |\n",
    "\n",
    "æ³¨æ„äº‹é …ï¼š  \n",
    "`top_n` ä¸¦éè¨­å®šå¾—è¶Šå¤§è¶Šå¥½ï¼Œæ‡‰åœ¨ã€Œè³‡è¨Šå®Œæ•´æ€§ã€èˆ‡ã€Œä¸Šä¸‹æ–‡æ•ˆç‡ã€ä¹‹é–“å–å¾—å¹³è¡¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**ç¸½çµ**\n",
    "\n",
    "- ç¬¬ä¸€éšæ®µï¼šå¿«ä½†ä¸ç²¾ï¼Œè² è²¬ã€Œæ‰¾å¾—åˆ°ã€\n",
    "- ç¬¬äºŒéšæ®µï¼šæ…¢ä½†ç²¾ï¼Œè² è²¬ã€Œæ‰¾å¾—æº–ã€\n",
    "- `top_n`ï¼šæ§åˆ¶æœ€çµ‚è¼¸å…¥çµ¦ LLM çš„ã€Œé»ƒé‡‘ä¸Šä¸‹æ–‡æ•¸é‡ã€\n",
    "\n",
    "åˆç†è¨­å®š `top_n`ï¼Œæ˜¯æ‰“é€ é«˜å“è³ªã€ä½æˆæœ¬ RAG ç³»çµ±çš„é—œéµä¹‹ä¸€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6311887-53d2-4d4f-aab0-1415444c916c",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ç¬¬äºŒå‘¨çš„æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea86474-5b4c-4f02-867c-407f854bbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[f for f in glob(\"week_2/data/*.txt\")]).load_data()\n",
    "\n",
    "sentence_splitter_node_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "nodes = sentence_splitter_node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d06c27-79c0-4c3f-bb8c-a6fe70b18b1c",
   "metadata": {},
   "source": [
    "å»ºç«‹VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f976538-122c-4980-b744-52447c853c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "\n",
    "d = 1024 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "callback_manager = CallbackManager([LlamaDebugHandler()])\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "        nodes,\n",
    "        embed_model=embed_model,\n",
    "        storage_context=storage_context,\n",
    "        callback_manager=callback_manager,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c263724-4abd-4113-ade3-68c3d1b51427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index.index_struct.nodes_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879314d7-2d67-4aea-a387-edea3e8f1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=50,\n",
    "    node_postprocessors=[\n",
    "        flag_embedding_reranker\n",
    "    ],\n",
    "    llm=ollama_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbba1c4-a87c-49ba-bca6-9c50bac20700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rerank_response = rerank_query_engine.query(\"è‹±é›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce8aef-659c-440c-9832-e91a91c8d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = rerank_response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9be7c-7777-4a3b-892e-d9ab41ca3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906e04-3a28-4c34-8d23-f8fffcc60ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4046ca-2390-4586-96cf-241724299c5f",
   "metadata": {},
   "source": [
    "### GPTReranker\n",
    "\n",
    "RankGPT æ˜¯ä¸€ç¨®**åˆ—è¡¨å¼é‡æ’åºï¼ˆListwise Rerankingï¼‰**ç­–ç•¥ï¼Œåˆ©ç”¨å¤§å‹èªè¨€æ¨¡å‹ä¾†å°æ–‡ä»¶é€²è¡Œæ’åºã€‚\n",
    "\n",
    "- é‹ä½œåŸç†ï¼š å®ƒä¸¦éé€ä¸€ç‚ºæ–‡ä»¶è©•åˆ†ï¼Œè€Œæ˜¯å°‡æŸ¥è©¢ï¼ˆQueryï¼‰èˆ‡ä¸€æ•´çµ„æ–‡ä»¶åˆ—è¡¨åŒæ™‚è¼¸å…¥è‡³å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä¸¦è©¢å•ï¼šã€Œé€™äº›æ–‡ä»¶ä¸­å“ªäº›æœ€ç›¸é—œï¼Ÿè«‹æŒ‰é †åºè¼¸å‡ºç·¨è™Ÿã€‚ã€\n",
    "- æ ¸å¿ƒå„ªå‹¢ï¼š å®ƒèƒ½ç™¼æ®å‰æ²¿ LLM çš„å®Œæ•´æ¨ç†èƒ½åŠ›ï¼Œæ¯”èµ·å°å‹çš„ç·¨ç¢¼å™¨æ¨¡å‹ï¼ˆEncoder-only modelsï¼‰ï¼Œå®ƒæ›´èƒ½ç†è§£èªæ„ç´°å¾®çš„å·®åˆ¥ã€è¤‡é›œé‚è¼¯ä»¥åŠä½¿ç”¨è€…çš„æ„åœ–ã€‚\n",
    "- æ¬Šè¡¡è€ƒé‡ï¼š æˆæœ¬è¼ƒé«˜ï¼ˆAPI Token æ¶ˆè€—ï¼‰ä¸”å»¶é²è¼ƒé•·ï¼ˆéœ€ç­‰å¾… LLM ç”Ÿæˆçµæœï¼‰ã€‚å®ƒé€šå¸¸è¢«è¦–ç‚ºé«˜æ¨™æº–æª¢ç´¢æµç¨‹ä¸­çš„ã€Œæœ€å¾Œç£¨å…‰ï¼ˆFinal Polishï¼‰ã€æ­¥é©Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63e956-9ea2-437c-b5d0-eaed34712c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.rankgpt_rerank import RankGPTRerank\n",
    "\n",
    "gpt_reranker = RankGPTRerank(llm=ollama_llm, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163904a-9251-4093-b5ea-069bc87c7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=50,\n",
    "    node_postprocessors=[\n",
    "        gpt_reranker\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a429a76-f069-4631-a9c5-4bbba4fc90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_response = rerank_query_engine.query(\"è‹±é›„\")\n",
    "retrieved_nodes = rerank_response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8dff7-9e2b-4306-a717-fb3b040b479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fe11c-9eb1-459d-ae36-0db5172463ba",
   "metadata": {},
   "source": [
    "é™¤äº†é–‹æºçš„ BGE æ–¹æ¡ˆï¼Œè‹¥è¿½æ±‚æ¥µè‡´çš„ç†è§£èƒ½åŠ›æˆ–ä¼æ¥­ç´šçš„ç©©å®šæ€§ï¼Œæˆ‘å€‘å¯ä»¥è€ƒæ…®åŸºæ–¼ LLM çš„ RankGPT æˆ–è¨—ç®¡å‹çš„ Cohere APIã€‚\n",
    "\n",
    "### Cohere Rerank 4\n",
    "\n",
    "Cohere Rerank 4 (æ­£å¼åç¨±ç‚º Rerank v4.0) æ˜¯ Cohere æ–¼ 2025 å¹´åº•æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é‡æ’åºæ¨¡å‹ã€‚èˆ‡å‰ä»£ï¼ˆv3.5ï¼‰ç›¸æ¯”ï¼Œå®ƒåœ¨æ•ˆèƒ½ã€ä¸Šä¸‹æ–‡é•·åº¦å’Œä¼æ¥­ç´šæ‡‰ç”¨ä¸Šéƒ½æœ‰é¡¯è‘—çš„çªç ´ï¼Œè¢«è¦–ç‚ºç›®å‰ç”Ÿç”¢ç’°å¢ƒä¸­æœ€é ˜å…ˆçš„è¨—ç®¡å‹é‡æ’åºè§£æ±ºæ–¹æ¡ˆä¹‹ä¸€ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ Rerank 4 çš„é—œéµç‰¹æ€§ï¼š\n",
    "\n",
    "1. é›™ç‰ˆæœ¬æ¨¡å‹ç­–ç•¥\n",
    "Rerank 4 æ¡å–äº†èˆ‡ LLM é¡ä¼¼çš„ç­–ç•¥ï¼Œæä¾›äº†å…©æ¬¾é‡å°ä¸åŒéœ€æ±‚å„ªåŒ–çš„ç‰ˆæœ¬ï¼š\n",
    "\n",
    "Rerank 4 Pro: æœ€å¼·æ€§èƒ½ç‰ˆæœ¬ï¼Œå°ˆç‚ºè¿½æ±‚æ¥µè‡´æº–ç¢ºåº¦çš„è¤‡é›œä»»å‹™è¨­è¨ˆï¼ˆå¦‚é‡‘èã€æ³•å¾‹ã€é†«ç™‚ï¼‰ã€‚åœ¨å¤šé …åŸºæº–æ¸¬è©¦ä¸­å…¶æ’åå‡ä½å±…å‰äºŒã€‚\n",
    "\n",
    "Rerank 4 Fast: æ•ˆèƒ½å¹³è¡¡ç‰ˆæœ¬ï¼Œåœ¨ç¶­æŒæ¯” v3.5 æ›´é«˜æº–ç¢ºåº¦çš„åŒæ™‚ï¼Œå¤§å¹…é™ä½äº†å»¶é²ï¼ˆç´„æ¯” Pro å¿« 30-40%ï¼‰ï¼Œé©åˆé«˜æµé‡èˆ‡å³æ™‚æ€§éœ€æ±‚ã€‚\n",
    "\n",
    "2. ä¸Šä¸‹æ–‡çª—å£å·¨å¤§é£›èº (32k Tokens)\n",
    "å¾ 4k åˆ° 32kï¼š ç›¸æ¯”å‰ä»£ v3.5 çš„ 4096 tokensï¼ŒRerank 4 çš„ä¸Šä¸‹æ–‡é•·åº¦æå‡äº† 8 å€ã€‚\n",
    "\n",
    "3. å¤šèªè¨€èˆ‡è·¨èªè¨€èƒ½åŠ›\n",
    "æ”¯æŒ 100+ ç¨®èªè¨€ï¼š åœ¨ä¸­æ–‡ã€æ—¥æ–‡ã€å¾·æ–‡ã€é˜¿æ‹‰ä¼¯æ–‡ç­‰ä¸»æµèªè¨€çš„è¡¨ç¾é”åˆ°äº†æ¥­ç•Œé ˜å…ˆæ°´å¹³ã€‚\n",
    "\n",
    "è·¨èªè¨€æª¢ç´¢ï¼š å®ƒèƒ½æ¥µå…¶ç²¾æº–åœ°è™•ç†ã€Œè‹±æ–‡æŸ¥è©¢ã€ä¸­æ–‡æ–‡ä»¶ã€é€™é¡è·¨èªè¨€çš„ç›¸é—œæ€§åŒ¹é…ã€‚\n",
    "\n",
    "4. çµæ§‹åŒ–æ•¸æ“šèˆ‡æ¨ç†èƒ½åŠ›\n",
    "åŸç”Ÿæ”¯æŒ YAML/JSONï¼š å®ƒå¯ä»¥ç›´æ¥å°çµæ§‹åŒ–æ•¸æ“šé€²è¡Œæ’åºï¼Œè€Œä¸åƒ…åƒ…æ˜¯ç´”æ–‡æœ¬ã€‚\n",
    "\n",
    "æ›´å¼·çš„æ¨ç†ï¼š é‡å°éœ€è¦é‚è¼¯æ¨ç†çš„æŸ¥è©¢ï¼ˆä¾‹å¦‚ï¼šéœ€è¦ç¶œåˆå¤šå€‹æ¢ä»¶çš„æœå°‹ï¼‰ï¼ŒRerank 4 çš„ç†è§£èƒ½åŠ›é¡¯è‘—å„ªæ–¼å‚³çµ±çš„ç·¨ç¢¼å™¨æ¨¡å‹ã€‚\n",
    "\n",
    "5. æ˜“æ–¼æ•´åˆ\n",
    "API æ¥å£ï¼š åªéœ€å¹¾è¡Œç¨‹å¼ç¢¼å³å¯æ¥å…¥ï¼ˆæ”¯æ´ LlamaIndexã€LangChain ç­‰æ¡†æ¶ï¼‰ã€‚\n",
    "\n",
    "ç¸½çµä¾†èªªï¼š å¦‚æœæ‚¨æ­£åœ¨é–‹ç™¼ä¸€å€‹ä¼æ¥­ç´š RAG ç³»çµ±ï¼Œä¸”å°å¤šèªè¨€æ”¯æŒã€é•·æ–‡ä»¶è™•ç†æˆ–é‡‘è/é†«ç™‚æ•¸æ“šç²¾æº–åº¦æœ‰å¾ˆé«˜è¦æ±‚ï¼ŒCohere Rerank 4 Pro æ˜¯ç›®å‰çš„æœ€ä½³é¸æ“‡ï¼›å¦‚æœæ‚¨æ›´åœ¨æ„æˆæœ¬èˆ‡å›è¦†é€Ÿåº¦ï¼ŒRerank 4 Fast å‰‡æä¾›äº†æ¥µä½³çš„æ€§åƒ¹æ¯”ã€‚\n",
    "\n",
    "**å¯ä»¥åœ¨ https://cohere.com/ è¨»å†Šä¸€å€‹å¸³è™Ÿï¼Œå–å¾—è©¦ç”¨API KEYã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77466a7e-2ccc-472c-9170-fc1c90b21d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "cohere_reranker = CohereRerank(api_key=os.environ[\"COHERE_API_KEY\"], top_n=10)\n",
    "\n",
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=50,\n",
    "    node_postprocessors=[\n",
    "        cohere_reranker\n",
    "    ],\n",
    "    llm=ollama_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f77ca-c40d-48f6-89bb-c37374d2de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_response = rerank_query_engine.query(\"è‹±é›„\")\n",
    "retrieved_nodes = rerank_response.source_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c8b2f-8a63-42d2-b313-d86e93ed566b",
   "metadata": {},
   "source": [
    "#### ReRank ç­–ç•¥çš„æ¯”è¼ƒè¡¨\n",
    "\n",
    "| æ–¹æ¡ˆ | æˆæœ¬ | é€Ÿåº¦ | é©ç”¨å ´æ™¯ | \n",
    "| --- | --- | --- | --- |\n",
    "| BGE (Local) | å…è²» (éœ€ GPU) | å¿« | éš±ç§è¦æ±‚é«˜ã€é ç®—æœ‰é™ |\n",
    "| RankGPT | é«˜ (API æ¶ˆè€—) | æ…¢ | æ¥µè‡´æº–ç¢ºåº¦ã€é•·æ–‡æœ¬ç†è§£ | \n",
    "| Cohere v4 | ä¸­ (æŒ‰æ¬¡æ”¶è²») | æ¥µå¿« | ä¼æ¥­ç”Ÿç”¢ç’°å¢ƒã€å¤šèªè¨€æ··åˆ |\n",
    "\n",
    "\n",
    "å‰›æ‰æˆ‘å€‘å­¸ç¿’äº†å¦‚ä½•å°ç¾æœ‰çš„çµæœé€²è¡Œã€é‡æ–°æ’åºã€ï¼Œä½†å¦‚æœä¸€é–‹å§‹å‘é‡æœå°‹å°±æ²’æ‰¾å°å…§å®¹ï¼ˆä¾‹å¦‚é—œéµå­—ç²¾ç¢ºåŒ¹é…å¤±æ•—ï¼‰ï¼Œé‚£é‡æ–°æ’åºä¹Ÿæ²’æ•‘ã€‚å› æ­¤ï¼Œæ¥ä¸‹ä¾†æˆ‘å€‘è¦é€²å…¥ Hybrid Retrieverï¼ˆæ··åˆæª¢ç´¢ï¼‰ï¼Œå­¸ç¿’å¦‚ä½•çµåˆå‚³çµ±æœå°‹èˆ‡èªæ„æœå°‹çš„å„ªå‹¢..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08226e36-2203-4f5c-b044-ef4646819ff6",
   "metadata": {},
   "source": [
    "### å¥—ç”¨å¤šå€‹ReRankç­–ç•¥\n",
    "\n",
    "ç‚ºä»€éº¼è¦ä½¿ç”¨ã€Œè¤‡æ•¸ ReRankã€\n",
    "\n",
    "----------------------------\n",
    "\n",
    "ä½¿ç”¨è¤‡æ•¸ ReRankï¼Œæœ¬è³ªä¸Šæ˜¯å°‡æª¢ç´¢èˆ‡æ’åºæ‹†æˆã€Œç”±ç²—åˆ°ç´°ã€çš„å¤šéšæ®µæµç¨‹ï¼Œè®“ç³»çµ±åœ¨æ•ˆç‡ã€æˆæœ¬èˆ‡æº–ç¢ºåº¦ä¹‹é–“å–å¾—æ›´å¥½çš„å¹³è¡¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "1. å…ˆå¿«ç¯©ï¼Œå†ç²¾æ’ï¼ˆæå‡æ•ˆç‡èˆ‡é™ä½æˆæœ¬ï¼‰\n",
    "\n",
    "ç¬¬ä¸€å±¤ ReRank é€šå¸¸ä½¿ç”¨é€Ÿåº¦å¿«ã€æˆæœ¬ä½çš„æ–¹æ³•ï¼Œå…ˆæ’é™¤æ˜é¡¯ä¸ç›¸é—œçš„ç¯€é»ï¼›  \n",
    "å¾ŒçºŒ ReRank å‰‡ä½¿ç”¨è¼ƒç²¾æº–ä½†è¼ƒæ…¢æˆ–è¼ƒæ˜‚è²´çš„æ¨¡å‹ï¼Œå°ˆæ³¨åœ¨å°‘é‡é«˜æ½›åŠ›å…§å®¹ä¸Šã€‚\n",
    "\n",
    "é€™æ¨£å¯ä»¥é¿å…ä¸€é–‹å§‹å°±è®“æ˜‚è²´æ¨¡å‹è™•ç†å¤§é‡ä½å“è³ªè³‡æ–™ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "2. åŒæ™‚å…¼é¡§ Recall èˆ‡ Precision\n",
    "\n",
    "å–®ä¸€ ReRank å¸¸é¢è‡¨å…©é›£ï¼š\n",
    "\n",
    "- top_n è¨­å¤ªå°ï¼Œå®¹æ˜“éæ—©åˆªæ‰çœŸæ­£ç›¸é—œçš„ chunk  \n",
    "- top_n è¨­å¤ªå¤§ï¼Œæ’åºæˆæœ¬é«˜ä¸”é›œè¨Šå¤š  \n",
    "\n",
    "å¤šå±¤ ReRank çš„åšæ³•æ˜¯ï¼š\n",
    "\n",
    "- å‰æ®µä¿ç•™è¼ƒå¤šçµæœï¼Œç¢ºä¿ Recall  \n",
    "- å¾Œæ®µé€æ­¥ç¸®å°ç¯„åœï¼Œæé«˜ Precision  \n",
    "\n",
    "---\n",
    "\n",
    "3. çµåˆä¸åŒæ’åºè¨Šè™Ÿï¼Œçµæœæ›´ç©©å®š\n",
    "\n",
    "ä¸åŒ ReRank é—œæ³¨çš„è¨Šè™Ÿå¯èƒ½ä¸åŒï¼Œä¾‹å¦‚ï¼š\n",
    "\n",
    "- å‘é‡èªæ„ç›¸ä¼¼åº¦  \n",
    "- é—œéµå­—æˆ–è©å½™é‡ç–Š  \n",
    "- å•é¡Œèˆ‡å…§å®¹çš„å›ç­”é©é…åº¦ï¼ˆLLM-based ReRankï¼‰  \n",
    "\n",
    "é€éå¤šå±¤ ReRankï¼Œå¯ä»¥å¾ä¸åŒè§’åº¦åè¦†ç¢ºèªå…§å®¹ç›¸é—œæ€§ï¼Œé™ä½å–®ä¸€æ–¹æ³•èª¤åˆ¤çš„é¢¨éšªã€‚\n",
    "\n",
    "---\n",
    "\n",
    "4. æä¾›æ›´ä¹¾æ·¨çš„ Context çµ¦ LLM\n",
    "\n",
    "ç¶“éå¤šéšæ®µç¯©é¸å¾Œï¼š\n",
    "\n",
    "- ç¯€é»æ•¸é‡æ›´å°‘  \n",
    "- ä¸ç›¸é—œå…§å®¹æ›´å°‘  \n",
    "- Context æ›´é›†ä¸­  \n",
    "\n",
    "é€™èƒ½å¹«åŠ© LLM ç”Ÿæˆæ›´æº–ç¢ºã€è¼ƒå°‘ hallucination çš„å›ç­”ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "ä¸€å¥è©±ç¸½çµ\n",
    "\n",
    "è¤‡æ•¸ ReRank å°±åƒã€Œåˆé¸ â†’ è¤‡é¸ â†’ æ±ºé¸ã€ï¼Œ  \n",
    "ä¸æ˜¯ä¸€æ¬¡å°±åšå‡ºæœ€çµ‚åˆ¤æ–·ï¼Œè€Œæ˜¯é€æ­¥æ”¶æ–‚åˆ°æœ€ç›¸é—œçš„çµæœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fbcce-6977-4934-b5b8-e259c3f66aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e263d-5c0a-48c8-bf62-fe1370915f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "import llama_index.core\n",
    "\n",
    "# å•Ÿå‹•æœ¬åœ°è¿½è¹¤ä¼ºæœå™¨\n",
    "px.launch_app()\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a8298-83f1-4af2-85c8-c9db6ab4808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=50,\n",
    "    node_postprocessors=[\n",
    "        flag_embedding_reranker,\n",
    "        cohere_reranker,\n",
    "        gpt_reranker\n",
    "    ],\n",
    "    llm=ollama_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c2f0a-586c-41be-8bd2-b8c0d8f5e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_response = ensemble_rerank_query_engine.query(\"èª°æ˜¯æœ€å¼·çš„ç¦¿é ­?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492bf38-0213-4419-9757-b8c3897460bb",
   "metadata": {},
   "source": [
    "## Hybrid Retriever\n",
    "\n",
    "ReRank è§£æ±ºçš„æ˜¯ã€æ’ä¸æº–ã€çš„å•é¡Œï¼Œä½†å¦‚æœå‘é‡æª¢ç´¢ä¸€é–‹å§‹å°±ã€æ‰¾ä¸åˆ°ã€ï¼ˆRecall å¬å›ä¸è¶³ï¼‰ï¼Œå‰‡éœ€è¦ Hybrid Retriever ä¾†è£œè¶³ã€‚\n",
    "\n",
    "### BM25\n",
    "\n",
    "ç‚ºäº†è®“å¤§å®¶å°ˆæ³¨æ–¼ BM25 çš„æ©Ÿåˆ¶è€Œéè™•ç†ä¸­æ–‡æ–·è©çš„ç¹ç‘£é…ç½®ï¼Œæ¥ä¸‹ä¾†çš„ Hybrid ç¯„ä¾‹æˆ‘å€‘å…ˆå°‡åˆ‡æ›è‡³è‹±æ–‡è³‡æ–™é›†ï¼ˆTech Companiesï¼‰ã€‚\n",
    "\n",
    "ç„¶å¾Œå†ä¾†å¯¦é©—å¦‚ä½•åŠ å…¥ä¸­æ–‡Tokenization (åƒè€ƒhttps://zhuanlan.zhihu.com/p/1911447708331376894)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c947200-bda9-4c0e-800d-fc4e9537e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "\n",
    "wiki_titles = [\"Anthropic\", \"OpenAI\", \"XAI_(company)\", \"Tesla,_Inc.\"]\n",
    "wiki_metadatas = {\n",
    "    \"Anthropic\": {\n",
    "        \"headquarter\": \"San Francisco\",\n",
    "        \"industry\": \"Artificial intelligence\"\n",
    "    },\n",
    "    \"OpenAI\": {\n",
    "        \"headquarter\": \"San Francisco\",\n",
    "        \"industry\": \"Artificial intelligence\"\n",
    "    },\n",
    "    \"XAI_(company)\": {\n",
    "        \"headquarter\": \"Palo Alto\",\n",
    "        \"industry\": \"Technology\"\n",
    "    },\n",
    "    \"Tesla,_Inc.\": {\n",
    "        \"headquarter\": \"Austin\",\n",
    "        \"industry\": \"Automotive\"\n",
    "    },\n",
    "}\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='AI Tutorial(mengchiehling@gmail.com)', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c6342-c4e1-4969-b0e8-b24c6c603c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in wiki_titles:\n",
    "    page = wiki_wiki.page(title)\n",
    "    wiki_text = page.text\n",
    "\n",
    "    data_path = Path(\"week_4/data\")\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfefdb-d5cf-4f19-88ad-f5b8b0340545",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(input_files=[f for f in glob(\"week_4/data/*.txt\")]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4a2ba-85c3-48be-9a60-a1175017fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# initialize node parser\n",
    "splitter = SentenceSplitter(chunk_size=512)\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999093d6-17bc-46a0-a69c-3ea4632b0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02a64c-1eff-47c2-99cb-e54b876ce5e4",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ BM25Retriever çš„å…©ç¨®æ–¹å¼\n",
    "\n",
    "BM25Retriever å¯ä»¥é€éä¸åŒä¾†æºå»ºç«‹ï¼Œä»¥ä¸‹ä»‹ç´¹å…©ç¨®å¸¸è¦‹åšæ³•ã€‚\n",
    "\n",
    "**æ–¹æ³•ä¸€ï¼šç›´æ¥å¾ nodes å»ºç«‹ BM25Retrieverï¼ˆå¯å­˜å–åˆ°ç£ç¢Ÿï¼‰**\n",
    "\n",
    "é€™ç¨®æ–¹å¼æ˜¯ç›´æ¥ä½¿ç”¨ nodes ä¾†å»ºç«‹ retrieverï¼Œé©åˆè³‡æ–™é‡ä¸å¤§ã€æˆ–ä¸éœ€è¦é ç«¯å„²å­˜çš„æƒ…å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa988cda-37a2-443d-8492-e7483f2f833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# ç›´æ¥å¾ nodes å»ºç«‹ BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    "    # å¯é¸ï¼šè¨­å®š stemmer èˆ‡ stopwords èªè¨€\n",
    "    # ç”¨æ–¼ç§»é™¤åœç”¨è©ä¸¦å°æŸ¥è©¢èˆ‡æ–‡æœ¬åš stemming\n",
    "    # é è¨­èªè¨€ç‚º english\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6e3f0-c110-438c-afe3-2aa13b7817ee",
   "metadata": {},
   "source": [
    "**æ–¹æ³•äºŒï¼šä½¿ç”¨ docstore ç®¡ç† nodesï¼ˆæ”¯æ´é ç«¯å„²å­˜ï¼‰**\n",
    "\n",
    "é€™ç¨®æ–¹å¼æœƒå…ˆå°‡ nodes å­˜å…¥ docstoreï¼Œå†ç”± docstore å»ºç«‹ BM25Retrieverã€‚\n",
    "\n",
    "å„ªé»æ˜¯ docstore å¯ä»¥æ˜¯é ç«¯çš„ï¼Œä¾‹å¦‚ MongoDBã€Redis ç­‰ï¼Œé©åˆå¤§å‹æˆ–åˆ†æ•£å¼ç³»çµ±ã€‚è‹¥è¦çœŸæ­£å¯¦ç¾åˆ†ä½ˆå¼ï¼Œéœ€å°æ¥ RedisDocumentStore æˆ– MongoDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e79b1-a8ff-4f32-a773-84ddbf18fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# å»ºç«‹ docstore ä¸¦åŠ å…¥ nodes\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# å¾ docstore å»ºç«‹ BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    docstore=docstore,\n",
    "    similarity_top_k=5,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d8f4f-c2e0-4dfb-8766-351b68cacd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will retrieve context from specific companies\n",
    "retrieved_nodes = bm25_retriever.retrieve(\n",
    "    \"artiticial intelligence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6a38-ed9b-486f-8d10-556929e766da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fec69-5ecd-4059-8ffd-413fdba426c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1723d3-a949-444c-8110-a671c1218c8a",
   "metadata": {},
   "source": [
    "**ç”¨ StorageContext persist docstore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f5ed3-3879-458f-85fa-4e9321953ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ StorageContext\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=docstore\n",
    ")\n",
    "\n",
    "# Persist åˆ°ç£ç¢Ÿ\n",
    "storage_context.persist(persist_dir=\"week_4/storage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e575aa8-7f89-4bdb-9372-9a7b624e2e0c",
   "metadata": {},
   "source": [
    "**é‡æ–°è¼‰å…¥ï¼ˆloadï¼‰ä¸¦å»ºç«‹ BM25Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0781b7-05f9-40f4-904e-f2c618553b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(\n",
    "    persist_dir=\"week_4/storage\"\n",
    ")\n",
    "\n",
    "docstore = storage_context.docstore\n",
    "\n",
    "# ä½¿ç”¨å·²è¼‰å…¥çš„ docstore å»ºç«‹ BM25Retriever\n",
    "bm25_retriever_loaded = BM25Retriever.from_defaults(\n",
    "    docstore=docstore,\n",
    "    similarity_top_k=5,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")\n",
    "\n",
    "retrieved_nodes = bm25_retriever.retrieve(\n",
    "    \"artiticial intelligence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b26bffa-3ea9-417f-b3c8-61f54de1e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a5554-7a0f-4296-8c68-2c499179c489",
   "metadata": {},
   "source": [
    "### BM25 Retriever + MetadataFiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271734b6-6cd5-4f96-b726-b6ed5f117395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata filters\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilters,\n",
    "    MetadataFilter,\n",
    "    FilterOperator,\n",
    "    FilterCondition,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(\n",
    "            key=\"headquarter\",\n",
    "            value=\"San Francisco\",\n",
    "            operator=FilterOperator.EQ,\n",
    "        )\n",
    "    ],\n",
    "    condition=FilterCondition.AND,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2fb0a-f334-4e58-92ba-8d499c0338d0",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ä¸€å€‹dummy query ä¾†æ¸¬è©¦filtersæ˜¯å¦æˆåŠŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f03fb-0f83-44d9-8010-55e33a669a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = BM25Retriever.from_defaults(\n",
    "    docstore=docstore,\n",
    "    similarity_top_k=3,\n",
    "    filters=filters,  # Add filters here\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ").retrieve(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019ef66-2104-463f-9202-667dbe975af1",
   "metadata": {},
   "source": [
    "å¯ä»¥æ‹¿ä¾†å˜—è©¦çš„query:\n",
    "\n",
    "**Company Background & Positioning**\n",
    "\n",
    "> Best for testing keyword matching + semantic understanding\n",
    "\n",
    "- What is OpenAI and what is its core mission?\n",
    "- How does Anthropic position itself in the AI safety landscape?\n",
    "- What company is xAI and why was it founded?\n",
    "- What is Tesla primarily known for besides electric vehicles?\n",
    "\n",
    "---\n",
    "\n",
    "**Founders & Key Figures**\n",
    "\n",
    "> Strong keyword signals (names, dates) with semantic reinforcement\n",
    "\n",
    "- Who founded OpenAI and when?\n",
    "- Who are the founders of Anthropic?\n",
    "- What is Elon Muskâ€™s involvement in xAI?\n",
    "- How is Elon Musk connected to Tesla?\n",
    "\n",
    "---\n",
    "\n",
    "**Mission, Goals, and Philosophy**\n",
    "\n",
    "> Conceptual questions where dense retrieval excels\n",
    "\n",
    "- What does OpenAI mean by artificial general intelligence?\n",
    "- What is Anthropicâ€™s approach to building safe AI systems?\n",
    "- What problem is xAI trying to solve?\n",
    "- What is Teslaâ€™s long-term vision for sustainable energy?\n",
    "\n",
    "---\n",
    "\n",
    "**Products & Technologies**\n",
    "\n",
    "> Hybrid retrieval works especially well for mixed factual + semantic queries\n",
    "\n",
    "- What products or models has OpenAI released?\n",
    "- What is Anthropicâ€™s Claude model?\n",
    "- Does xAI develop large language models?\n",
    "- What technologies does Tesla develop besides cars?\n",
    "\n",
    "---\n",
    "\n",
    "**Comparison Queries**\n",
    "\n",
    "> Ideal for demonstrating QueryFusionRetriever and multi-document reasoning\n",
    "\n",
    "- How is OpenAI different from Anthropic?\n",
    "- Compare the goals of OpenAI and xAI.\n",
    "- How do AI companies like OpenAI and Anthropic differ from Tesla?\n",
    "- Which of these companies focuses on AI safety?\n",
    "\n",
    "---\n",
    "\n",
    "**Advanced / RAG Demo Queries (Recommended)**\n",
    "\n",
    "> Excellent for end-to-end RetrieverQueryEngine demonstrations\n",
    "\n",
    "- Which companies in the documents are focused on artificial intelligence research?\n",
    "- Which organization emphasizes AI safety and alignment?\n",
    "- What companies were founded by Elon Musk?\n",
    "- Summarize the missions of OpenAI, Anthropic, xAI, and Tesla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af901562-d565-4bb4-b552-d27c1e1948b1",
   "metadata": {},
   "source": [
    "### ä¸­æ–‡ Tokenization\n",
    "\n",
    "Byte Pair Encoding (BPE)\n",
    "\n",
    "- pip install jieba\n",
    "\n",
    "åƒè€ƒBlog https://medium.com/seaniap/python-%E4%B8%AD%E6%96%87%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86jieba%E6%96%B7%E8%A9%9E-9ab44a1b6a9d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da300b1e-c10d-4440-8b57-e07be91cb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# https://github.com/fxsjy/jieba/blob/master/extra_dict/dict.txt.big\n",
    "\"\"\"\n",
    "jieba é è¨­ä¸æ”¯æ´ç¹é«”å­—å…¸ï¼Œå»ºè­°åŠ å…¥ jieba.set_dictionary('dict.txt.big') çš„æç¤ºï¼Œé€™å°å°ç£ä½¿ç”¨è€…æ›´å‹å¥½ã€‚\n",
    "\"\"\"\n",
    "jieba.set_dictionary('week_4/dict.txt.big')\n",
    "\n",
    "# åœ¨ç°¡ä¸­çš„è¡¨ç¾ä¸Šæ¯”ç¹ä¸­è¦å¥½ï¼Œä½†ç›®å‰ä¹Ÿæ²’æ›´å¥½çš„é¸æ“‡\n",
    "\n",
    "# text = \"æ¸…æ™¨çš„é˜³å…‰é€è¿‡çª—å¸˜ï¼Œåœ¨åœ°æ¿ä¸Šæ´’ä¸‹æ–‘é©³çš„å…‰å½±ã€‚\"\n",
    "text = \"æ¸…æ™¨çš„é™½å…‰é€éçª—ç°¾ï¼Œåœ¨åœ°æ¿ä¸Šç‘ä¸‹æ–‘é§çš„å…‰å½±ã€‚\"\n",
    "\n",
    "jieba.lcut_for_search(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5e8cc-2d5f-4a61-8407-e569a25fbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import bm25s\n",
    "from bm25s.tokenization import Tokenized\n",
    "from typing import List, Union, Callable\n",
    "from nltk import corpus\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def tokenize(\n",
    "    texts: Union[str, List[str]],\n",
    "    lower: bool = True,\n",
    "    token_pattern: str = r\"(?u)\\b\\w\\w+\\b\",\n",
    "    stopwords: Union[str, List[str]] = \"zh\",\n",
    "    stemmer: Callable = None,  \n",
    "    return_ids: bool = True,\n",
    "    show_progress: bool = True,\n",
    "    leave: bool = False,\n",
    "    allow_empty: bool = True,\n",
    ") -> Union[List[List[str]], Tokenized]:\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    language_map = {\n",
    "        \"zh\":\"chinese\",\n",
    "        \"en\":\"english\"\n",
    "    }\n",
    "    \n",
    "    if isinstance(stopwords, str):\n",
    "        stopword_list = corpus.stopwords.words(language_map[stopwords])\n",
    "    else:\n",
    "        stopword_list = []\n",
    "        for stopword in stopwords:\n",
    "            stopword_list.extend(corpus.stopwords.words(language_map[stopword]))\n",
    "    corpus_ids = []\n",
    "    token_to_index = {}\n",
    "    for text in tqdm(\n",
    "        texts, desc=\"Split strings\", leave=leave, disable=not show_progress\n",
    "    ):  \n",
    "        if lower:\n",
    "            text = text.lower()\n",
    "\n",
    "        splitted = jieba.lcut_for_search(text)\n",
    "        if allow_empty is False and len(splitted) == 0:\n",
    "            splitted = [\"\"]\n",
    "\n",
    "        doc_ids = []\n",
    "        for token in splitted:\n",
    "            if token in stopword_list:\n",
    "                continue \n",
    "            token_to_index.setdefault(token, len(token_to_index))\n",
    "            doc_ids.append(token_to_index[token])\n",
    "        corpus_ids.append(doc_ids)\n",
    "    if return_ids:\n",
    "        return Tokenized(ids=corpus_ids, vocab=token_to_index)\n",
    "    else:\n",
    "        unique_tokens = list(token_to_index.keys())\n",
    "        for i, token_ids in enumerate(\n",
    "            tqdm(\n",
    "                corpus_ids,\n",
    "                desc=\"Reconstructing token strings\",\n",
    "                leave=leave,\n",
    "                disable=not show_progress,\n",
    "            )\n",
    "        ):\n",
    "            corpus_ids[i] = [unique_tokens[token_id] for token_id in token_ids]\n",
    "\n",
    "        return corpus_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d47545-930f-4d06-bb84-4c499defac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25s.tokenize = tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4ec26-5f0c-467e-8916-cc3b45a6e059",
   "metadata": {},
   "source": [
    "Judgement Day!\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2eaf45-a27e-491e-8ee8-3117659b3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "documents = [\n",
    "    Document(text=\"æ¸…æ™¨çš„é™½å…‰é€éçª—ç°¾ï¼Œåœ¨åœ°æ¿ä¸Šç‘ä¸‹æ–‘é§çš„å…‰å½±ã€‚\"),\n",
    "    Document(text=\"è¡—è§’çš„å’–å•¡åº—é£„ä¾†é™£é™£é¦™æ°£ï¼Œå¼•å¾—è·¯äººé »é »é§è¶³ã€‚\"),\n",
    "    Document(text=\"å¥¹ç¿»é–‹ç›¸å†Šï¼ŒæŒ‡å°–è¼•è¼•æ‘©æŒ²è‘—æ³›é»ƒçš„ç…§ç‰‡ç‰‡æ®µã€‚\"),\n",
    "    Document(text=\"ä¸€åªè²“æ‡¶æ´‹æ´‹åœ°è¶´åœ¨çª—å°ä¸Šï¼Œçœ¯è‘—çœ¼æ‰“é‡éå¾€çš„è¡Œäººã€‚\")\n",
    "]\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=2,\n",
    "    # tokenizer=chinese_tokenize,\n",
    "    language='zh'\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"é™½å…‰\")\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472be930-3aeb-4e23-86c4-3a25c084a21c",
   "metadata": {},
   "source": [
    "## æ··åˆå¼æª¢ç´¢å™¨ (QueryFusionRetriever)\n",
    "\n",
    "æ··åˆå¼æª¢ç´¢å™¨çµåˆäº† BM25 èˆ‡å‘é‡æª¢ç´¢ï¼ˆå¦‚ FAISSï¼‰çš„å„ªé»ï¼Œèƒ½æœ‰æ•ˆå½Œè£œå½¼æ­¤çš„é™åˆ¶ï¼š\n",
    "\n",
    "- **æå‡å¬å›ç‡ï¼ˆRecallï¼‰**\n",
    "  - BM25 æ“…é•·ç²¾ç¢ºçš„é—œéµå­—æ¯”å°\n",
    "  - FAISS æ“…é•·æ•æ‰èªæ„ç›¸è¿‘ä½†ç”¨è©ä¸åŒçš„å…§å®¹\n",
    "  - å…©è€…çµåˆèƒ½æ‰¾å›æ›´å¤šã€ŒçœŸæ­£ç›¸é—œã€çš„æ–‡ä»¶\n",
    "\n",
    "- **å…¼é¡§èªæ„èˆ‡é—œéµå­—ç²¾æº–åº¦**\n",
    "  - å°æ–¼å°ˆæœ‰åè©ã€æ•¸å­—ã€ç¨‹å¼ç¢¼ç­‰ï¼ŒBM25 è¡¨ç¾è¼ƒä½³\n",
    "  - å°æ–¼èªæ„ç›¸ä¼¼ã€åŒç¾©æ”¹å¯«çš„æŸ¥è©¢ï¼Œå‘é‡æª¢ç´¢æ›´æœ‰å„ªå‹¢\n",
    "\n",
    "- **é™ä½å–®ä¸€æª¢ç´¢æ–¹å¼çš„ç›²é»**\n",
    "  - åƒ…ä½¿ç”¨ BM25 å¯èƒ½å¿½ç•¥èªæ„ç›¸é—œä½†æœªå‡ºç¾é—œéµå­—çš„å…§å®¹\n",
    "  - åƒ…ä½¿ç”¨å‘é‡æª¢ç´¢å¯èƒ½åœ¨ç²¾ç¢ºå­—è©åŒ¹é…ä¸Šè¡¨ç¾ä¸è¶³\n",
    "\n",
    "- **é€é Query Fusion æå‡æ’åºå“è³ª**\n",
    "  - QueryFusionRetriever å¯ä»¥å°‡å¤šç¨®æª¢ç´¢çµæœåŠ æ¬Šã€èåˆèˆ‡é‡æ–°æ’åº\n",
    "  - æä¾›æ›´ç©©å®šä¸”é«˜å“è³ªçš„æœ€çµ‚çµæœ\n",
    "\n",
    "---\n",
    "\n",
    "**Hybrid Retrieverï¼ˆBM25 + Semantic Searchï¼‰** æ˜¯ä¸€ç¨®åŒæ™‚çµåˆ  \n",
    "ğŸ‘‰ **é—œéµå­—ç²¾æº–åŒ¹é…** èˆ‡  \n",
    "ğŸ‘‰ **èªæ„ç†è§£èƒ½åŠ›** çš„æª¢ç´¢ç­–ç•¥ã€‚\n",
    "\n",
    "é€é **QueryFusionRetriever** å°‡çµæœæ•´åˆå¾Œï¼Œå†æ­é… **RetrieverQueryEngine**ï¼Œ  \n",
    "å¯ä»¥æ‰“é€ å‡ºæ›´æº–ç¢ºã€æ›´å¥å£¯ã€ä¹Ÿæ›´é©åˆå¯¦å‹™æ‡‰ç”¨çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»çµ±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb26fc4-c14d-46ec-8e04-f0e4841823e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af00e4b-ba3f-49e8-a1e9-58db9cb65fc0",
   "metadata": {},
   "source": [
    "å»ºç«‹èªæ„æª¢ç´¢å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5775a-6a7e-4b14-bbc5-e1496052be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "d = 1024 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[f for f in glob(\"week_2/data/*.txt\")]).load_data()\n",
    "\n",
    "# initialize node parser\n",
    "splitter = SentenceSplitter(chunk_size=512)\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2e4c9-c695-4424-b0c6-a7bed08f6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9d9fe-91f3-46b6-a872-4b5e58ddfc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "\n",
    "callback_manager = CallbackManager([LlamaDebugHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6279b-fab4-474f-a183-d9ac15c82076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex(nodes=nodes, \n",
    "                         storage_context=storage_context,\n",
    "                         callback_manager=callback_manager,\n",
    "                         embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d3c3e-bfac-42dc-af15-10ffef930fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s\n",
    "import jieba\n",
    "\n",
    "from src.ollama_connection import llama_index_ollama\n",
    "from src.tokenizer import chinese_tokenize\n",
    "\n",
    "jieba.set_dictionary('week_4/dict.txt.big')\n",
    "bm25s.tokenize = chinese_tokenize\n",
    "\n",
    "ollama_llm = llama_index_ollama(model=\"gpt-oss:120b-cloud\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b9f0e2-61fd-4b91-abd4-2cd96baf53b7",
   "metadata": {},
   "source": [
    "å¿«é€Ÿæ¸¬è©¦ BM25 æ˜¯å¦æ­£å¸¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f640b2-2655-4b1f-8c7a-d647714e2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "documents = [\n",
    "    Document(text=\"æ¸…æ™¨çš„é™½å…‰é€éçª—ç°¾ï¼Œåœ¨åœ°æ¿ä¸Šç‘ä¸‹æ–‘é§çš„å…‰å½±ã€‚\"),\n",
    "    Document(text=\"è¡—è§’çš„å’–å•¡åº—é£„ä¾†é™£é™£é¦™æ°£ï¼Œå¼•å¾—è·¯äººé »é »é§è¶³ã€‚\"),\n",
    "    Document(text=\"å¥¹ç¿»é–‹ç›¸å†Šï¼ŒæŒ‡å°–è¼•è¼•æ‘©æŒ²è‘—æ³›é»ƒçš„ç…§ç‰‡ç‰‡æ®µã€‚\"),\n",
    "    Document(text=\"ä¸€åªè²“æ‡¶æ´‹æ´‹åœ°è¶´åœ¨çª—å°ä¸Šï¼Œçœ¯è‘—çœ¼æ‰“é‡éå¾€çš„è¡Œäººã€‚\")\n",
    "]\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=2,\n",
    "    # tokenizer=chinese_tokenize,\n",
    "    language='zh'\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"é™½å…‰\")\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889a723-540b-4ed9-a69c-d7f8529011d5",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ QueryFusionRetriever æ•´åˆ å…©å€‹ä¸åŒçš„æª¢ç´¢å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac10cb-42f3-4bb2-9060-97a7b1a93fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [\n",
    "        index.as_retriever(similarity_top_k=2),\n",
    "        BM25Retriever.from_defaults(\n",
    "            docstore=index.docstore, similarity_top_k=2,\n",
    "            language='zh'\n",
    "        ),\n",
    "    ],\n",
    "    num_queries=1,\n",
    "    use_async=True,\n",
    "    llm=ollama_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb6fc0-be38-407d-a2a7-420bb0e29d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"è‰å¸½æµ·è³Šåœ˜çš„äººå“¡æœ‰å“ªäº›?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534d5e4-d792-4759-8634-1393140372e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680dda96-273f-47ea-9099-944dcc6878b1",
   "metadata": {},
   "source": [
    "**num_queries**ï¼š\n",
    "\n",
    "åœ¨é€™å€‹æ­¥é©Ÿä¸­ï¼Œæˆ‘å€‘æœƒå°‡å¤šå€‹ç´¢å¼•èåˆæˆä¸€å€‹å–®ä¸€çš„æª¢ç´¢å™¨ï¼ˆretrieverï¼‰ã€‚é€™å€‹æª¢ç´¢å™¨åŒæ™‚ä¹Ÿæœƒé€éç”¢ç”Ÿèˆ‡åŸå§‹å•é¡Œç›¸é—œçš„é¡å¤–æŸ¥è©¢ä¾†æ“´å……ï¼ˆaugmentï¼‰ä½ çš„æŸ¥è©¢ï¼Œä¸¦å½™ç¸½æ‰€æœ‰æŸ¥è©¢çš„çµæœã€‚\n",
    "\n",
    "æ­¤è¨­å®šæœƒåŸ·è¡Œ 4 æ¬¡æŸ¥è©¢ï¼šä¸€æ¬¡ä½¿ç”¨ä½ çš„åŸå§‹æŸ¥è©¢ï¼Œä¸¦å¦å¤–ç”¢ç”Ÿ 3 å€‹æ–°çš„æŸ¥è©¢ã€‚\n",
    "\n",
    "é è¨­æƒ…æ³ä¸‹ï¼Œå®ƒæœƒä½¿ç”¨ä»¥ä¸‹æç¤ºï¼ˆpromptï¼‰ä¾†ç”¢ç”Ÿé¡å¤–çš„æŸ¥è©¢ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06eacc-b1f5-48b0-adc9-98a22a630d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QUERY_GEN_PROMPT = (\n",
    "    \"You are a helpful assistant that generates multiple search queries based on a \"\n",
    "    \"single input query. Generate {num_queries} search queries, one on each line, \"\n",
    "    \"related to the following input query:\\n\"\n",
    "    \"Query: {query}\\n\"\n",
    "    \"Queries:\\n\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57856f59-e0bf-4bf2-bbf8-14bb17b3f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QueryFusionRetriever(\n",
    "    [\n",
    "        index.as_retriever(similarity_top_k=2),\n",
    "        BM25Retriever.from_defaults(\n",
    "            docstore=index.docstore, similarity_top_k=2,\n",
    "            language='zh'\n",
    "        ),\n",
    "    ],\n",
    "    num_queries=4,\n",
    "    use_async=True,\n",
    "    llm=ollama_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cf2a2-672d-456c-86c9-5e309dea61d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3f5ad60-1d69-422c-a509-22ad949ff48e",
   "metadata": {},
   "source": [
    "#### æ·±åº¦è§£æï¼šå¾å¤šå€‹ç¶­åº¦æ•æ‰èªæ„ï¼ˆRAG-Fusionï¼‰\n",
    "\n",
    "é€™è£¡è¨­ç½®çš„ num_queries å¯¦éš›ä¸Šé«”ç¾äº† RAG-Fusion çš„æ ¸å¿ƒæ€æƒ³ã€‚\n",
    "\n",
    "å…‹æœæŸ¥è©¢çš„ä¸ç¢ºå®šæ€§ï¼šåŸå§‹æŸ¥è©¢å¾€å¾€è¼ƒç‚ºç°¡çŸ­æˆ–æ¨¡ç³Šï¼Œè€Œ RAG-Fusion åˆ©ç”¨ LLM å°‡å–®ä¸€æŸ¥è©¢æ‹†è§£ã€æ”¹å¯«æˆå¤šå€‹ä¸åŒè§’åº¦çš„æœå°‹æŒ‡ä»¤ã€‚\n",
    "\n",
    "å¤šè§’åº¦æª¢ç´¢ï¼šä¾‹å¦‚ï¼Œç•¶ä½¿ç”¨è€…å•ã€Œè‹±é›„ã€æ™‚ï¼ŒLLM å¯èƒ½æœƒç”¢ç”Ÿã€Œè‹±é›„å®šç¾©ã€ã€ã€Œå‹•æ¼«ä¸­çš„è‹±é›„è§’è‰²ã€æˆ–ã€Œè‹±é›„ç›¸é—œåŠ‡æƒ…ã€ç­‰æŸ¥è©¢ï¼Œç¢ºä¿å¾å‘é‡ç©ºé–“ä¸­æª¢ç´¢å‡ºæ›´å…¨é¢çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "æ¶ˆé™¤æ’åºåå·®ï¼šé€éç”¢ç”Ÿå¤šå€‹æŸ¥è©¢ä¸¦é…åˆ Reciprocal Rank Fusion (RRF) æ¼”ç®—æ³•ï¼Œç³»çµ±èƒ½æœ‰æ•ˆæ¸›å°‘å–®ä¸€æª¢ç´¢æ¼”ç®—æ³•å°ç‰¹å®šé—œéµå­—çš„æ’åºåè¦‹ï¼Œä½¿æœ€çµ‚çµæœæ›´å…·é­¯æ£’æ€§ï¼ˆRobustnessï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ace795-133a-4f83-afa7-71140b78f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"è‰å¸½æµ·è³Šåœ˜çš„äººå“¡æœ‰å“ªäº›?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46977413-bbde-45ce-8ead-bdc74dd4594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b32408-d2c9-4be1-b30b-88968b9345dc",
   "metadata": {},
   "source": [
    "å°‡æª¢ç´¢å™¨æ”¾å…¥QueryEngineè£¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdc339-2fad-4c3a-a32d-7eb928d75969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542044bc-80fe-4c9a-bcfe-fbea383d0f6e",
   "metadata": {},
   "source": [
    "Fusion Retriever ä¸­æœ‰ä¸€å€‹åƒæ•¸:\n",
    "\n",
    "mode: llama_index.core.retrievers.fusion_retriever.FUSION_MODES\n",
    "\n",
    "ä¾†çµ¦ä¸åŒæª¢ç´¢å™¨çµ¦å‡ºçš„æ’åä¸­çš„nodesé‡æ–°é€²è¡Œæ··åˆæ’å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413013ed-74ae-41da-83a0-0d4aadcbe938",
   "metadata": {},
   "source": [
    "1. Reciprocal Rerankï¼ˆRRFï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**  \n",
    "FUSION_MODE.RECIPROCAL_RANKï¼ˆé è¨­ï¼‰\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**  \n",
    "é€™æ˜¯ç›®å‰æœ€å¸¸è¦‹ã€ä¹Ÿæœ€å—æ­¡è¿çš„æ–¹æ³•ã€‚  \n",
    "å®ƒä¸æœƒä½¿ç”¨ LLM ä¾†å°æ–‡ä»¶é€²è¡Œè©•åˆ†ï¼Œè€Œæ˜¯é€éä¸€å€‹æ•¸å­¸å…¬å¼ï¼Œæ ¹æ“šæ–‡ä»¶åœ¨å¤šå€‹çµæœæ¸…å–®ä¸­çš„æ’åï¼ˆrankï¼‰ä¾†é‡æ–°æ’åºã€‚\n",
    "\n",
    "**å…¬å¼ï¼ˆFormulaï¼‰**  \n",
    "\n",
    "$score = sum( 1 / (k + rank(d)) )$\n",
    "\n",
    "å…¶ä¸­ k æ˜¯ä¸€å€‹å¸¸æ•¸ï¼ˆé€šå¸¸ç‚º 60ï¼‰ã€‚\n",
    "\n",
    "**é©ç”¨æƒ…å¢ƒï¼ˆBest forï¼‰**  \n",
    "é€šç”¨å‹çš„æ··åˆæœå°‹ï¼ˆHybrid Searchï¼‰ã€‚  \n",
    "ç•¶ä½ å¸Œæœ›åœ¨å‘é‡æœå°‹èˆ‡é—œéµå­—æœå°‹ä¹‹é–“å–å¾—è‰¯å¥½å¹³è¡¡ï¼ŒåŒæ™‚é¿å…é¡å¤–çš„ LLM æˆæœ¬æ™‚ï¼Œéå¸¸é©åˆä½¿ç”¨ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "2. Relative Score Fusionï¼ˆç›¸å°åˆ†æ•¸èåˆï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**  \n",
    "FUSION_MODE.RELATIVE_SCORE\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**  \n",
    "æ­¤æ–¹æ³•ä¸å†é—œæ³¨æ–‡ä»¶çš„æ’åï¼ˆä¾‹å¦‚ç¬¬ 1 åã€ç¬¬ 2 åï¼‰ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨å¯¦éš›çš„ç›¸ä¼¼åº¦åˆ†æ•¸ã€‚  \n",
    "å®ƒæœƒå°‡ä¾†è‡ªä¸åŒæª¢ç´¢å™¨ï¼ˆé€šå¸¸åˆ†æ•¸å°ºåº¦ä¸åŒï¼‰çš„åˆ†æ•¸æ­£è¦åŒ–åˆ° 0 åˆ° 1 çš„ç¯„åœå…§ï¼Œæ¥è‘—å†å°é€™äº›åˆ†æ•¸å–å¹³å‡ã€‚\n",
    "\n",
    "**é©ç”¨æƒ…å¢ƒï¼ˆBest forï¼‰**  \n",
    "ç•¶æª¢ç´¢å™¨æ‰€æä¾›çš„ä¿¡å¿ƒåˆ†æ•¸ï¼ˆconfidence scoreï¼‰æœ¬èº«å°±ç›¸ç•¶å¯é æ™‚ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "3. Distribution-Based Score Fusionï¼ˆåˆ†ä½ˆå¼åˆ†æ•¸èåˆï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**  \n",
    "FUSION_MODE.DIST_BASED_SCORE\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**  \n",
    "é€™æ˜¯ä¸€ç¨®æ›´é€²éšçš„åˆ†æ•¸èåˆæ–¹æ³•ï¼ŒæœƒåŒæ™‚è€ƒæ…®çµæœé›†ä¸­åˆ†æ•¸çš„å¹³å‡å€¼ï¼ˆmeanï¼‰èˆ‡æ¨™æº–å·®ï¼ˆstandard deviationï¼‰ã€‚  \n",
    "é€™æœ‰åŠ©æ–¼è™•ç†ä¸åŒæª¢ç´¢å™¨å¯èƒ½ç”¢ç”Ÿã€Œåˆ†æ•¸éå¸¸é›†ä¸­ã€æˆ–ã€Œåˆ†æ•¸åˆ†ä½ˆéå¸¸åˆ†æ•£ã€çš„æƒ…æ³ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "4. Simple Fusionï¼ˆç°¡å–®èåˆï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**  \n",
    "FUSION_MODE.SIMPLE\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**  \n",
    "é€™æ˜¯ä¸€ç¨®åŸºç¤åšæ³•ï¼Œé€šå¸¸åªæ˜¯å°‡çµæœç›´æ¥ä¸²æ¥ï¼ˆconcatenationï¼‰æˆ–é€²è¡Œç°¡å–®åŠ ç¸½ã€‚  \n",
    "ç›¸è¼ƒæ–¼ RRFï¼Œé€™ç¨®æ–¹æ³•åœ¨å¯¦éš›ç”Ÿç”¢ç’°å¢ƒä¸­è¼ƒå°‘ä½¿ç”¨ï¼Œä½†å¯ç”¨æ–¼æ¸¬è©¦åŸºæº–æ•ˆèƒ½ï¼ˆbaseline performanceï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeef356-4133-4a1c-bcc8-25ddc987cc25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
