{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c0143-1c1f-4a95-b11e-7b3c47612c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ragas langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a53154-43b2-43fe-af7b-763d3db9a483",
   "metadata": {},
   "source": [
    "# RAGAS (Retrieval Augmented Generation Assessment)\n",
    "\n",
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994465f-f54e-40cb-ad27-8dd82c1aaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from ragas.llms import llm_factory\n",
    "from ragas import evaluate, experiment\n",
    "\n",
    "# è¨­å®š API Key\n",
    "from initialization import credential_init\n",
    "credential_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f753c-1bb2-4d2d-b173-af0dde698a78",
   "metadata": {},
   "source": [
    "### RAGAS after v0.4 API\n",
    "\n",
    "LLMé ˜åŸŸçš„APIè®ŠåŒ–çš„å¾ˆå¿«ï¼Œè®Šå¾—ä¸å¿«çš„æ¡†æ¶å¤§æ¦‚éƒ½æ˜¯å¿«è¦æ­»æ‰çš„ã€‚BUCKLE UP~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0031ae-fd3c-48e9-be0f-070538a3423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. æº–å‚™æ¸¬è©¦æ•¸æ“š (åŒå‰)\n",
    "from ragas import Dataset\n",
    "\n",
    "dataset = Dataset(name=\"test_dataset\", backend=\"local/csv\", root_dir=\".\")\n",
    "test_data = [\n",
    "    {\"question\": \"ä»€éº¼æ˜¯ RAG?\", \"answer\": \"RAG æ˜¯æª¢ç´¢å¢å¼·ç”Ÿæˆã€‚\", \"contexts\": [\"RAG çµåˆäº†æª¢ç´¢èˆ‡ç”ŸæˆæŠ€è¡“...\"], \"ground_truth\": \"RAG æ˜¯çµåˆæª¢ç´¢èˆ‡ç”Ÿæˆçš„æŠ€è¡“ã€‚\"},\n",
    "]\n",
    "\n",
    "for sample in test_data:\n",
    "    dataset.append(sample)\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386269b6-255d-45a4-a17c-15997bccdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel\n",
    "from ragas import experiment\n",
    "from ragas.metrics.collections import Faithfulness, AnswerRelevancy\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.embeddings import embedding_factory\n",
    "\n",
    "# --- é—œéµéƒ¨åˆ†ï¼šå®šç¾© LLM ---\n",
    "# é€™è£¡å®šç¾©çš„æ˜¯ã€Œè©•å¯©æ¨¡å‹ã€ï¼Œå»ºè­°ä½¿ç”¨ GPT-4o ä»¥ç²å¾—ç©©å®šçš„è©•åˆ†\n",
    "client = AsyncOpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "embeddings = embedding_factory(\"huggingface\", \"BAAI/bge-m3\")\n",
    "\n",
    "# Define experiment result structure\n",
    "class ExperimentResult(BaseModel):\n",
    "    faithfulness: float\n",
    "    answer_relevancy: float\n",
    "\n",
    "# Create experiment function\n",
    "@experiment(ExperimentResult)\n",
    "async def run_evaluation(row):\n",
    "    faithfulness = Faithfulness(llm=llm)\n",
    "    answer_relevancy = AnswerRelevancy(llm=llm, embeddings=embeddings)\n",
    "    \n",
    "    faith_result = await faithfulness.ascore(\n",
    "        response=row.get(\"answer\"),\n",
    "        retrieved_contexts=row.get(\"contexts\"),\n",
    "        user_input=row.get(\"question\")\n",
    "    )\n",
    "\n",
    "    relevancy_result = await answer_relevancy.ascore(\n",
    "        user_input=row.get(\"question\"),\n",
    "        response=row.get(\"answer\")\n",
    "    )\n",
    "\n",
    "    return ExperimentResult(\n",
    "        faithfulness=faith_result.value,\n",
    "        answer_relevancy=relevancy_result.value\n",
    "    )\n",
    "\n",
    "# Run experiment\n",
    "exp_results = await run_evaluation.arun(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866123e-182f-4a2a-8a35-9fca2c50796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f373e6-2246-4aa3-a7cc-e883edb5318b",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "## å…§å®¹ç²¾æº–åº¦ (Context Precision)å…§å®¹ç²¾æº–åº¦ \n",
    "(Context Precision) æ˜¯ä¸€é …è¡¡é‡æŒ‡æ¨™ï¼Œç”¨æ–¼è©•ä¼°æª¢ç´¢å™¨ï¼ˆRetrieverï¼‰é‡å°çµ¦å®šæŸ¥è©¢æ™‚ï¼Œå°‡æª¢ç´¢å…§å®¹ä¸­ç›¸é—œå€å¡Šï¼ˆRelevant Chunksï¼‰çš„æ’åå„ªæ–¼ç„¡é—œå€å¡Šçš„èƒ½åŠ›ã€‚å…·é«”è€Œè¨€ï¼Œå®ƒè©•ä¼°äº†æª¢ç´¢å…§å®¹ä¸­ç›¸é—œå€å¡Šè¢«ç½®æ–¼æ’åé ‚éƒ¨çš„ç¨‹åº¦ã€‚å…¶è¨ˆç®—æ–¹å¼ç‚ºå…§å®¹ä¸­æ¯å€‹å€å¡Šçš„ Precision@k å¹³å‡å€¼ã€‚Precision@k æ˜¯æŒ‡åœ¨æ’åç¬¬ $k$ ä½æ™‚ï¼Œç›¸é—œå€å¡Šæ•¸é‡èˆ‡æ’åç¬¬ $k$ ä½ç¸½å€å¡Šæ•¸é‡çš„æ¯”ä¾‹ã€‚\n",
    "\n",
    "$$\n",
    "\\text{Context Precision@K} =\n",
    "\\frac{\\sum_{k=1}^{K} \\left(\\text{Precision@k} \\times v_k\\right)}\n",
    "{\\text{Total number of relevant items in the top } K \\text{ results}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Precision@k} =\n",
    "\\frac{\\text{true positives@k}}\n",
    "{\\text{true positives@k} + \\text{false positives@k}}\n",
    "$$\n",
    "\n",
    "The ContextPrecision metric evaluates whether retrieved contexts are useful for answering a question by comparing each context against a reference answer. Use this when you have a reference answer available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a10dc7-1bc9-41ae-8bce-79b2ace26f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.metrics.collections import ContextPrecision\n",
    "\n",
    "# Setup LLM\n",
    "client = AsyncOpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "# Create metric\n",
    "scorer = ContextPrecision(llm=llm)\n",
    "\n",
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\n",
    "        \"The Eiffel Tower is located in Paris.\",\n",
    "        \"The Brandenburg Gate is located in Berlin.\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Context Precision Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e086f-999a-40ee-b011-f3539a6cffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\n",
    "        \"The Brandenburg Gate is located in Berlin.\",\n",
    "        \"The Eiffel Tower is located in Paris.\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Context Precision Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d695ae-620b-4cba-a581-9d4429b3037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"Where is the Eiffel Tower located?\",\n",
    "    reference=\"The Eiffel Tower is located in Paris.\",\n",
    "    retrieved_contexts=[\n",
    "        \"The weather is great today\",\n",
    "        \"The Brandenburg Gate is located in Berlin.\",\n",
    "        \"The Eiffel Tower is located in Paris.\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Context Precision Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9c581-0dda-4768-8610-3ec4e455b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics.collections import ContextPrecision\n",
    "\n",
    "\n",
    "# Define experiment result structure\n",
    "class ExperimentResult(BaseModel):\n",
    "    context_precision: float\n",
    "\n",
    "# Create experiment function\n",
    "@experiment(ExperimentResult)\n",
    "async def run_evaluation(row):\n",
    "    context_precision = ContextPrecision(llm=llm)\n",
    "    \n",
    "    context_precision_result = await context_precision.ascore(\n",
    "        retrieved_contexts=row.get(\"contexts\"),\n",
    "        user_input=row.get(\"question\"),\n",
    "        reference=row.get(\"ground_truth\")\n",
    "    )\n",
    "\n",
    "    return ExperimentResult(\n",
    "        context_precision=context_precision_result.value,\n",
    "    )\n",
    "\n",
    "dataset = Dataset(name=\"test_dataset_context_precision\", backend=\"local/csv\", root_dir=\".\")\n",
    "test_data = [\n",
    "    {\"question\": \"Where is the Eiffel Tower located?\", \"answer\": \"RAG æ˜¯æª¢ç´¢å¢å¼·ç”Ÿæˆã€‚\", \n",
    "     \"contexts\": [\"The weather is great today\", \"The Brandenburg Gate is located in Berlin.\", \"The Eiffel Tower is located in Paris.\"], \n",
    "     \"ground_truth\": \"RAG æ˜¯çµåˆæª¢ç´¢èˆ‡ç”Ÿæˆçš„æŠ€è¡“ã€‚\"},\n",
    "]\n",
    "\n",
    "for sample in test_data:\n",
    "    dataset.append(sample)\n",
    "dataset.save()\n",
    "\n",
    "# Run experiment\n",
    "exp_results = await run_evaluation.arun(dataset, name=\"context_precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7a424-5425-42af-bf4e-3e287daecd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a813e-87ef-497b-9f06-d5df4732c507",
   "metadata": {},
   "source": [
    "## å›ç­”ç›¸é—œæ€§ (Answer Relevance)\n",
    "ç•¶ä¸€å€‹å›ç­”èƒ½ç›´æ¥ä¸”å¦¥å–„åœ°è§£æ±ºåŸå§‹å•é¡Œæ™‚ï¼Œå³è¢«è¦–ç‚ºå…·æœ‰ç›¸é—œæ€§ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘å€‘å°å›ç­”ç›¸é—œæ€§çš„è©•ä¼°ä¸¦ä¸è€ƒæ…®çœŸå¯¦æ€§ (Factuality)ï¼Œè€Œæ˜¯é‡å°å›ç­”å…§å®¹ä¸å®Œæ•´æˆ–åŒ…å«å†—é¤˜ç´°ç¯€çš„æƒ…æ³é€²è¡Œæ‰£åˆ†ã€‚\n",
    "\n",
    "ä½ å¯ä»¥æƒ³åƒæˆå›ç­”æ˜¯å¦å°æ–¼å•é¡Œæœ‰è¶³å¤ çš„é‡å°æ€§ï¼Œå¯ä»¥é¿å…å‡ºç¾é›åŒé´¨è¬›ï¼Œæˆ–æ˜¯å›ç­”æ˜¯å°ˆæ¥­çš„å¹¹è©±ã€‚\n",
    "\n",
    "ç‚ºäº†è¨ˆç®—æ­¤åˆ†æ•¸ï¼Œç³»çµ±æœƒå¼•å°å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰é‡å°ç”Ÿæˆçš„å›ç­”å¤šæ¬¡ç”¢ç”Ÿå°æ‡‰çš„å•é¡Œï¼Œä¸¦æ¸¬é‡é€™äº›ç”Ÿæˆå•é¡Œèˆ‡åŸå§‹å•é¡Œä¹‹é–“çš„å¹³å‡é¤˜å¼¦ç›¸ä¼¼åº¦ (Mean Cosine Similarity)ã€‚å…¶æ ¸å¿ƒç†å¿µåœ¨æ–¼ï¼šå¦‚æœç”Ÿæˆçš„å›ç­”èƒ½æº–ç¢ºè§£æ±ºåˆå§‹å•é¡Œï¼Œé‚£éº¼ LLM æ‡‰è©²èƒ½å¤ å¾è©²å›ç­”ä¸­åå‘ç”Ÿæˆèˆ‡åŸå§‹å•é¡Œä¸€è‡´çš„å•é¡Œã€‚\n",
    "\n",
    "$$\n",
    "\\text{Answer Relevancy} =\n",
    "\\frac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "\\text{cosine similarity}(E_{g_i}, E_o)\n",
    "$$\n",
    "\n",
    "ä»¥ä¸‹ç‚ºç¹é«”ä¸­æ–‡ç¿»è­¯ï¼š\n",
    "\n",
    "ç‚ºäº†è¨ˆç®—ç­”æ¡ˆèˆ‡çµ¦å®šå•é¡Œä¹‹é–“çš„ç›¸é—œæ€§ï¼Œæˆ‘å€‘æ¡ç”¨å…©å€‹æ­¥é©Ÿï¼š\n",
    "\n",
    "### æ­¥é©Ÿä¸€\n",
    "ä½¿ç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰å¾ç”Ÿæˆçš„ç­”æ¡ˆä¸­é€†å‘æ¨å°å‡º **n** å€‹å•é¡Œè®Šé«”ã€‚  \n",
    "ä¾‹å¦‚ï¼Œé‡å°ç¬¬ä¸€å€‹ç­”æ¡ˆï¼ŒLLM å¯èƒ½æœƒç”Ÿæˆä»¥ä¸‹å¯èƒ½çš„å•é¡Œï¼š\n",
    "\n",
    "- å•é¡Œä¸€ï¼šæ³•åœ‹ä½æ–¼æ­æ´²çš„å“ªå€‹å€åŸŸï¼Ÿ\n",
    "- å•é¡ŒäºŒï¼šæ³•åœ‹åœ¨æ­æ´²ä¸­çš„åœ°ç†ä½ç½®æ˜¯ä»€éº¼ï¼Ÿ\n",
    "- å•é¡Œä¸‰ï¼šä½ èƒ½æŒ‡å‡ºæ³•åœ‹ä½æ–¼æ­æ´²çš„å“ªå€‹åœ°å€å—ï¼Ÿ\n",
    "\n",
    "### æ­¥é©ŸäºŒ\n",
    "è¨ˆç®—é€™äº›ç”Ÿæˆå•é¡Œèˆ‡å¯¦éš›å•é¡Œä¹‹é–“çš„å¹³å‡é¤˜å¼¦ç›¸ä¼¼åº¦ã€‚\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "å…¶æ ¸å¿ƒæ¦‚å¿µåœ¨æ–¼ï¼šå¦‚æœç­”æ¡ˆç¢ºå¯¦æ­£ç¢ºå›æ‡‰äº†å•é¡Œï¼Œé‚£éº¼åƒ…æ ¹æ“šè©²ç­”æ¡ˆï¼Œå°±æ¥µæœ‰å¯èƒ½é‡å»ºå‡ºåŸå§‹å•é¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb136b1-3cb1-478e-8511-6fb59b192937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from ragas.metrics.collections import AnswerRelevancy\n",
    "\n",
    "# Setup LLM and embeddings\n",
    "client = AsyncOpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "embeddings = embedding_factory(\"huggingface\", \"BAAI/bge-m3\")\n",
    "\n",
    "# Create metric\n",
    "scorer = AnswerRelevancy(llm=llm, embeddings=embeddings)\n",
    "\n",
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"When was the first super bowl?\",\n",
    "    response=\"The first superbowl was held on Jan 15, 1967\"\n",
    ")\n",
    "print(f\"Answer Relevancy Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0192c97-2933-4d46-8ef4-6d881c54634e",
   "metadata": {},
   "source": [
    "## å¿ å¯¦åº¦ï¼ˆFaithfulnessï¼‰\n",
    "\n",
    "Faithfulness æŒ‡æ¨™ç”¨æ–¼è¡¡é‡å›æ‡‰å…§å®¹èˆ‡æ‰€æª¢ç´¢ä¸Šä¸‹æ–‡ä¹‹é–“åœ¨äº‹å¯¦ä¸Šçš„ä¸€è‡´æ€§ã€‚å…¶åˆ†æ•¸ç¯„åœç‚º 0 åˆ° 1ï¼Œåˆ†æ•¸è¶Šé«˜ä»£è¡¨ä¸€è‡´æ€§è¶Šå¥½ã€‚\n",
    "\n",
    "è‹¥å›æ‡‰ä¸­çš„æ‰€æœ‰ä¸»å¼µéƒ½èƒ½ç”±æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ‰€æ”¯æŒï¼Œå‰‡è©²å›æ‡‰è¢«è¦–ç‚ºæ˜¯å¿ å¯¦çš„ï¼ˆfaithfulï¼‰ã€‚\n",
    "\n",
    "è¨ˆç®—æ–¹å¼å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. è¾¨è­˜å›æ‡‰ä¸­çš„æ‰€æœ‰ä¸»å¼µã€‚\n",
    "2. æª¢æŸ¥æ¯ä¸€é …ä¸»å¼µæ˜¯å¦èƒ½å¾æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸­æ¨è«–å¾—å‡ºã€‚\n",
    "3. ä½¿ç”¨ä»¥ä¸‹å…¬å¼è¨ˆç®—å¿ å¯¦åº¦åˆ†æ•¸ï¼š\n",
    "\n",
    "$$\n",
    "\\text{å¿ å¯¦åº¦åˆ†æ•¸} = \\frac{\\text{å›æ‡‰ä¸­å¯ç”±æª¢ç´¢ä¸Šä¸‹æ–‡æ”¯æŒçš„ä¸»å¼µæ•¸é‡}}{\\text{å›æ‡‰ä¸­çš„ä¸»å¼µç¸½æ•¸}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddffcd-0b9b-41c1-8534-73679b0d68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.metrics.collections import Faithfulness\n",
    "\n",
    "# Setup LLM\n",
    "client = AsyncOpenAI()\n",
    "llm = llm_factory(\"gpt-4o\", client=client)\n",
    "\n",
    "# Create metric\n",
    "scorer = Faithfulness(llm=llm)\n",
    "\n",
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"When was the first super bowl?\",\n",
    "    response=\"The first superbowl was held on Jan 15, 1967\",\n",
    "    retrieved_contexts=[\n",
    "        \"The First AFLâ€“NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles.\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Faithfulness Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f923ed-dc29-4835-a98d-94bdfe0cf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"Where and when was Einstein born?\",\n",
    "    response=\"Einstein was born in Germany, Einstein was born on 1st March 1879.\",\n",
    "    retrieved_contexts=[\n",
    "        \"Albert Einstein (born 14 March 1879) was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time\"\n",
    "    ]\n",
    ")\n",
    "print(f\"Faithfulness Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436232ff-fd54-4de3-8dd9-1f4dc75e3b9c",
   "metadata": {},
   "source": [
    "## å™ªéŸ³æ•æ„Ÿåº¦ï¼ˆNoise Sensitivityï¼‰\n",
    "\n",
    "### ğŸ” ç†è§£ RAGAS ä¸­çš„å™ªéŸ³æ•æ„Ÿåº¦\n",
    "\n",
    "å™ªéŸ³æ•æ„Ÿåº¦ç”¨æ–¼è¡¡é‡ç”Ÿæˆæ¨¡å‹ï¼ˆLLMï¼‰åœ¨é¢å°æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸­**ä¸æ­£ç¢ºæˆ–ä¸ç›¸é—œè³‡è¨Š**æ™‚ï¼Œå—åˆ°å¹²æ“¾çš„ç¨‹åº¦ã€‚ç„¶è€Œï¼Œå¾åŸå§‹ç¢¼çš„å¯¦ä½œå¯ä»¥çœ‹å‡ºï¼Œé€™å€‹æŒ‡æ¨™æ˜¯**å…·æ¢ä»¶æ€§çš„**ï¼Œéœ€è¦è¬¹æ…è§£è®€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 1. é‚è¼¯é‹ç®—ï¼ˆæ‡²ç½°è¨ˆç®—ï¼‰\n",
    "\n",
    "æ ¹æ“š RAGAS çš„å¯¦ä½œæ–¹å¼ï¼Œç­”æ¡ˆä¸­çš„æŸä¸€é …ä¸»å¼µï¼Œåªæœ‰åœ¨**åŒæ™‚æ»¿è¶³ä¸‰å€‹å¸ƒæ—æ¢ä»¶**æ™‚ï¼Œæ‰æœƒè§¸ç™¼ã€Œå™ªéŸ³æ‡²ç½°ï¼ˆNoise Penaltyï¼‰ã€ã€‚\n",
    "\n",
    "å°æ–¼ä¸€å€‹ä¸»å¼µ $c$ï¼Œå…¶æ‡²ç½°å¯è¡¨ç¤ºç‚ºï¼š\n",
    "\n",
    "$$\n",
    "\\text{Penalty}(c) = (\\text{Context} \\cap \\text{GT}) \\wedge (\\text{Context} \\cap \\text{Answer}) \\wedge \\neg \\text{GT}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "\n",
    "- $(\\text{Context} \\cap \\text{GT})$ï¼šä¸Šä¸‹æ–‡å¿…é ˆæ˜¯**ç›¸é—œçš„**ï¼ˆåŒ…å«æ­£ç¢ºç­”æ¡ˆï¼äº‹å¯¦ï¼‰ã€‚\n",
    "- $(\\text{Context} \\cap \\text{Answer})$ï¼šæ¨¡å‹å¿…é ˆå°è©²ä¸Šä¸‹æ–‡ä¿æŒ**å¿ å¯¦**ï¼ˆç­”æ¡ˆç¢ºå¯¦æ˜¯å¾ä¸Šä¸‹æ–‡ä¸­æŠ½å–çš„ï¼‰ã€‚\n",
    "- $\\neg \\text{GT}$ï¼šè©²ä¸»å¼µå¿…é ˆæ˜¯**éŒ¯èª¤çš„**ï¼ˆä¸å­˜åœ¨æ–¼ Ground Truth ä¸­ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 2. ã€Œé›¶åˆ†ã€çš„ç´°å¾®å·®ç•°ï¼ˆZero Score Nuanceï¼‰\n",
    "\n",
    "åˆ†æ•¸ç‚º **0** ä¸¦ä¸ä¸€å®šä»£è¡¨ç³»çµ±è¡¨ç¾å®Œç¾ã€‚ç”±æ–¼ä½¿ç”¨çš„æ˜¯ $\\wedge$ï¼ˆANDï¼‰é‚è¼¯ï¼Œåªè¦éˆæ¢ä¸­çš„**ä»»ä½•ä¸€å€‹æ¢ä»¶ä¸æˆç«‹**ï¼Œæœ€çµ‚åˆ†æ•¸å°±æœƒè®Šæˆ 0ã€‚\n",
    "\n",
    "| å¦‚æœâ€¦â€¦ | çµæœ | åŸå›  |\n",
    "| :--- | :--- | :--- |\n",
    "| **æª¢ç´¢å“è³ªä¸ä½³** | åˆ†æ•¸ = 0 | è‹¥ä¸Šä¸‹æ–‡ä¸åŒ…å« Ground Truthï¼Œã€Œç›¸é—œæ€§ã€æ¢ä»¶ç‚º False |\n",
    "| **æ¨¡å‹ç”¢ç”Ÿå¹»è¦º** | åˆ†æ•¸ = 0 | è‹¥ç­”æ¡ˆä¸åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œã€Œå¿ å¯¦æ€§ã€æ¢ä»¶ç‚º False |\n",
    "| **æ¨¡å‹è¡¨ç¾å®Œç¾** | åˆ†æ•¸ = 0 | è‹¥ç­”æ¡ˆç¬¦åˆ Ground Truthï¼Œã€ŒéŒ¯èª¤æ€§ã€æ¢ä»¶ç‚º False |\n",
    "\n",
    "> **âš ï¸ æ³¨æ„äº‹é …ï¼š**  \n",
    "> è«‹å‹™å¿…å°‡å™ªéŸ³æ•æ„Ÿåº¦èˆ‡ **Context Recallï¼ˆä¸Šä¸‹æ–‡å¬å›ç‡ï¼‰** åŠ **Faithfulnessï¼ˆå¿ å¯¦åº¦ï¼‰** ä¸€ä½µè©•ä¼°ï¼Œä»¥é¿å…å°‡ã€Œ0 åˆ†ã€èª¤åˆ¤ç‚ºæ­£å‘çµæœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c904044-c6a7-4624-9048-1fb8d99207ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics.collections import NoiseSensitivity\n",
    "\n",
    "# Setup LLM\n",
    "client = AsyncOpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "# Create metric\n",
    "scorer = NoiseSensitivity(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4042d0-6a1d-4fa3-be38-b0344d4a25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await scorer.ascore(\n",
    "        user_input=\"What is the Life Insurance Corporation of India (LIC) known for?\",\n",
    "        response=\"The Life Insurance Corporation of India (LIC) is the largest insurance company in India, known for its vast portfolio of investments. LIC contributes to the financial stability of the country.\",\n",
    "        reference=\"The Life Insurance Corporation of India (LIC) is the largest insurance company in India, established in 1956 through the nationalization of the insurance industry. It is known for managing a large portfolio of investments.\",\n",
    "        retrieved_contexts=[\n",
    "            \"The Life Insurance Corporation of India (LIC) was established in 1956 following the nationalization of the insurance industry in India.\",\n",
    "            \"LIC is the largest insurance company in India, with a vast network of policyholders and huge investments.\",\n",
    "            \"As the largest institutional investor in India, LIC manages substantial funds, contributing to the financial stability of the country.\",\n",
    "            \"The Indian economy is one of the fastest-growing major economies in the world, thanks to sectors like finance, technology, manufacturing etc.\"\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Noise Sensitivity Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18c1aaf-83be-432a-8201-306cf5522fe7",
   "metadata": {},
   "source": [
    "## ç­”æ¡ˆæº–ç¢ºåº¦ï¼ˆAnswer Accuracyï¼‰\n",
    "\n",
    "ç­”æ¡ˆæº–ç¢ºåº¦ç”¨æ–¼è¡¡é‡æ¨¡å‹å›æ‡‰èˆ‡çµ¦å®šå•é¡Œä¹‹**åƒè€ƒæ¨™æº–ç­”æ¡ˆï¼ˆGround Truthï¼‰**ä¹‹é–“çš„ä¸€è‡´ç¨‹åº¦ã€‚  \n",
    "æ­¤æŒ‡æ¨™é€éå…©å€‹ç¨ç«‹çš„ã€Œ**LLM-as-a-Judge**ã€æç¤ºé€²è¡Œè©•ä¼°ï¼Œæ¯å€‹æç¤ºéƒ½æœƒå›å‚³ä¸€å€‹è©•åˆ†ï¼ˆ0ã€2 æˆ– 4ï¼‰ã€‚\n",
    "\n",
    "æ¥è‘—ï¼Œè©²æŒ‡æ¨™æœƒå°‡è©•åˆ†è½‰æ›ç‚º \\([0, 1]\\) çš„å€é–“ï¼Œä¸¦å°å…©ä½è©•å¯©çš„åˆ†æ•¸å–å¹³å‡å€¼ã€‚  \n",
    "åˆ†æ•¸è¶Šé«˜ï¼Œè¡¨ç¤ºæ¨¡å‹çš„å›ç­”è¶Šæ¥è¿‘åƒè€ƒç­”æ¡ˆã€‚\n",
    "\n",
    "è©•åˆ†å°æ‡‰æ„ç¾©å¦‚ä¸‹ï¼š\n",
    "\n",
    "- **0** â†’ å›æ‡‰ä¸æ­£ç¢ºï¼Œæˆ–æœªå›ç­”èˆ‡åƒè€ƒç­”æ¡ˆç›¸åŒçš„å•é¡Œã€‚\n",
    "- **2** â†’ å›æ‡‰èˆ‡åƒè€ƒç­”æ¡ˆ**éƒ¨åˆ†ä¸€è‡´**ã€‚\n",
    "- **4** â†’ å›æ‡‰èˆ‡åƒè€ƒç­”æ¡ˆ**å®Œå…¨ä¸€è‡´**ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19034433-4230-4520-8c36-36890227c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.metrics.collections import AnswerAccuracy\n",
    "\n",
    "# Setup LLM\n",
    "client = AsyncOpenAI()\n",
    "llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "\n",
    "# Create metric\n",
    "scorer = AnswerAccuracy(llm=llm)\n",
    "\n",
    "# Evaluate\n",
    "result = await scorer.ascore(\n",
    "    user_input=\"When was Einstein born?\",\n",
    "    response=\"Albert Einstein was born in 1879.\",\n",
    "    reference=\"Albert Einstein was born in 1879.\"\n",
    ")\n",
    "print(f\"Answer Accuracy Score: {result.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458d26f-6ff5-473d-b24d-57bcf253b8c6",
   "metadata": {},
   "source": [
    "## Testset Generation for RAG\n",
    "\n",
    "### Overview\n",
    "In this tutorial, we'll explore the test set generation module in Ragas to create a synthetic test set for a Retrieval-Augmented Generation (RAG)-based question-answering bot. Our goal is to design a Ragas Airline Assistant capable of answering customer queries on various topics, including:\n",
    "\n",
    "- Flight booking\n",
    "- Flight changes and cancellations\n",
    "- Baggage policies\n",
    "- Viewing reservations\n",
    "- Flight delays\n",
    "- In-flight services\n",
    "- Special assistance\n",
    " \n",
    "To make sure our synthetic dataset is as realistic and diverse as possible, we will create different customer personas. Each persona will represent distinct traveler types and behaviors, helping us build a comprehensive and representative test set. This approach ensures that we can thoroughly evaluate the effectiveness and robustness of our RAG model.\n",
    "\n",
    "Source: https://docs.ragas.io/en/v0.4.0/howtos/applications/singlehop_testset_gen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d6b96e-bd1a-4444-8fbb-0d7b9cdd2556",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/datasets/vibrantlabsai/ragas-airline-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc0668-9806-48fb-aa6f-a105506d7a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4cb11-d8cc-44e5-9b88-521763644ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unstructured[md]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc4b89-ca98-4db5-92d7-922e011b39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"ragas-airline-dataset\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.md\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dea98a-d71e-46ef-9281-4f9caf7e5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274e7c2-5f72-43db-a96b-0426e57ea1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "from ragas.llms import llm_factory\n",
    "from ragas.embeddings import embedding_factory\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "generator_llm = llm_factory(\"gpt-4o-mini\", client=client)\n",
    "embeddings = embedding_factory(\"huggingface\", \"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930d200-b105-4a4d-a986-953b7d051257",
   "metadata": {},
   "source": [
    "## Create Knowledge Graph\n",
    "Create a base knowledge graph with the documents\n",
    "\n",
    "ToDo: use the earily version of RAGAS to explain knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba69342-2eec-4426-96ee-02f7e59d2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "\n",
    "kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420e852-555f-4538-b79b-20ff49c91aa5",
   "metadata": {},
   "source": [
    "## Setup the transforms\n",
    "\n",
    "In this tutorial, we create a Single Hop Query dataset using a knowledge graph built solely from nodes. To enhance our graph and improve query generation, we apply three key transformations:\n",
    "\n",
    "- **Headline Extraction**: Uses a language model to extract clear section titles from each document (e.g., â€œAirline Initiated Cancellationsâ€ from flight cancellations.md). These titles isolate specific topics and provide direct context for generating focused questions.\n",
    "- **Headline Splitting**: Divides documents into manageable subsections based on the extracted headlines. This increases the number of nodes and ensures more granular, context-specific query generation.\n",
    "- **Keyphrase Extraction**: Identifies core thematic keyphrases (such as key seating information) that serve as semantic seed points, enriching the diversity and relevance of the generated queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1400c55-cb6d-449b-8d58-c500b7d23244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.transforms import apply_transforms\n",
    "from ragas.testset.transforms import HeadlinesExtractor, HeadlineSplitter, KeyphrasesExtractor\n",
    "\n",
    "headline_extractor = HeadlinesExtractor(llm=generator_llm, max_num=20)\n",
    "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
    "keyphrase_extractor = KeyphrasesExtractor(llm=generator_llm)\n",
    "\n",
    "transforms = [\n",
    "    headline_extractor,\n",
    "    headline_splitter,\n",
    "    keyphrase_extractor\n",
    "]\n",
    "\n",
    "apply_transforms(kg, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de6b78-a45b-40c2-828f-9276cf402024",
   "metadata": {},
   "outputs": [],
   "source": [
    "HeadlinesExtractor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8c4e8-afc3-4413-a36c-916351b31766",
   "metadata": {},
   "source": [
    "## Configuring Personas for Query Generation\n",
    "Personas provide context and perspective, ensuring that generated queries are natural, user-specific, and diverse. By tailoring queries to different user viewpoints, our test set covers a wide range of scenarios:\n",
    "\n",
    "- **First Time Flier**: Generates queries with detailed, step-by-step guidance, catering to newcomers who need clear instructions.\n",
    "- **Frequent Flier**: Produces concise, efficiency-focused queries for experienced travelers.\n",
    "- **Angry Business Class Flier**: Yields queries with a critical, urgent tone to reflect high expectations and immediate resolution demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d085cd5-a27d-4ec1-b6c0-f9f1463b5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.persona import Persona\n",
    "\n",
    "persona_first_time_flier = Persona(\n",
    "    name=\"First Time Flier\",\n",
    "    role_description=\"Is flying for the first time and may feel anxious. Needs clear guidance on flight procedures, safety protocols, and what to expect throughout the journey.\",\n",
    ")\n",
    "\n",
    "persona_frequent_flier = Persona(\n",
    "    name=\"Frequent Flier\",\n",
    "    role_description=\"Travels regularly and values efficiency and comfort. Interested in loyalty programs, express services, and a seamless travel experience.\",\n",
    ")\n",
    "\n",
    "persona_angry_business_flier = Persona(\n",
    "    name=\"Angry Business Class Flier\",\n",
    "    role_description=\"Demands top-tier service and is easily irritated by any delays or issues. Expects immediate resolutions and is quick to express frustration if standards are not met.\",\n",
    ")\n",
    "\n",
    "personas = [persona_first_time_flier, persona_frequent_flier, persona_angry_business_flier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22c7c6-cbd5-4e76-bce0-dd1b851bd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers.single_hop.specific import SingleHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distibution = [\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(llm=generator_llm, property_name=\"headlines\"),\n",
    "        0.5,\n",
    "    ),\n",
    "    (\n",
    "        SingleHopSpecificQuerySynthesizer(\n",
    "            llm=generator_llm, property_name=\"keyphrases\"\n",
    "        ),\n",
    "        0.5,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26731513-8c55-46d4-ba3e-1f88054d0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleHopSpecificQuerySynthesizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e20c7c-6016-4893-8ef4-9a6c7deee8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=embeddings,\n",
    "    knowledge_graph=kg,\n",
    "    persona_list=personas,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e784636-e46b-42f2-a0a6-e24537ad5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestsetGenerator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa97128-4282-4641-85bc-732a9a9e00a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distibution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167e949-5ad3-47b1-b965-3b3703c73501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
