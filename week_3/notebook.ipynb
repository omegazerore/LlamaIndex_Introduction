{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d66705-1b85-462f-90de-d4176e520fd5",
   "metadata": {},
   "source": [
    "# Advanced Retrieval Strategies - ç¬¬äºŒéƒ¨åˆ†\n",
    "## ReRank\n",
    "\n",
    "### FlagEmbeddingReranker\n",
    "é€™æ˜¯ç”¨æ–¼åœ¨æœ¬åœ°åŸ·è¡Œé–‹æºé‡æ–°æ’åºï¼ˆrerankerï¼‰æ¨¡å‹çš„ **LlamaIndex æ•´åˆé¡åˆ¥**ã€‚\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼š**  \n",
    "å®ƒæ˜¯å° BAAIï¼ˆåŒ—äº¬æ™ºæºäººå·¥æ™ºæ…§ç ”ç©¶é™¢ï¼‰æ¨¡å‹å¥—ä»¶çš„å°è£ã€‚è©²é¡åˆ¥æ¡ç”¨ **Cross-Encoderï¼ˆäº¤å‰ç·¨ç¢¼å™¨ï¼‰æ¶æ§‹**ï¼Œä¹Ÿå°±æ˜¯åŒæ™‚è™•ç†æŸ¥è©¢ï¼ˆqueryï¼‰èˆ‡æ–‡ä»¶ï¼ˆdocumentï¼‰ï¼Œä»¥è¨ˆç®—ã€ŒçœŸæ­£çš„ã€ç›¸é—œæ€§åˆ†æ•¸ï¼Œè€Œä¸æ˜¯æ¯”è¼ƒé å…ˆè¨ˆç®—å¥½çš„å‘é‡ã€‚  \n",
    "\n",
    "**æœ€é©åˆå°è±¡ï¼š**  \n",
    "å¸Œæœ›åœ¨è‡ªæœ‰ç¡¬é«”ï¼ˆGPUï¼‰ä¸ŠåŸ·è¡Œé«˜å“è³ªé‡æ–°æ’åºã€ä¸”ä¸æƒ³æ”¯ä»˜ API å‘¼å«è²»ç”¨çš„é–‹ç™¼è€…ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "**BAAI/bge-reranker-large**\n",
    "\n",
    "é€™æ˜¯ç›®å‰å…¨çƒæœ€å—æ­¡è¿çš„é–‹æºé‡æ–°æ’åºæ¨¡å‹ä¹‹ä¸€ã€‚\n",
    "\n",
    "**ä¸»è¦å„ªå‹¢ï¼š**  \n",
    "å®ƒåœ¨ MTEBï¼ˆMassive Text Embedding Benchmarkï¼Œå¤§è¦æ¨¡æ–‡å­—åµŒå…¥åŸºæº–æ¸¬è©¦ï¼‰ä¸­é•·æœŸååˆ—å‰èŒ…ã€‚ã€ŒLargeã€ç‰ˆæœ¬ï¼ˆç´„ 5.6 å„„åƒæ•¸ï¼‰åœ¨è‹±æ–‡èˆ‡ä¸­æ–‡ä»»å‹™ä¸Šéƒ½å…·æœ‰æ¥µé«˜çš„æº–ç¢ºåº¦ã€‚  \n",
    "\n",
    "**å–æ¨ï¼š**  \n",
    "ç”±æ–¼å®ƒæ˜¯ Cross-Encoder æ¶æ§‹ï¼Œå…¶é€Ÿåº¦æ˜é¡¯æ…¢æ–¼åˆå§‹çš„å‘é‡æœå°‹ã€‚å› æ­¤ï¼Œé€šå¸¸åªæœƒå°‡å‰ 10â€“50 ç­†æ–‡ä»¶å‚³å…¥è©²æ¨¡å‹é€²è¡Œé‡æ–°æ’åºã€‚\n",
    "\n",
    "**ç›®å‰ç‹€æ…‹ï¼š**  \n",
    "è¼ƒæ–°çš„ **BGE-Reranker-v2-m3**ï¼ˆè¿‘æœŸç™¼å¸ƒï¼‰åŠŸèƒ½æ›´åŠ å…¨é¢ï¼Œæ”¯æ´å¤šèªè¨€ä¸¦å¯è™•ç†æ¥µé•·çš„ä¸Šä¸‹æ–‡å…§å®¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d6bf2-1a08-40fb-b4cb-579514e72621",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/FlagOpen/FlagEmbedding.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eca919-4216-46da-88b3-785a99803dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.chdir(\"../\")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "# from llama_index.indices.postprocessor import LLMRerank \n",
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "llm = OpenAI(\"gpt-4o-mini\")\n",
    "reranker = FlagEmbeddingReranker(\n",
    "    top_n=10,\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    "    use_fp16=False\n",
    ")\n",
    "# reranker = LLMRerank(choice_batch_size=5, top_n=5, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea86474-5b4c-4f02-867c-407f854bbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "wiki_titles = [\"é‹¼ä¹‹éŠé‡‘è¡“å¸«\", \"ä¸€æ‹³è¶…äºº\", \"ONE_PIECE\", \"æ±äº¬å–°ç¨®\"]\n",
    "wiki_metadatas = {\n",
    "    \"é‹¼ä¹‹éŠé‡‘è¡“å¸«\": {\n",
    "        \"author\": \"è’å·å¼˜\",\n",
    "    },\n",
    "    \"ä¸€æ‹³è¶…äºº\": {\n",
    "        \"author\": \"ONE\",\n",
    "    },\n",
    "    \"ONE_PIECE\": {\n",
    "        \"author\": \"å°¾ç”°æ¦®ä¸€éƒ\",\n",
    "    },\n",
    "    \"æ±äº¬å–°ç¨®\": {\n",
    "        \"author\": \"çŸ³ç”°ç¿ \",\n",
    "    },\n",
    "}\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='AI Tutorial(mengchiehling@gmail.com)', language='zh-tw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a87db-0e3a-402d-9505-0f4a9e42990c",
   "metadata": {},
   "source": [
    "å¾Wikipediaä¸‹è¼‰æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954f6ad-0153-4a45-b4ba-6109a4295a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "data_path = Path(\"week_3/data\")\n",
    "\n",
    "for title in wiki_titles:\n",
    "    page = wiki_wiki.page(title)\n",
    "    wiki_text = page.text\n",
    "\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path /f\"{title}.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(wiki_text)\n",
    "\n",
    "# Load all wiki documents\n",
    "docs_dict = {}\n",
    "for wiki_title in wiki_titles:\n",
    "    doc = SimpleDirectoryReader(\n",
    "        input_files=[data_path/f\"{wiki_title}.txt\"]\n",
    "    ).load_data()[0]\n",
    "\n",
    "    doc.metadata.update(wiki_metadatas[wiki_title])\n",
    "    docs_dict[wiki_title] = doc\n",
    "\n",
    "documents = [docs_dict[wiki_title] for wiki_title in wiki_titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d06c27-79c0-4c3f-bb8c-a6fe70b18b1c",
   "metadata": {},
   "source": [
    "å°‡ä¸Šé€±çš„å…§å®¹copy/pasteä¸‹ä¾†ï¼Œå»ºç«‹VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f976538-122c-4980-b744-52447c853c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "\n",
    "d = 1024 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "callback_manager = CallbackManager([LlamaDebugHandler()])\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    [],\n",
    "    storage_context=storage_context,\n",
    "    transformations=[SentenceSplitter.from_defaults()],\n",
    "    callback_manager=callback_manager,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# add documents to index\n",
    "for wiki_title in wiki_titles:\n",
    "    index.insert(docs_dict[wiki_title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c263724-4abd-4113-ade3-68c3d1b51427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(index.index_struct.nodes_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879314d7-2d67-4aea-a387-edea3e8f1fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=50,\n",
    "    node_postprocessors=[\n",
    "        reranker\n",
    "    ]\n",
    ")\n",
    "\n",
    "basic_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbba1c4-a87c-49ba-bca6-9c50bac20700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rerank_response = rerank_query_engine.query(\"è‹±é›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce8aef-659c-440c-9832-e91a91c8d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = rerank_response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9be7c-7777-4a3b-892e-d9ab41ca3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906e04-3a28-4c34-8d23-f8fffcc60ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48055ba-a8b2-47ce-811f-dfe6045d64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_response = basic_query_engine.query(\"è‹±é›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfd01a3-da5e-47f6-8540-ae7430b32967",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = basic_response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f3c13-2951-429f-bea2-7bed96a3749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4046ca-2390-4586-96cf-241724299c5f",
   "metadata": {},
   "source": [
    "### GPTReranker\n",
    "\n",
    "RankGPT æ˜¯ä¸€ç¨®**åˆ—è¡¨å¼é‡æ’åºï¼ˆListwise Rerankingï¼‰**ç­–ç•¥ï¼Œåˆ©ç”¨å¤§å‹èªè¨€æ¨¡å‹ï¼ˆå¦‚ GPT-4o æˆ– Llama 3ï¼‰ä¾†å°æ–‡ä»¶é€²è¡Œæ’åºã€‚\n",
    "\n",
    "- é‹ä½œåŸç†ï¼š å®ƒä¸¦éé€ä¸€ç‚ºæ–‡ä»¶è©•åˆ†ï¼Œè€Œæ˜¯å°‡æŸ¥è©¢ï¼ˆQueryï¼‰èˆ‡ä¸€æ•´çµ„æ–‡ä»¶åˆ—è¡¨åŒæ™‚è¼¸å…¥è‡³å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä¸¦è©¢å•ï¼šã€Œé€™äº›æ–‡ä»¶ä¸­å“ªäº›æœ€ç›¸é—œï¼Ÿè«‹æŒ‰é †åºè¼¸å‡ºç·¨è™Ÿã€‚ã€\n",
    "- æ ¸å¿ƒå„ªå‹¢ï¼š å®ƒèƒ½ç™¼æ®å‰æ²¿ LLM çš„å®Œæ•´æ¨ç†èƒ½åŠ›ï¼Œæ¯”èµ·å°å‹çš„ç·¨ç¢¼å™¨æ¨¡å‹ï¼ˆEncoder-only modelsï¼‰ï¼Œå®ƒæ›´èƒ½ç†è§£èªæ„ç´°å¾®çš„å·®åˆ¥ã€è¤‡é›œé‚è¼¯ä»¥åŠä½¿ç”¨è€…çš„æ„åœ–ã€‚\n",
    "- æ¬Šè¡¡è€ƒé‡ï¼š æˆæœ¬è¼ƒé«˜ï¼ˆAPI Token æ¶ˆè€—ï¼‰ä¸”å»¶é²è¼ƒé•·ï¼ˆéœ€ç­‰å¾… LLM ç”Ÿæˆçµæœï¼‰ã€‚å®ƒé€šå¸¸è¢«è¦–ç‚ºé«˜æ¨™æº–æª¢ç´¢æµç¨‹ä¸­çš„ã€Œæœ€å¾Œç£¨å…‰ï¼ˆFinal Polishï¼‰ã€æ­¥é©Ÿã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82436ac2-535d-4e94-8d9b-17092b14bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index-postprocessor-rankgpt-rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63e956-9ea2-437c-b5d0-eaed34712c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.rankgpt_rerank import RankGPTRerank\n",
    "\n",
    "reranker = RankGPTRerank(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8163904a-9251-4093-b5ea-069bc87c7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=50,\n",
    "    node_postprocessors=[\n",
    "        reranker\n",
    "    ]\n",
    ")\n",
    "\n",
    "basic_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a429a76-f069-4631-a9c5-4bbba4fc90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_response = rerank_query_engine.query(\"è‹±é›„\")\n",
    "retrieved_nodes = rerank_response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff01ab-bba3-468f-9c8b-e0eb66eb3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7dc976-f6ad-424e-bd83-d6f0ee30a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_response = basic_query_engine.query(\"è‹±é›„\")\n",
    "retrieved_nodes = basic_response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8dff7-9e2b-4306-a717-fb3b040b479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fe11c-9eb1-459d-ae36-0db5172463ba",
   "metadata": {},
   "source": [
    "### Cohere Rerank 4\n",
    "\n",
    "Cohere Rerank 4 (æ­£å¼åç¨±ç‚º Rerank v4.0) æ˜¯ Cohere æ–¼ 2025 å¹´åº•æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é‡æ’åºæ¨¡å‹ã€‚èˆ‡å‰ä»£ï¼ˆv3.5ï¼‰ç›¸æ¯”ï¼Œå®ƒåœ¨æ•ˆèƒ½ã€ä¸Šä¸‹æ–‡é•·åº¦å’Œä¼æ¥­ç´šæ‡‰ç”¨ä¸Šéƒ½æœ‰é¡¯è‘—çš„çªç ´ï¼Œè¢«è¦–ç‚ºç›®å‰ç”Ÿç”¢ç’°å¢ƒä¸­æœ€é ˜å…ˆçš„è¨—ç®¡å‹é‡æ’åºè§£æ±ºæ–¹æ¡ˆä¹‹ä¸€ã€‚\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ Rerank 4 çš„é—œéµç‰¹æ€§ï¼š\n",
    "\n",
    "1. é›™ç‰ˆæœ¬æ¨¡å‹ç­–ç•¥\n",
    "Rerank 4 æ¡å–äº†èˆ‡ LLM é¡ä¼¼çš„ç­–ç•¥ï¼Œæä¾›äº†å…©æ¬¾é‡å°ä¸åŒéœ€æ±‚å„ªåŒ–çš„ç‰ˆæœ¬ï¼š\n",
    "\n",
    "Rerank 4 Pro: æœ€å¼·æ€§èƒ½ç‰ˆæœ¬ï¼Œå°ˆç‚ºè¿½æ±‚æ¥µè‡´æº–ç¢ºåº¦çš„è¤‡é›œä»»å‹™è¨­è¨ˆï¼ˆå¦‚é‡‘èã€æ³•å¾‹ã€é†«ç™‚ï¼‰ã€‚åœ¨å¤šé …åŸºæº–æ¸¬è©¦ä¸­å…¶æ’åå‡ä½å±…å‰äºŒã€‚\n",
    "\n",
    "Rerank 4 Fast: æ•ˆèƒ½å¹³è¡¡ç‰ˆæœ¬ï¼Œåœ¨ç¶­æŒæ¯” v3.5 æ›´é«˜æº–ç¢ºåº¦çš„åŒæ™‚ï¼Œå¤§å¹…é™ä½äº†å»¶é²ï¼ˆç´„æ¯” Pro å¿« 30-40%ï¼‰ï¼Œé©åˆé«˜æµé‡èˆ‡å³æ™‚æ€§éœ€æ±‚ã€‚\n",
    "\n",
    "2. ä¸Šä¸‹æ–‡çª—å£å·¨å¤§é£›èº (32k Tokens)\n",
    "å¾ 4k åˆ° 32kï¼š ç›¸æ¯”å‰ä»£ v3.5 çš„ 4096 tokensï¼ŒRerank 4 çš„ä¸Šä¸‹æ–‡é•·åº¦æå‡äº† 8 å€ã€‚\n",
    "\n",
    "è™•ç†é•·æ–‡ä»¶ï¼š é€™æ„å‘³è‘—å®ƒç¾åœ¨å¯ä»¥ä¸€æ¬¡æ€§ã€Œé–±è®€ã€ç´„ 50 é çš„æ–‡ä»¶ï¼Œè€Œä¸éœ€è¦å°‡æ–‡ä»¶åˆ‡æˆç¢ç‰‡ã€‚é€™å°æ–¼éœ€è¦è·¨ç« ç¯€ç†è§£å…§å®¹çš„ RAG ç³»çµ±ä¾†èªªè‡³é—œé‡è¦ã€‚\n",
    "\n",
    "3. å¤šèªè¨€èˆ‡è·¨èªè¨€èƒ½åŠ›\n",
    "æ”¯æŒ 100+ ç¨®èªè¨€ï¼š åœ¨ä¸­æ–‡ã€æ—¥æ–‡ã€å¾·æ–‡ã€é˜¿æ‹‰ä¼¯æ–‡ç­‰ä¸»æµèªè¨€çš„è¡¨ç¾é”åˆ°äº†æ¥­ç•Œé ˜å…ˆæ°´å¹³ã€‚\n",
    "\n",
    "è·¨èªè¨€æª¢ç´¢ï¼š å®ƒèƒ½æ¥µå…¶ç²¾æº–åœ°è™•ç†ã€Œè‹±æ–‡æŸ¥è©¢ã€ä¸­æ–‡æ–‡ä»¶ã€é€™é¡è·¨èªè¨€çš„ç›¸é—œæ€§åŒ¹é…ã€‚\n",
    "\n",
    "4. çµæ§‹åŒ–æ•¸æ“šèˆ‡æ¨ç†èƒ½åŠ›\n",
    "åŸç”Ÿæ”¯æŒ YAML/JSONï¼š å®ƒå¯ä»¥ç›´æ¥å°çµæ§‹åŒ–æ•¸æ“šé€²è¡Œæ’åºï¼Œè€Œä¸åƒ…åƒ…æ˜¯ç´”æ–‡æœ¬ã€‚\n",
    "\n",
    "æ›´å¼·çš„æ¨ç†ï¼š é‡å°éœ€è¦é‚è¼¯æ¨ç†çš„æŸ¥è©¢ï¼ˆä¾‹å¦‚ï¼šéœ€è¦ç¶œåˆå¤šå€‹æ¢ä»¶çš„æœå°‹ï¼‰ï¼ŒRerank 4 çš„ç†è§£èƒ½åŠ›é¡¯è‘—å„ªæ–¼å‚³çµ±çš„ç·¨ç¢¼å™¨æ¨¡å‹ï¼Œè¡¨ç¾æ›´æ¥è¿‘å°å‹ LLMï¼Œä½†æˆæœ¬èˆ‡é€Ÿåº¦æ›´å„ªã€‚\n",
    "\n",
    "5. æ˜“æ–¼æ•´åˆ\n",
    "API æ¥å£ï¼š åªéœ€å¹¾è¡Œç¨‹å¼ç¢¼å³å¯æ¥å…¥ï¼ˆæ”¯æ´ LlamaIndexã€LangChain ç­‰æ¡†æ¶ï¼‰ã€‚\n",
    "\n",
    "é›²ç«¯æ”¯æŒï¼š å·²æ•´åˆé€² Azure AI Foundryã€AWS SageMaker ç­‰ä¸»æµä¼æ¥­é›²å¹³å°ï¼Œæ»¿è¶³å®‰å…¨æ€§èˆ‡åˆè¦æ€§è¦æ±‚ã€‚\n",
    "\n",
    "ç¸½çµä¾†èªªï¼š å¦‚æœæ‚¨æ­£åœ¨é–‹ç™¼ä¸€å€‹ä¼æ¥­ç´š RAG ç³»çµ±ï¼Œä¸”å°å¤šèªè¨€æ”¯æŒã€é•·æ–‡ä»¶è™•ç†æˆ–é‡‘è/é†«ç™‚æ•¸æ“šç²¾æº–åº¦æœ‰å¾ˆé«˜è¦æ±‚ï¼ŒCohere Rerank 4 Pro æ˜¯ç›®å‰çš„æœ€ä½³é¸æ“‡ï¼›å¦‚æœæ‚¨æ›´åœ¨æ„æˆæœ¬èˆ‡å›è¦†é€Ÿåº¦ï¼ŒRerank 4 Fast å‰‡æä¾›äº†æ¥µä½³çš„æ€§åƒ¹æ¯”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77466a7e-2ccc-472c-9170-fc1c90b21d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "# api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "# cohere_rerank = CohereRerank(api_key=api_key, top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111e664-223b-47e3-ab68-ef17c2234a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CohereRerank?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c8b2f-8a63-42d2-b313-d86e93ed566b",
   "metadata": {},
   "source": [
    "#### ReRank ç­–ç•¥çš„æ¯”è¼ƒè¡¨\n",
    "\n",
    "| æ–¹æ¡ˆ | æˆæœ¬ | é€Ÿåº¦ | é©ç”¨å ´æ™¯ | \n",
    "| --- | --- | --- | --- |\n",
    "| BGE (Local) | å…è²» (éœ€ GPU) | å¿« | éš±ç§è¦æ±‚é«˜ã€é ç®—æœ‰é™ |\n",
    "| RankGPT | é«˜ (API æ¶ˆè€—) | æ…¢ | æ¥µè‡´æº–ç¢ºåº¦ã€é•·æ–‡æœ¬ç†è§£ | \n",
    "| Cohere v4 | ä¸­ (æŒ‰æ¬¡æ”¶è²») | æ¥µå¿« | ä¼æ¥­ç”Ÿç”¢ç’°å¢ƒã€å¤šèªè¨€æ··åˆ |\n",
    "\n",
    "\n",
    "å‰›æ‰æˆ‘å€‘å­¸ç¿’äº†å¦‚ä½•å°ç¾æœ‰çš„çµæœé€²è¡Œã€é‡æ–°æ’åºã€ï¼Œä½†å¦‚æœä¸€é–‹å§‹å‘é‡æœå°‹å°±æ²’æ‰¾å°å…§å®¹ï¼ˆä¾‹å¦‚é—œéµå­—ç²¾ç¢ºåŒ¹é…å¤±æ•—ï¼‰ï¼Œé‚£é‡æ–°æ’åºä¹Ÿæ²’æ•‘ã€‚å› æ­¤ï¼Œæ¥ä¸‹ä¾†æˆ‘å€‘è¦é€²å…¥ Hybrid Retrieverï¼ˆæ··åˆæª¢ç´¢ï¼‰ï¼Œå­¸ç¿’å¦‚ä½•çµåˆå‚³çµ±æœå°‹èˆ‡èªæ„æœå°‹çš„å„ªå‹¢..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492bf38-0213-4419-9757-b8c3897460bb",
   "metadata": {},
   "source": [
    "## Hybrid Retriever\n",
    "\n",
    "### BM25\n",
    "\n",
    "ç‚ºäº†è®“å¤§å®¶å°ˆæ³¨æ–¼ BM25 çš„æ©Ÿåˆ¶è€Œéè™•ç†ä¸­æ–‡æ–·è©çš„ç¹ç‘£é…ç½®ï¼Œæ¥ä¸‹ä¾†çš„ Hybrid ç¯„ä¾‹æˆ‘å€‘å°‡åˆ‡æ›è‡³è‹±æ–‡è³‡æ–™é›†ï¼ˆTech Companiesï¼‰ã€‚\n",
    "\n",
    "*LlamaIndex çš„ BM25åœ¨è™•ç†ä¸­æ–‡æ–‡æœ¬ä¸Šéœ€è¦é«˜åº¦å®¢è£½åŒ–* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c947200-bda9-4c0e-800d-fc4e9537e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import wikipediaapi\n",
    "\n",
    "\n",
    "wiki_titles = [\"Anthropic\", \"OpenAI\", \"XAI_(company)\", \"Tesla,_Inc.\"]\n",
    "wiki_metadatas = {\n",
    "    \"Anthropic\": {\n",
    "        \"headquarter\": \"San Francisco\",\n",
    "        \"industry\": \"Artificial intelligence\"\n",
    "    },\n",
    "    \"OpenAI\": {\n",
    "        \"headquarter\": \"San Francisco\",\n",
    "        \"industry\": \"Artificial intelligence\"\n",
    "    },\n",
    "    \"XAI_(company)\": {\n",
    "        \"headquarter\": \"Palo Alto\",\n",
    "        \"industry\": \"Technology\"\n",
    "    },\n",
    "    \"Tesla,_Inc.\": {\n",
    "        \"headquarter\": \"Austin\",\n",
    "        \"industry\": \"Automotive\"\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='AI Tutorial(mengchiehling@gmail.com)', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606c6342-c4e1-4969-b0e8-b24c6c603c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in wiki_titles:\n",
    "    page = wiki_wiki.page(title)\n",
    "    wiki_text = page.text\n",
    "\n",
    "    data_path = Path(\"data\")\n",
    "    if not data_path.exists():\n",
    "        Path.mkdir(data_path)\n",
    "\n",
    "    with open(data_path / f\"{title}.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(wiki_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfefdb-d5cf-4f19-88ad-f5b8b0340545",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for wiki_title in wiki_titles:\n",
    "    doc = SimpleDirectoryReader(\n",
    "        input_files=[f\"data/{wiki_title}.txt\"]\n",
    "    ).load_data()[0]\n",
    "\n",
    "    doc.metadata.update(wiki_metadatas[wiki_title])\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4a2ba-85c3-48be-9a60-a1175017fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# initialize node parser\n",
    "splitter = SentenceSplitter(chunk_size=512)\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999093d6-17bc-46a0-a69c-3ea4632b0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02a64c-1eff-47c2-99cb-e54b876ce5e4",
   "metadata": {},
   "source": [
    "One option is to create the BM25Retriever directly from nodes, and save to and from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa988cda-37a2-443d-8492-e7483f2f833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "# We can pass in the index, docstore, or list of nodes to create the retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    "    # Optional: We can pass in the stemmer and set the language for stopwords\n",
    "    # This is important for removing stopwords and stemming the query + text\n",
    "    # The default is english for both\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6e3f0-c110-438c-afe3-2aa13b7817ee",
   "metadata": {},
   "source": [
    "Here, we cover using a BM25Retriever with a docstore to hold your nodes. The advantage here is that the docstore can be remote (mongodb, redis, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e79b1-a8ff-4f32-a773-84ddbf18fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a docstore to store nodes\n",
    "# also available are mongodb, redis, postgres, etc for docstores\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# We can pass in the index, docstore, or list of nodes to create the retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    docstore=docstore,\n",
    "    similarity_top_k=5,\n",
    "    # Optional: We can pass in the stemmer and set the language for stopwords\n",
    "    # This is important for removing stopwords and stemming the query + text\n",
    "    # The default is english for both\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d8f4f-c2e0-4dfb-8766-351b68cacd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will retrieve context from specific companies\n",
    "retrieved_nodes = bm25_retriever.retrieve(\n",
    "    \"artiticial intelligence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bba6a38-ed9b-486f-8d10-556929e766da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fec69-5ecd-4059-8ffd-413fdba426c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375d1a3-6431-416e-ac8e-44e39710adee",
   "metadata": {},
   "source": [
    "### BM25 Retriever + MetadataFiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326daba-0f60-4af2-a677-011bd9b53023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata filters\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilters,\n",
    "    MetadataFilter,\n",
    "    FilterOperator,\n",
    "    FilterCondition,\n",
    ")\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(\n",
    "            key=\"headquarter\",\n",
    "            value=\"San Francisco\",\n",
    "            operator=FilterOperator.EQ,\n",
    "        )\n",
    "    ],\n",
    "    condition=FilterCondition.AND,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980c84f-2904-407a-baf6-392b85329a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = BM25Retriever.from_defaults(\n",
    "    docstore=docstore,\n",
    "    similarity_top_k=3,\n",
    "    filters=filters,  # Add filters here\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ").retrieve(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e2fa39-855c-403b-b8c7-a1042abcaaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b784f297-5c7e-40fd-a7f0-e5c95fe62bd0",
   "metadata": {},
   "source": [
    "### Queries\n",
    "\n",
    "**Company Background & Positioning**\n",
    "\n",
    "> Best for testing keyword matching + semantic understanding\n",
    "\n",
    "- What is OpenAI and what is its core mission?\n",
    "- How does Anthropic position itself in the AI safety landscape?\n",
    "- What company is xAI and why was it founded?\n",
    "- What is Tesla primarily known for besides electric vehicles?\n",
    "\n",
    "---\n",
    "\n",
    "**Founders & Key Figures**\n",
    "\n",
    "> Strong keyword signals (names, dates) with semantic reinforcement\n",
    "\n",
    "- Who founded OpenAI and when?\n",
    "- Who are the founders of Anthropic?\n",
    "- What is Elon Muskâ€™s involvement in xAI?\n",
    "- How is Elon Musk connected to Tesla?\n",
    "\n",
    "---\n",
    "\n",
    "**Mission, Goals, and Philosophy**\n",
    "\n",
    "> Conceptual questions where dense retrieval excels\n",
    "\n",
    "- What does OpenAI mean by artificial general intelligence?\n",
    "- What is Anthropicâ€™s approach to building safe AI systems?\n",
    "- What problem is xAI trying to solve?\n",
    "- What is Teslaâ€™s long-term vision for sustainable energy?\n",
    "\n",
    "---\n",
    "\n",
    "**Products & Technologies**\n",
    "\n",
    "> Hybrid retrieval works especially well for mixed factual + semantic queries\n",
    "\n",
    "- What products or models has OpenAI released?\n",
    "- What is Anthropicâ€™s Claude model?\n",
    "- Does xAI develop large language models?\n",
    "- What technologies does Tesla develop besides cars?\n",
    "\n",
    "---\n",
    "\n",
    "**Comparison Queries**\n",
    "\n",
    "> Ideal for demonstrating QueryFusionRetriever and multi-document reasoning\n",
    "\n",
    "- How is OpenAI different from Anthropic?\n",
    "- Compare the goals of OpenAI and xAI.\n",
    "- How do AI companies like OpenAI and Anthropic differ from Tesla?\n",
    "- Which of these companies focuses on AI safety?\n",
    "\n",
    "---\n",
    "\n",
    "**Advanced / RAG Demo Queries (Recommended)**\n",
    "\n",
    "> Excellent for end-to-end RetrieverQueryEngine demonstrations\n",
    "\n",
    "- Which companies in the documents are focused on artificial intelligence research?\n",
    "- Which organization emphasizes AI safety and alignment?\n",
    "- What companies were founded by Elon Musk?\n",
    "- Summarize the missions of OpenAI, Anthropic, xAI, and Tesla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ae629-b0f2-4c52-8fea-669de8684ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "retrieved_nodes = BM25Retriever.from_defaults(\n",
    "    docstore=docstore,\n",
    "    similarity_top_k=5,\n",
    "    filters=filters,  # Add filters here\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ").retrieve(\"Hello, world!\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472be930-3aeb-4e23-86c4-3a25c084a21c",
   "metadata": {},
   "source": [
    "## Hybrid Retriever with BM25 + FAISSï¼ˆBM25 + FAISS çš„æ··åˆå¼æª¢ç´¢å™¨ï¼‰\n",
    "\n",
    "### 1ï¸âƒ£ å…§å®¹ç¿»è­¯ï¼ˆç¹é«”ä¸­æ–‡ï¼‰\n",
    "\n",
    "### ä½¿ç”¨ BM25 + FAISS çš„æ··åˆå¼æª¢ç´¢å™¨\n",
    "ç¾åœ¨æˆ‘å€‘å°‡çµåˆ **BM25** èˆ‡ **FAISS**ï¼ŒåŒæ™‚é€²è¡Œ**ç¨€ç–æª¢ç´¢ï¼ˆsparse retrievalï¼‰**èˆ‡**ç¨ å¯†æª¢ç´¢ï¼ˆdense retrievalï¼‰**ã€‚\n",
    "\n",
    "æª¢ç´¢çµæœæœƒé€é **QueryFusionRetriever** é€²è¡Œæ•´åˆã€‚\n",
    "\n",
    "é€éé€™å€‹ retrieverï¼Œæˆ‘å€‘å¯ä»¥å»ºç«‹ä¸€å€‹å®Œæ•´çš„ **RetrieverQueryEngine**ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 2ï¸âƒ£ Hybrid Retrieverï¼ˆæ··åˆå¼æª¢ç´¢å™¨ï¼‰çš„å¥½è™•èªªæ˜\n",
    "\n",
    "æ··åˆå¼æª¢ç´¢å™¨çµåˆäº† BM25 èˆ‡å‘é‡æª¢ç´¢ï¼ˆå¦‚ FAISSï¼‰çš„å„ªé»ï¼Œèƒ½æœ‰æ•ˆå½Œè£œå½¼æ­¤çš„é™åˆ¶ï¼š\n",
    "\n",
    "- **æå‡å¬å›ç‡ï¼ˆRecallï¼‰**\n",
    "  - BM25 æ“…é•·ç²¾ç¢ºçš„é—œéµå­—æ¯”å°\n",
    "  - FAISS æ“…é•·æ•æ‰èªæ„ç›¸è¿‘ä½†ç”¨è©ä¸åŒçš„å…§å®¹\n",
    "  - å…©è€…çµåˆèƒ½æ‰¾å›æ›´å¤šã€ŒçœŸæ­£ç›¸é—œã€çš„æ–‡ä»¶\n",
    "\n",
    "- **å…¼é¡§èªæ„èˆ‡é—œéµå­—ç²¾æº–åº¦**\n",
    "  - å°æ–¼å°ˆæœ‰åè©ã€æ•¸å­—ã€ç¨‹å¼ç¢¼ç­‰ï¼ŒBM25 è¡¨ç¾è¼ƒä½³\n",
    "  - å°æ–¼èªæ„ç›¸ä¼¼ã€åŒç¾©æ”¹å¯«çš„æŸ¥è©¢ï¼Œå‘é‡æª¢ç´¢æ›´æœ‰å„ªå‹¢\n",
    "\n",
    "- **é™ä½å–®ä¸€æª¢ç´¢æ–¹å¼çš„ç›²é»**\n",
    "  - åƒ…ä½¿ç”¨ BM25 å¯èƒ½å¿½ç•¥èªæ„ç›¸é—œä½†æœªå‡ºç¾é—œéµå­—çš„å…§å®¹\n",
    "  - åƒ…ä½¿ç”¨å‘é‡æª¢ç´¢å¯èƒ½åœ¨ç²¾ç¢ºå­—è©åŒ¹é…ä¸Šè¡¨ç¾ä¸è¶³\n",
    "\n",
    "- **é€é Query Fusion æå‡æ’åºå“è³ª**\n",
    "  - QueryFusionRetriever å¯ä»¥å°‡å¤šç¨®æª¢ç´¢çµæœåŠ æ¬Šã€èåˆèˆ‡é‡æ–°æ’åº\n",
    "  - æä¾›æ›´ç©©å®šä¸”é«˜å“è³ªçš„æœ€çµ‚çµæœ\n",
    "\n",
    "---\n",
    "\n",
    "### 3ï¸âƒ£ ç¸½çµ\n",
    "\n",
    "**Hybrid Retrieverï¼ˆBM25 + FAISSï¼‰** æ˜¯ä¸€ç¨®åŒæ™‚çµåˆ  \n",
    "ğŸ‘‰ **é—œéµå­—ç²¾æº–åŒ¹é…** èˆ‡  \n",
    "ğŸ‘‰ **èªæ„ç†è§£èƒ½åŠ›** çš„æª¢ç´¢ç­–ç•¥ã€‚\n",
    "\n",
    "é€é **QueryFusionRetriever** å°‡çµæœæ•´åˆå¾Œï¼Œå†æ­é… **RetrieverQueryEngine**ï¼Œ  \n",
    "å¯ä»¥æ‰“é€ å‡ºæ›´æº–ç¢ºã€æ›´å¥å£¯ã€ä¹Ÿæ›´é©åˆå¯¦å‹™æ‡‰ç”¨çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»çµ±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5775a-6a7e-4b14-bbc5-e1496052be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "d = 1024 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5411f0-8626-42bb-960d-182d3529d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for wiki_title in wiki_titles:\n",
    "    doc = SimpleDirectoryReader(\n",
    "        input_files=[f\"data/{wiki_title}.txt\"]\n",
    "    ).load_data()[0]\n",
    "\n",
    "    doc.metadata.update(wiki_metadatas[wiki_title])\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2f52a-1e6f-4dd3-b852-92ebdf5b5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# initialize node parser\n",
    "splitter = SentenceSplitter(chunk_size=512)\n",
    "\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be2e4c9-c695-4424-b0c6-a7bed08f6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f9d9fe-91f3-46b6-a872-4b5e58ddfc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "\n",
    "callback_manager = CallbackManager([LlamaDebugHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b6279b-fab4-474f-a183-d9ac15c82076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex(nodes=nodes, \n",
    "                         storage_context=storage_context,\n",
    "                         callback_manager=callback_manager,\n",
    "                         embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d3c3e-bfac-42dc-af15-10ffef930fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "llm = OpenAI(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac10cb-42f3-4bb2-9060-97a7b1a93fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [\n",
    "        index.as_retriever(similarity_top_k=2),\n",
    "        BM25Retriever.from_defaults(\n",
    "            docstore=index.docstore, similarity_top_k=2\n",
    "        ),\n",
    "    ],\n",
    "    num_queries=1,\n",
    "    use_async=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb6fc0-be38-407d-a2a7-420bb0e29d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"Hello, world!\")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680dda96-273f-47ea-9099-944dcc6878b1",
   "metadata": {},
   "source": [
    "**num_queries**ï¼š\n",
    "\n",
    "åœ¨é€™å€‹æ­¥é©Ÿä¸­ï¼Œæˆ‘å€‘æœƒå°‡å¤šå€‹ç´¢å¼•èåˆæˆä¸€å€‹å–®ä¸€çš„æª¢ç´¢å™¨ï¼ˆretrieverï¼‰ã€‚é€™å€‹æª¢ç´¢å™¨åŒæ™‚ä¹Ÿæœƒé€éç”¢ç”Ÿèˆ‡åŸå§‹å•é¡Œç›¸é—œçš„é¡å¤–æŸ¥è©¢ä¾†æ“´å……ï¼ˆaugmentï¼‰ä½ çš„æŸ¥è©¢ï¼Œä¸¦å½™ç¸½æ‰€æœ‰æŸ¥è©¢çš„çµæœã€‚\n",
    "\n",
    "æ­¤è¨­å®šæœƒåŸ·è¡Œ 4 æ¬¡æŸ¥è©¢ï¼šä¸€æ¬¡ä½¿ç”¨ä½ çš„åŸå§‹æŸ¥è©¢ï¼Œä¸¦å¦å¤–ç”¢ç”Ÿ 3 å€‹æ–°çš„æŸ¥è©¢ã€‚\n",
    "\n",
    "é è¨­æƒ…æ³ä¸‹ï¼Œå®ƒæœƒä½¿ç”¨ä»¥ä¸‹æç¤ºï¼ˆpromptï¼‰ä¾†ç”¢ç”Ÿé¡å¤–çš„æŸ¥è©¢ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06eacc-b1f5-48b0-adc9-98a22a630d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QUERY_GEN_PROMPT = (\n",
    "    \"You are a helpful assistant that generates multiple search queries based on a \"\n",
    "    \"single input query. Generate {num_queries} search queries, one on each line, \"\n",
    "    \"related to the following input query:\\n\"\n",
    "    \"Query: {query}\\n\"\n",
    "    \"Queries:\\n\"\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57856f59-e0bf-4bf2-bbf8-14bb17b3f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QueryFusionRetriever(\n",
    "    [\n",
    "        index.as_retriever(similarity_top_k=2),\n",
    "        BM25Retriever.from_defaults(\n",
    "            docstore=index.docstore, similarity_top_k=2\n",
    "        ),\n",
    "    ],\n",
    "    num_queries=4,\n",
    "    use_async=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5ad60-1d69-422c-a509-22ad949ff48e",
   "metadata": {},
   "source": [
    "#### æ·±åº¦è§£æï¼šå¾å¤šå€‹ç¶­åº¦æ•æ‰èªæ„ï¼ˆRAG-Fusionï¼‰\n",
    "\n",
    "é€™è£¡è¨­ç½®çš„ num_queries å¯¦éš›ä¸Šé«”ç¾äº† RAG-Fusion çš„æ ¸å¿ƒæ€æƒ³ã€‚\n",
    "\n",
    "å…‹æœæŸ¥è©¢çš„ä¸ç¢ºå®šæ€§ï¼šåŸå§‹æŸ¥è©¢å¾€å¾€è¼ƒç‚ºç°¡çŸ­æˆ–æ¨¡ç³Šï¼Œè€Œ RAG-Fusion åˆ©ç”¨ LLM å°‡å–®ä¸€æŸ¥è©¢æ‹†è§£ã€æ”¹å¯«æˆå¤šå€‹ä¸åŒè§’åº¦çš„æœå°‹æŒ‡ä»¤ã€‚\n",
    "\n",
    "å¤šè§’åº¦æª¢ç´¢ï¼šä¾‹å¦‚ï¼Œç•¶ä½¿ç”¨è€…å•ã€Œè‹±é›„ã€æ™‚ï¼ŒLLM å¯èƒ½æœƒç”¢ç”Ÿã€Œè‹±é›„å®šç¾©ã€ã€ã€Œå‹•æ¼«ä¸­çš„è‹±é›„è§’è‰²ã€æˆ–ã€Œè‹±é›„ç›¸é—œåŠ‡æƒ…ã€ç­‰æŸ¥è©¢ï¼Œç¢ºä¿å¾å‘é‡ç©ºé–“ä¸­æª¢ç´¢å‡ºæ›´å…¨é¢çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "\n",
    "æ¶ˆé™¤æ’åºåå·®ï¼šé€éç”¢ç”Ÿå¤šå€‹æŸ¥è©¢ä¸¦é…åˆ Reciprocal Rank Fusion (RRF) æ¼”ç®—æ³•ï¼Œç³»çµ±èƒ½æœ‰æ•ˆæ¸›å°‘å–®ä¸€æª¢ç´¢æ¼”ç®—æ³•å°ç‰¹å®šé—œéµå­—çš„æ’åºåè¦‹ï¼Œä½¿æœ€çµ‚çµæœæ›´å…·é­¯æ£’æ€§ï¼ˆRobustnessï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ace795-133a-4f83-afa7-71140b78f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46977413-bbde-45ce-8ead-bdc74dd4594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b32408-d2c9-4be1-b30b-88968b9345dc",
   "metadata": {},
   "source": [
    "Now, we can plug our retriever into a query engine to synthesize natural language responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdc339-2fad-4c3a-a32d-7eb928d75969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ba4a1-301d-4e30-af42-04eeef53186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryFusionRetriever?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413013ed-74ae-41da-83a0-0d4aadcbe938",
   "metadata": {},
   "source": [
    "### 1. Reciprocal Rerankï¼ˆRRFï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**ï¼š`FUSION_MODE.RECIPROCAL_RANK`ï¼ˆé è¨­ï¼‰\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**ï¼š  \n",
    "é€™æ˜¯ç›®å‰æœ€å¸¸è¦‹ã€ä¹Ÿæœ€å—æ­¡è¿çš„æ–¹æ³•ã€‚å®ƒä¸æœƒä½¿ç”¨ LLM ä¾†å°æ–‡ä»¶é€²è¡Œè©•åˆ†ï¼Œè€Œæ˜¯é€éä¸€å€‹æ•¸å­¸å…¬å¼ï¼Œæ ¹æ“šæ–‡ä»¶åœ¨å¤šå€‹çµæœæ¸…å–®ä¸­çš„æ’åï¼ˆrankï¼‰ä¾†é‡æ–°æ’åºã€‚\n",
    "\n",
    "**å…¬å¼ï¼ˆFormulaï¼‰**ï¼š  \n",
    "\n",
    "$$\n",
    "score = \\sum_{d \\in r} \\frac{1}{k + rank(d)}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼Œ`k` æ˜¯ä¸€å€‹å¸¸æ•¸ï¼ˆé€šå¸¸ç‚º 60ï¼‰ã€‚\n",
    "\n",
    "**é©ç”¨æƒ…å¢ƒï¼ˆBest forï¼‰**ï¼š  \n",
    "é€šç”¨å‹çš„ã€Œæ··åˆæœå°‹ï¼ˆHybrid Searchï¼‰ã€ï¼Œç•¶ä½ å¸Œæœ›åœ¨å‘é‡æœå°‹èˆ‡é—œéµå­—æœå°‹ä¹‹é–“å–å¾—è‰¯å¥½å¹³è¡¡ï¼ŒåŒæ™‚é¿å…é¡å¤–çš„ LLM æˆæœ¬æ™‚ï¼Œéå¸¸é©åˆä½¿ç”¨ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Relative Score Fusionï¼ˆç›¸å°åˆ†æ•¸èåˆï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**ï¼š`FUSION_MODE.RELATIVE_SCORE`\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**ï¼š  \n",
    "æ­¤æ–¹æ³•ä¸å†é—œæ³¨æ–‡ä»¶çš„æ’åï¼ˆä¾‹å¦‚ç¬¬ 1 åã€ç¬¬ 2 åï¼‰ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨å¯¦éš›çš„ç›¸ä¼¼åº¦åˆ†æ•¸ã€‚  \n",
    "å®ƒæœƒå°‡ä¾†è‡ªä¸åŒæª¢ç´¢å™¨ï¼ˆé€šå¸¸åˆ†æ•¸å°ºåº¦ä¸åŒï¼‰çš„åˆ†æ•¸æ­£è¦åŒ–åˆ° 0 åˆ° 1 çš„ç¯„åœå…§ï¼Œæ¥è‘—å†å°é€™äº›åˆ†æ•¸å–å¹³å‡ã€‚\n",
    "\n",
    "**é©ç”¨æƒ…å¢ƒï¼ˆBest forï¼‰**ï¼š  \n",
    "ç•¶æª¢ç´¢å™¨æ‰€æä¾›çš„ä¿¡å¿ƒåˆ†æ•¸ï¼ˆconfidence scoreï¼‰æœ¬èº«å°±ç›¸ç•¶å¯é æ™‚ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Distribution-Based Score Fusionï¼ˆåˆ†ä½ˆå¼åˆ†æ•¸èåˆï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**ï¼š`FUSION_MODE.DIST_BASED_SCORE`\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**ï¼š  \n",
    "é€™æ˜¯ä¸€ç¨®æ›´é€²éšçš„åˆ†æ•¸èåˆæ–¹æ³•ï¼ŒæœƒåŒæ™‚è€ƒæ…®çµæœé›†ä¸­åˆ†æ•¸çš„å¹³å‡å€¼ï¼ˆmeanï¼‰èˆ‡æ¨™æº–å·®ï¼ˆstandard deviationï¼‰ã€‚  \n",
    "é€™æœ‰åŠ©æ–¼è™•ç†ä¸åŒæª¢ç´¢å™¨å¯èƒ½ç”¢ç”Ÿã€Œåˆ†æ•¸éå¸¸é›†ä¸­ã€æˆ–ã€Œåˆ†æ•¸åˆ†ä½ˆéå¸¸åˆ†æ•£ã€çš„æƒ…æ³ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Simple Fusionï¼ˆç°¡å–®èåˆï¼‰\n",
    "\n",
    "**æ¨¡å¼ï¼ˆModeï¼‰**ï¼š`FUSION_MODE.SIMPLE`\n",
    "\n",
    "**é‹ä½œæ–¹å¼ï¼ˆHow it worksï¼‰**ï¼š  \n",
    "é€™æ˜¯ä¸€ç¨®åŸºç¤åšæ³•ï¼Œé€šå¸¸åªæ˜¯å°‡çµæœç›´æ¥ä¸²æ¥ï¼ˆconcatenationï¼‰æˆ–é€²è¡Œç°¡å–®åŠ ç¸½ã€‚  \n",
    "ç›¸è¼ƒæ–¼ RRFï¼Œé€™ç¨®æ–¹æ³•åœ¨å¯¦éš›ç”Ÿç”¢ç’°å¢ƒä¸­è¼ƒå°‘ä½¿ç”¨ï¼Œä½†å¯ç”¨æ–¼æ¸¬è©¦åŸºæº–æ•ˆèƒ½ï¼ˆbaseline performanceï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552dd0cd-f318-4046-9523-5bb6c0825a18",
   "metadata": {},
   "source": [
    "## SumaryIndex Orchestration\n",
    "\n",
    "æ­¤æ–¹æ³•é€éè¨­å®š IndexNode ç‰©ä»¶ ä¾†é‹ä½œï¼Œå…¶ä¸­ obj æ¬„ä½å¯æŒ‡å‘ä»¥ä¸‹ä»»ä¸€é …ï¼š\n",
    "\n",
    "- Query Engineï¼ˆæŸ¥è©¢å¼•æ“ï¼‰\n",
    "- Retrieverï¼ˆæª¢ç´¢å™¨ï¼‰\n",
    "- Query Pipelineï¼ˆæŸ¥è©¢æµç¨‹ç®¡ç·šï¼‰\n",
    "- å¦ä¸€å€‹ Nodeï¼ˆç¯€é»ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd5d41-9712-4be1-a111-dee6536ce858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "\n",
    "\n",
    "wiki_titles = [\"Anthropic\", \"OpenAI\", \"XAI_(company)\", \"Tesla,_Inc.\"]\n",
    "wiki_metadatas = {\n",
    "    \"Anthropic\": {\n",
    "        \"headquarter\": \"San Francisco\",\n",
    "        \"industry\": \"Artificial intelligence\"\n",
    "    },\n",
    "    \"OpenAI\": {\n",
    "        \"headquarter\": \"San Francisco\",\n",
    "        \"industry\": \"Artificial intelligence\"\n",
    "    },\n",
    "    \"XAI_(company)\": {\n",
    "        \"headquarter\": \"Palo Alto\",\n",
    "        \"industry\": \"Technology\"\n",
    "    },\n",
    "    \"Tesla,_Inc.\": {\n",
    "        \"headquarter\": \"Austin\",\n",
    "        \"industry\": \"Automotive\"\n",
    "    },\n",
    "}\n",
    "\n",
    "documents = []\n",
    "\n",
    "for wiki_title in wiki_titles:\n",
    "    doc = SimpleDirectoryReader(\n",
    "        input_files=[f\"data/{wiki_title}.txt\"]\n",
    "    ).load_data()[0]\n",
    "\n",
    "    doc.metadata.update(wiki_metadatas[wiki_title])\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b36b4-f919-4c10-8906-e9dac5322af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1024 # å¿…é ˆèˆ‡ embedding model çš„è¼¸å‡ºç¶­åº¦ä¸€è‡´\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    [],\n",
    "    storage_context=storage_context,\n",
    "    transformations=[SentenceSplitter.from_defaults()],\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# add documents to index\n",
    "for document in documents:\n",
    "    index.insert(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee943f9-e062-401c-bec5-f4c3240921e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "vector_retriever = index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "# We can pass in the index, docstore, or list of nodes to create the retriever\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    docstore=index.docstore,\n",
    "    similarity_top_k=2,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8f5bd-23c3-4339-80c7-60c99c444303",
   "metadata": {},
   "source": [
    "### çµ„åˆç‰©ä»¶ï¼ˆComposing Objectsï¼‰\n",
    "\n",
    "åœ¨æ­¤æ­¥é©Ÿä¸­ï¼Œæˆ‘å€‘å»ºç«‹ IndexNodeã€‚è«‹æ³¨æ„ï¼Œtext æ¬„ä½æ˜¯ç”¨ä¾†è®“**æœ€ä¸Šå±¤ç´¢å¼•ï¼ˆtop-level indexï¼‰**å°è©²ç¯€é»é€²è¡Œç´¢å¼•çš„å…§å®¹ã€‚\n",
    "\n",
    "å°æ–¼ å‘é‡ç´¢å¼•ï¼ˆVector Indexï¼‰ï¼Œtext æœƒè¢«è½‰æ›ç‚º Embedding\n",
    "\n",
    "å°æ–¼ é—œéµå­—ç´¢å¼•ï¼ˆKeyword Indexï¼‰ï¼Œtext æœƒè¢«ç”¨ä¾†é€²è¡Œé—œéµå­—æ¯”å°\n",
    "\n",
    "åœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œæˆ‘å€‘ä½¿ç”¨çš„æ˜¯ SummaryIndexã€‚ç”±æ–¼å®ƒåœ¨æŸ¥è©¢æ™‚ç¸½æ˜¯æœƒå–å›æ‰€æœ‰ç¯€é»ï¼Œå› æ­¤åœ¨æŠ€è¡“ä¸Šä¸¦ä¸éœ€è¦ä¾è³´ text ä¾†é€²è¡Œæª¢ç´¢ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d3a73-478e-4afe-a5ac-625fbb501caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "vector_obj = IndexNode(\n",
    "    index_id=\"vector\", obj=vector_retriever, text=\"Vector Retriever\"\n",
    ")\n",
    "\n",
    "bm25_obj = IndexNode(\n",
    "    index_id=\"bm25\", obj=bm25_retriever, text=\"BM25 Retriever\"\n",
    ")\n",
    "\n",
    "summary_index = SummaryIndex(objects=[vector_obj, bm25_obj])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63d8ea-a866-417f-ae59-fb2e0ec02dd6",
   "metadata": {},
   "source": [
    "# åœ¨ LlamaIndex ä¸­ä½¿ç”¨ `SummaryIndex` èˆ‡ `IndexNode` çš„æ··åˆæª¢ç´¢ï¼ˆHybrid Retrievalï¼‰\n",
    "\n",
    "![caption](SummaryIndexOchestration.png)\n",
    "\n",
    "ä»¥ä¸‹ç­†è¨˜ç¸½çµäº†æˆ‘å€‘é—œæ–¼åœ¨ LlamaIndex ä¸­ä½¿ç”¨ **`SummaryIndex` æ­é… `IndexNode`** ä¾†å»ºç«‹**æ··åˆæª¢ç´¢ç³»çµ±ï¼ˆHybrid Retrieval Systemï¼‰**çš„è¨è«–ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ä»€éº¼æ˜¯ `SummaryIndex`ï¼Ÿ\n",
    "\n",
    "**`SummaryIndex`**ï¼ˆå…ˆå‰ç¨±ç‚º **List Index**ï¼‰æ˜¯ä¸€ç¨®åŸºç¤è³‡æ–™çµæ§‹ï¼Œç”¨ä¾†ä»¥æ‰å¹³ã€ç·šæ€§çš„æ–¹å¼å„²å­˜ç¯€é»ï¼ˆNodesï¼‰ã€‚\n",
    "\n",
    "### ä¸»è¦ç‰¹æ€§\n",
    "\n",
    "- **çµæ§‹ï¼š** æ‰å¹³ã€ä¾åºæ’åˆ—çš„ç¯€é»æ¸…å–®  \n",
    "- **æª¢ç´¢é‚è¼¯ï¼š**  \n",
    "  - é è¨­æƒ…æ³ä¸‹ï¼Œæœƒæª¢ç´¢ç´¢å¼•ä¸­å„²å­˜çš„**æ‰€æœ‰ç¯€é»**  \n",
    "  - **ä¸æœƒ**åŸ·è¡Œç›¸ä¼¼åº¦æœå°‹  \n",
    "- **ä¸»è¦ç›®æ¨™ï¼š**  \n",
    "  - å…¨é¢æ€§çš„å…§å®¹æ•´åˆ  \n",
    "  - è·¨æ‰€æœ‰å·²ç´¢å¼•å…§å®¹çš„æ‘˜è¦èˆ‡ç¸½çµ  \n",
    "\n",
    "å› æ­¤ï¼Œ`SummaryIndex` ç‰¹åˆ¥é©åˆç”¨æ–¼**èšåˆï¼ˆaggregationï¼‰ã€ç·¨æ’ï¼ˆorchestrationï¼‰èˆ‡ç¶œåˆï¼ˆsynthesisï¼‰**ï¼Œè€Œéç²¾æº–çš„ç›®æ¨™å¼æª¢ç´¢ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ä½¿ç”¨ `IndexNode` ç‰©ä»¶é€²è¡Œæª¢ç´¢ç·¨æ’ï¼ˆRetrieval Orchestrationï¼‰\n",
    "\n",
    "ç•¶ä½ å°‡ **`IndexNode` ç‰©ä»¶**å‚³å…¥ `SummaryIndex` æ™‚ï¼Œå°±ä¸å†åªæ˜¯å–®ç´”çš„æ–‡å­—ç´¢å¼•ï¼Œè€Œæ˜¯é€²å…¥äº†**æª¢ç´¢ç·¨æ’ï¼ˆretrieval orchestrationï¼‰**çš„å±¤æ¬¡ã€‚\n",
    "\n",
    "æ¯å€‹ `IndexNode` éƒ½å¯ä»¥åŒ…è£ä¸€å€‹ retrieverã€toolï¼Œæˆ–æ˜¯å­ç´¢å¼•ï¼ˆsub-indexï¼‰ã€‚\n",
    "\n",
    "### ç¯„ä¾‹ï¼šåŒ…è£å¤šå€‹ Retrievers\n",
    "\n",
    "```python\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core import SummaryIndex\n",
    "\n",
    "# å°‡å°ˆç”¨çš„ retrievers å®šç¾©ç‚º IndexNodes\n",
    "vector_obj = IndexNode(\n",
    "    index_id=\"vector\",\n",
    "    obj=vector_retriever,\n",
    "    text=\"Vector Retriever\"\n",
    ")\n",
    "\n",
    "bm25_obj = IndexNode(\n",
    "    index_id=\"bm25\",\n",
    "    obj=bm25_retriever,\n",
    "    text=\"BM25 Retriever\"\n",
    ")\n",
    "\n",
    "# å»ºç«‹ SummaryIndex ä½œç‚ºå®¹å™¨\n",
    "summary_index = SummaryIndex(objects=[vector_obj, bm25_obj])\n",
    "```\n",
    "åœ¨é€™è£¡ï¼Œ`SummaryIndex` æ‰®æ¼”çš„æ˜¯**è·¯ç”±å™¨ï¼ˆrouterï¼‰**çš„è§’è‰²ï¼Œè€Œä¸æ˜¯å‚³çµ±çš„æœå°‹ç´¢å¼•ã€‚\n",
    "\n",
    "## 3. åŸ·è¡Œæµç¨‹ï¼ˆExecution Workflowï¼‰\n",
    "\n",
    "ç•¶ä½ å°åŒ…å« `IndexNode` ç‰©ä»¶çš„ `SummaryIndex` ç™¼å‡ºæŸ¥è©¢æ™‚ï¼Œæœƒç™¼ç”Ÿä»¥ä¸‹æµç¨‹ï¼š\n",
    "\n",
    "é€æ­¥æµç¨‹èªªæ˜\n",
    "\n",
    "1. é¸æ“‡ï¼ˆSelectionï¼‰\n",
    "    - ç´¢å¼•æœƒå–å‡ºå…¶æ‰€å„²å­˜çš„ IndexNode é …ç›®\n",
    "    - é€šå¸¸æœƒé¸å–æ‰€æœ‰ç¯€é»\n",
    "2. å§”æ´¾ï¼ˆDelegationï¼‰\n",
    "    - ç”±æ–¼æ¯å€‹ç¯€é»éƒ½åŒ…å«ä¸€å€‹ objï¼ŒLlamaIndex æœƒï¼š\n",
    "    - å–å‡ºï¼ˆunwrapï¼‰è©²ç‰©ä»¶\n",
    "    - å°æ¯å€‹ retriever åŸ·è¡Œå­æŸ¥è©¢ï¼ˆsub-queryï¼‰\n",
    "3. æ··åˆæª¢ç´¢ï¼ˆHybrid Retrievalï¼‰\n",
    "    - Vector Retriever â†’ èªæ„ç›¸ä¼¼åº¦æœå°‹\n",
    "    - BM25 Retriever â†’ é—œéµå­—å°å‘çš„æœå°‹\n",
    "4. æ··åˆç¶œåˆï¼ˆHybrid Synthesisï¼‰\n",
    "    - LLM åŒæ™‚æ¥æ”¶ä¾†è‡ªå…©ç¨®æª¢ç´¢ç­–ç•¥çš„ä¸Šä¸‹æ–‡\n",
    "    - ç”¢ç”Ÿå–®ä¸€ã€æ•´åˆå¾Œçš„å›æ‡‰\n",
    "\n",
    "## 4. æ¯”è¼ƒï¼šSummaryIndex vs VectorStoreIndex\n",
    "\n",
    "| ç‰¹æ€§          | SummaryIndex | VectorStoreIndex |\n",
    "| ----------- | ------------ | ---------------- |\n",
    "| **çµæ§‹**      | ä¾åºæ’åˆ—çš„æ¸…å–®      | å‘é‡ç©ºé–“ï¼ˆEmbeddingsï¼‰ |\n",
    "| **æª¢ç´¢è¡Œç‚º**    | ï¼ˆé€šå¸¸ï¼‰æª¢ç´¢æ‰€æœ‰ç¯€é»   | å›å‚³å‰ k å€‹æœ€ç›¸ä¼¼çš„ç¯€é»    |\n",
    "| **ä¸»è¦ä½¿ç”¨æƒ…å¢ƒ**  | æ‘˜è¦èˆ‡å·¥å…·ç·¨æ’      | äº‹å¯¦æª¢ç´¢èˆ‡å•ç­”          |\n",
    "| **æœå°‹æ¨¡å¼**    | å»£æ³›ã€æ··åˆå¼åŸ·è¡Œ     | ç›®æ¨™æ˜ç¢ºçš„èªæ„æœå°‹        |\n",
    "| **LLM çš„è§’è‰²** | ç¶œåˆèˆ‡èšåˆ        | æ’åºèˆ‡å›ç­”            |\n",
    "\n",
    "## âš ï¸ é‡è¦æé†’ï¼šSummaryIndex çš„ä½¿ç”¨é‚Šç•Œèˆ‡ç—›é»\n",
    "é›–ç„¶ SummaryIndex åœ¨çµåˆ IndexNode æ™‚å±•ç¾äº†å¼·å¤§çš„ç·¨æ’èƒ½åŠ›ï¼Œä½†é–‹ç™¼è€…å¿…é ˆè­¦æƒ•å…¶æ“´å±•æ€§é™åˆ¶ï¼š\n",
    "\n",
    "Context çˆ†ç‚¸é¢¨éšªï¼šSummaryIndex çš„é è¨­è¡Œç‚ºæ˜¯æª¢ç´¢å…¶ä¸‹çš„æ‰€æœ‰ç¯€é»ã€‚å¦‚æœä½ å°‡å®ƒç”¨æ–¼ä¸€èˆ¬çš„æ–‡æª”ç¯€é»æª¢ç´¢ï¼Œç•¶æ–‡æª”æ•¸é‡é”åˆ°æ•¸ç™¾ç”šè‡³æ•¸åƒæ™‚ï¼Œä¸€æ¬¡æŸ¥è©¢å°±æœƒæŠŠæ‰€æœ‰æ–‡æœ¬å¡å…¥ Context Windowï¼Œç›´æ¥å°è‡´é•·åº¦æº¢å‡ºã€‚\n",
    "\n",
    "API è²»ç”¨æ¿€å¢ï¼šæ¯ä¸€æ¬¡æŸ¥è©¢éƒ½æœƒå¼·åˆ¶åŸ·è¡Œæ‰€æœ‰ IndexNode é—œè¯çš„å­è·¯å¾‘ï¼ˆSub-pathsï¼‰ï¼Œé€™æœƒæ¶ˆè€—å¤§é‡çš„ Token æˆæœ¬ã€‚\n",
    "\n",
    "æœ€ä½³å¯¦è¸ï¼šåšã€Œå°‡é ˜ã€è€Œéã€Œå£«å…µã€ï¼š\n",
    "\n",
    "ä¸è¦å°‡ SummaryIndex ç”¨æ–¼å­˜å„²æˆåƒä¸Šè¬å€‹åŸå§‹æ–‡æª”ç‰‡æ®µã€‚\n",
    "\n",
    "æ‡‰è©²å°‡å…¶è¦–ç‚º Retriever Orchestratorï¼ˆæª¢ç´¢ç·¨æ’å™¨ï¼‰ï¼Œç”¨ä¾†ç®¡ç†å°‘æ•¸å¹¾å€‹ï¼ˆä¾‹å¦‚ 3-5 å€‹ï¼‰é«˜æ€§èƒ½çš„å·¥å…·æˆ–å­ç´¢å¼•ã€‚é€™æ¨£å®ƒèƒ½ç¢ºä¿åœ¨ä¸€æ¬¡æŸ¥è©¢ä¸­ï¼ŒåŒæ™‚èª¿ç”¨ä¸åŒçš„æª¢ç´¢ç­–ç•¥ï¼ˆå¦‚ Vectorã€BM25ã€KGï¼‰ä¸¦é€²è¡Œæœ€çµ‚çš„ç¸½çµã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cdcdb0-5acc-467f-bd83-0b5b932ac838",
   "metadata": {},
   "source": [
    "### æŸ¥è©¢ï¼ˆQueryingï¼‰\n",
    "\n",
    "ç•¶æˆ‘å€‘é€²è¡ŒæŸ¥è©¢æ™‚ï¼Œæ‰€æœ‰ç‰©ä»¶éƒ½æœƒè¢«å–å›ï¼Œä¸¦ç”¨ä¾†ç”¢ç”Ÿç¯€é»ï¼ˆnodesï¼‰ï¼Œä»¥å–å¾—æœ€çµ‚ç­”æ¡ˆã€‚\n",
    "\n",
    "ä½¿ç”¨ `tree_summarize` æ­é… `aquery()` å¯ä»¥ç¢ºä¿ä¸¦è¡Œï¼ˆconcurrentï¼‰åŸ·è¡Œï¼Œä¸¦å¸¶ä¾†æ›´å¿«çš„å›æ‡‰é€Ÿåº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296ee4e-dd4c-4f20-8d31-915770c02ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776acdc3-b9b1-4b7f-8842-8c1723ec3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from initialization import credential_init\n",
    "\n",
    "credential_init()\n",
    "\n",
    "llm = OpenAI(\"gpt-4o-mini\")\n",
    "\n",
    "query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", verbose=True,\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d369d22-22e4-4740-bfa6-eac2aaf56716",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await query_engine.aquery(\n",
    "    \"Compare the strength between OpenAI and Anthroopic.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5afb8b-3ec6-4dc2-9256-dde9a965a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2cd3e5-91b0-4228-a153-1219d9d6c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0aae8-7332-4269-822c-c3d4a6d2c9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
